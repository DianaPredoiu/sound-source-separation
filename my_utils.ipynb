{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_after_getting_stft_done(female_filename, male_filename):\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = int(0.001 * 8000)\n",
    "    \n",
    "    male, sr_male = librosa.load(male_filename, sr=16000) \n",
    "    female, sr_female = librosa.load(female_filename, sr=16000) \n",
    "\n",
    "    # pad smaller array with zeros, so both audio files have the same length\n",
    "    female, male = my_utils.make_wav_files_same_size(female, male)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix_filename= my_utils.mix_audios(male_filename, female_filename)\n",
    "    mix, sr_mix = librosa.load(mix_filename, sr=16000)\n",
    "    \n",
    "    print(\"duration window: \",librosa.get_duration(y=mix, sr=16000))\n",
    "    \n",
    "    female_stft = librosa.stft(librosa.to_mono(female), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    male_stft = librosa.stft(librosa.to_mono(male), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    mix_stft = librosa.stft(librosa.to_mono(mix), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    \n",
    "    print(female_stft.shape)\n",
    "    duration= librosa.get_duration(S=female_stft, sr=16000) * 1000\n",
    "    seg = librosa.get_duration(S=female_stft[:,:2], sr=16000)\n",
    "    print(seg)\n",
    "    print(\"duration window: \",librosa.get_duration(S=female_stft, sr=16000))\n",
    "    print(\"duration window: \",librosa.get_duration(S=male_stft, sr=16000))\n",
    "    print(\"duration window: \",librosa.get_duration(S=mix_stft, sr=16000))\n",
    "    \n",
    "    sound1 = np.empty_like(female_stft)\n",
    "    sound2 = np.empty_like(female_stft)\n",
    "    \n",
    "    total_ms = mix_stft.shape[1]\n",
    "    frame_size_ms = 2\n",
    "    i = 0\n",
    "    \n",
    "#     print(\"duration window: \",librosa.get_duration(y=frame_1, sr=16000))\n",
    "    \n",
    "    while i * frame_size_ms < total_ms:\n",
    "        start = i * frame_size_ms\n",
    "        stop = i * frame_size_ms + frame_size_ms\n",
    "        \n",
    "        # in case the frame size goes above mix length\n",
    "        if stop > total_ms:\n",
    "            fs = total_ms - start\n",
    "            stop = i * frame_size_ms + fs\n",
    "        \n",
    "        # compute masks for current frame\n",
    "        mask_1 = my_utils.compute_mask(female_stft[:, start:stop], male_stft[:, start:stop])\n",
    "        mask_2 = my_utils.compute_mask(male_stft[:, start:stop], female_stft[:, start:stop])\n",
    "\n",
    "        print(\"--------------------------\")\n",
    "        print(mask_1[0:10, 0])\n",
    "        # get sound for each source of i-th frame\n",
    "#         y_frame_1_stft = my_utils.get_stft_matrix_from_mixture(mask_1, mix_stft[:, start:stop])\n",
    "#         y_frame_2_stft = my_utils.get_stft_matrix_from_mixture(mask_2, mix_stft[:, start:stop])\n",
    "        \n",
    "#         inverse_sound1_stft = librosa.istft(y_frame_1_stft, window='hann', hop_length=hop_length)\n",
    "#         inverse_sound2_stft = librosa.istft(y_frame_2_stft, window='hann', hop_length=hop_length)\n",
    "        \n",
    "# #         print(sound1.shape)\n",
    "# #         print(inverse_sound1_stft.shape)\n",
    "        \n",
    "        sound1 = np.concatenate((sound1, mask_1))\n",
    "        sound2 = np.concatenate((sound2, mask_2))\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    sound1 = my_utils.delete_final_zeros_for_silence(sound1)\n",
    "    sound2 = my_utils.delete_final_zeros_for_silence(sound2)\n",
    "        \n",
    "    librosa.output.write_wav('../recordings/test-female.wav', sound1, sr = 16000)\n",
    "    librosa.output.write_wav('../recordings/test-male.wav', sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audios(filename1, filename2):\n",
    "    sound1 = AudioSegment.from_file(filename1)\n",
    "    sound2 = AudioSegment.from_file(filename2)\n",
    "\n",
    "    # overlay over the longest audio source\n",
    "    if np.array(sound1.get_array_of_samples()).shape[0] > np.array(sound2.get_array_of_samples()).shape[0]:\n",
    "        combined = sound1.overlay(sound2)\n",
    "    else:\n",
    "        combined = sound2.overlay(sound1)\n",
    "\n",
    "    sound1_start, sound1_end = filename1.index('arctic'), filename1.index('.wav')\n",
    "    sound2_start, sound2_end = filename2.index('arctic'), filename2.index('.wav')\n",
    "    name = \"../recordings/mixes/\" + filename1[sound1_start:sound1_end] + '_' + filename2[sound2_start:sound2_end] + \".wav\"\n",
    "    combined.export(name, format='wav')\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_frame_in_ms(audio_array, start, stop):\n",
    "    # in milliseconds\n",
    "    newAudio = audio_array[start:stop]\n",
    "    return newAudio\n",
    "#     print(\"aici: \", len(audio_array), start, stop)\n",
    "    \n",
    "#     if stop <= len(audio_array):\n",
    "#     print(\"1: \", len(audio_array), start, stop)\n",
    "#     newAudio = audio_array[start:stop]\n",
    "#     return newAudio\n",
    "#     elif start >= len(audio_array):\n",
    "#         print(\"2: \", len(audio_array), start, stop)\n",
    "#         newAudio = np.zeros(stop-start)\n",
    "#         return ndarray_to_audiosegment(newAudio, 16000)\n",
    "#     elif start < len(audio_array) and stop > len(audio_array):\n",
    "#         print(\"3: \", len(audio_array), start, stop)\n",
    "#         oldAudio = audio_array[start:len(audio_array)-1]\n",
    "#         newAudio = np.zeros(stop-start)\n",
    "#         oldAudio.resize(newAudio.shape)\n",
    "#         newAudio = newAudio + oldAudio\n",
    "#         newAudio = ndarray_to_audiosegment(newAudio,16000)\n",
    "#         return newAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wav_files_same_size(arr1, arr2):\n",
    "    if arr1.shape[0] < arr2.shape[0] :\n",
    "        arr1 = np.pad(arr1, (0,(arr2.shape[0] - arr1.shape[0])), 'constant', constant_values=(0))\n",
    "    else :\n",
    "        arr2 = np.pad(arr2, (0,(arr1.shape[0] - arr2.shape[0])), 'constant', constant_values=(0))\n",
    "    \n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(stft_1, stft_2):\n",
    "#     print(\"aici: \", stft_1.shape, stft_2.shape)\n",
    "    # small epsilon to avoid dividing by zero\n",
    "    eps = np.finfo(np.float).eps\n",
    "\n",
    "    # compute model as the sum of spectrograms\n",
    "    mix = eps + np.abs(stft_1) + np.abs(stft_2)\n",
    "    \n",
    "    mask = np.divide(np.abs(stft_1), mix)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stft_matrix_from_mixture(mask, mixture):\n",
    "    return np.multiply(mask, mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_new_audio_file(sound, filename):\n",
    "    inverse_sound_stft = librosa.istft(sound)\n",
    "    librosa.output.write_wav(filename, inverse_sound_stft, 16000)\n",
    "    #s = sound.export(filename, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiosegment_to_ndarray(audiosegment):\n",
    "    samples = audiosegment.get_array_of_samples()\n",
    "    samples_float = librosa.util.buf_to_float(samples,n_bytes=2,\n",
    "                                      dtype=np.float32)\n",
    "    if audiosegment.channels==2:\n",
    "        sample_left= np.copy(samples_float[::2])\n",
    "        sample_right= np.copy(samples_float[1::2])\n",
    "        sample_all = np.array([sample_left,sample_right])\n",
    "    else:\n",
    "        sample_all = samples_float\n",
    "        \n",
    "        \n",
    "    return [sample_all,audiosegment.frame_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndarray_to_audiosegment(y,frame_rate):\n",
    "    \n",
    "    if(len(y.shape) == 2):\n",
    "        new_array = np.zeros((y.shape[1]*2),dtype=float)\n",
    "        new_array[::2] = y[0]\n",
    "        new_array[1::2] = y[1]\n",
    "    else:\n",
    "        new_array = y\n",
    "        \n",
    "    audio_segment = AudioSegment(\n",
    "    new_array.tobytes(), \n",
    "    frame_rate=frame_rate,\n",
    "    sample_width=new_array.dtype.itemsize, \n",
    "    channels = len(y.shape)\n",
    ")\n",
    "    return audio_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_mix_files(female_filename, male_filename):\n",
    "    # get 2 audio files\n",
    "    male, sr_male = librosa.load(male_filename, sr=16000) \n",
    "    female, sr_female = librosa.load(female_filename, sr=16000) \n",
    "\n",
    "    # pad smaller array with zeros, so both audio files have the same length\n",
    "    female, male = make_wav_files_same_size(female, male)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix_filename= mix_audios(male_filename, female_filename)\n",
    "    mix, sr_mix = librosa.load(mix_filename, sr=16000)\n",
    "\n",
    "    # durata totala a inregistrarii\n",
    "    male_rec_ms = float(len(male)) / sr_male * 1000\n",
    "    female_rec_ms = float(len(female)) / sr_female * 1000\n",
    "    mixed_audio_rec_ms = float(len(mix)) / 16000 * 1000\n",
    "    print(male_rec_ms, female_rec_ms, mixed_audio_rec_ms)\n",
    "    \n",
    "    return female, male, mix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
