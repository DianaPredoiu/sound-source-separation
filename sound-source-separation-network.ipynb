{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\envs\\machine-learning\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import my_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 8\n",
    "sr = 16000\n",
    "\n",
    "# cate bucati PF iau in considerare pentru AF -> cu overlapping => 15 frame-uri \n",
    "# ultimul frame din AF fiind PF-ul curent\n",
    "nb_of_PFs_per_AF = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT_AF_frames(AF_array, PF_size):\n",
    "    frames = []\n",
    "    half = (int)(PF_size/2)\n",
    "    \n",
    "    for i in range (0, AF_array.shape[0]):\n",
    "\n",
    "        # 1. add current frame from AF\n",
    "        frame = librosa.stft(librosa.to_mono(AF_array[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        frame = np.abs(frame)\n",
    "        \n",
    "        tensor = []\n",
    "        tensor.append(frame)        \n",
    "        frames.append(tensor)\n",
    "        \n",
    "        # 2. add overlapped frame if the current frame is not the last one\n",
    "        if i < AF_array.shape[0]-1:\n",
    "            overlap_frame = AF_array[i][half:]\n",
    "            overlap_frame = np.concatenate((overlap_frame, AF_array[i+1][:half]))\n",
    "            \n",
    "            frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "            frame = np.abs(frame)\n",
    "\n",
    "            tensor = []\n",
    "            tensor.append(frame)\n",
    "            frames.append(tensor)\n",
    "        \n",
    "    \n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set_for_mix(mix, voice_1, voice_2, samples_per_frame):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_1_frames = np.array([voice_1[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_2_frames = np.array([voice_2[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    \n",
    "    for index in range(mix_frames.shape[0]):\n",
    "        \n",
    "        if index < nb_of_PFs_per_AF - 1:\n",
    "            continue\n",
    "        \n",
    "        # 1. create train set input for AF with current PF and previous frames\n",
    "        AF_frames = np.array([mix_frames[i] for i in range(index - nb_of_PFs_per_AF, index)])\n",
    "        AF_STFT_frames = get_STFT_AF_frames(AF_array=AF_frames, PF_size= samples_per_frame)\n",
    "        inputs.append(AF_STFT_frames)\n",
    "        \n",
    "        # 2. create train set target for that AF, containing the mask for the current PF\n",
    "        stft_voice_1 = librosa.stft(librosa.to_mono(voice_1_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        stft_voice_2 = librosa.stft(librosa.to_mono(voice_2_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        mask = my_utils.compute_mask(stft_voice_1, stft_voice_2)\n",
    "        \n",
    "        targets.append(mask)\n",
    "    \n",
    "    # train set for only one audio\n",
    "    train_set_input = torch.from_numpy(np.array(inputs))\n",
    "    \n",
    "    # target contains the calculated masks for each PF from mix\n",
    "    train_set_target = torch.from_numpy(np.array(targets))\n",
    "\n",
    "#     assert(train_set_input.shape == (996, 4, 1, 513, 11))\n",
    "#     assert(train_set_target.shape == (996, 513, 11))\n",
    "    train_set = dict(zip(train_set_input, train_set_target))\n",
    "    return train_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 5 ms\n",
    "    def __init__(self, height = 513, width = 11):\n",
    "        super(Network, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(1 * height * width, 250)\n",
    "        self.fc1_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(250, 250)\n",
    "        self.fc2_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(250, height * width)\n",
    "        self.fc3_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # layer 1\n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        x = x.view(-1, self.height * self.width)        \n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc1_batch(x)\n",
    "#         print(\"1 shapes: \", x.shape)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2_batch(x)\n",
    "#         print(\"2 shapes: \", x.shape)\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc3_batch(x)\n",
    "#         print(\"3 shapes: \", x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network sent to CUDA\n"
     ]
    }
   ],
   "source": [
    "# create network\n",
    "# no params => height = 513, width = 11 -> for a processing frame of 5 ms\n",
    "network = Network()\n",
    "\n",
    "# if cuda is available, send network's params to gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(\"network sent to CUDA\")\n",
    "    network.cuda()\n",
    "    \n",
    "# set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "optimizer = optim.Adam(network.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init arrays for train/test errors\n",
    "# train_losses = []\n",
    "# train_counter = []\n",
    "\n",
    "# test_losses = []\n",
    "# test_counter = [i*len(train_set) for i in range(n_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix total length:  80000\n",
      "mix total length (ms) :  5000.0\n",
      "nb of samples for 5 ms frame = 80 samples/array\n",
      "---------------------------------------------------------\n",
      "AF entries in train_set:  993\n"
     ]
    }
   ],
   "source": [
    "male_filename = 'recordings/voice2/arctic_a0002.wav'\n",
    "female_filename = 'recordings/voice1/arctic_a0001.wav'\n",
    "\n",
    "male, sr = librosa.load(male_filename, sr=16000) \n",
    "female, sr = librosa.load(female_filename, sr=16000) \n",
    "\n",
    "# pad smaller array with zeros, so both audio files have the same length\n",
    "female, male = my_utils.make_wav_files_same_size(female, male)\n",
    "\n",
    "# load the mixed audio \n",
    "mix = female + male\n",
    "\n",
    "male = np.array(male)\n",
    "female = np.array(female)\n",
    "mix = np.array(mix)\n",
    "\n",
    "frame_length_ms = 5\n",
    "mix_length_ms = len(mix) / sr * 1000\n",
    "samples_per_frame = (int)(len(mix) * frame_length_ms / mix_length_ms)\n",
    "\n",
    "print(\"mix total length: \",len(mix))\n",
    "print(\"mix total length (ms) : \", mix_length_ms)\n",
    "print(\"nb of samples for\", frame_length_ms,\"ms frame =\", samples_per_frame, \"samples/array\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "\n",
    "train_set = get_train_set_for_mix(mix, female, male, samples_per_frame)\n",
    "\n",
    "# make test set the same as train set so I can test the overfitting\n",
    "test_set = get_train_set_for_mix(mix, female, male, samples_per_frame) \n",
    "print(\"AF entries in train_set: \",len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(nr_epochs, train_set, test_set):\n",
    "\n",
    "    mask = []\n",
    "    mask_test = []\n",
    "\n",
    "    last_valid_loss = 0\n",
    "    nb_of_epochs_for_valid_loss = 0\n",
    "\n",
    "    # plot train/valid loss contains losses on each epoch, so we can see after each epoch what happens with the error\n",
    "    plot_train_loss = []\n",
    "    plot_valid_loss = []\n",
    "\n",
    "    for epoch in range(1, nr_epochs+1):\n",
    "        mask = []\n",
    "        mask_test = []\n",
    "\n",
    "        train_loss, valid_loss = [], []\n",
    "        loss = 0\n",
    "\n",
    "        print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "        ## training part \n",
    "        network.train()\n",
    "        for index, (input, target) in enumerate(train_set.items()):\n",
    "\n",
    "            # target is transformed from a matrix to an array, so the error can be calculated easier\n",
    "            # since the network returns an array\n",
    "            target_view = target.view(-1, target.shape[0] * target.shape[1])\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            if torch.cuda.is_available():\n",
    "                input, target_view = input.cuda(), target_view.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network(input)\n",
    "\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target_view[0], output[len(output)-1])  \n",
    "\n",
    "\n",
    "            # 3. backward propagation\n",
    "            loss.backward() \n",
    "\n",
    "\n",
    "            # 4. weight optimization\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # 5. save the loss for this PF\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "\n",
    "            # 6. save the mask for the current PF, meaning the last entry in the output[AF]\n",
    "            current_mask = output[len(output)-1].view(513, 11)\n",
    "            mask.append(current_mask)\n",
    "\n",
    "        # add the mean loss for this training epoch for ploting\n",
    "        plot_train_loss.append(np.mean(train_loss))\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        ## evaluation part \n",
    "        network.eval()\n",
    "        for index, (input, target) in enumerate(test_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            target_view = target.view(-1, target.shape[0] * target.shape[1])\n",
    "            if torch.cuda.is_available():\n",
    "                input, target_view = input.cuda(), target_view.cuda()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network(input)\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target_view[0], output[len(output)-1]).detach().item()\n",
    "\n",
    "            # 6. save the mask for the current PF, meaning the last entry in the output\n",
    "            current_mask = output[len(output)-1].view(513, 11)\n",
    "            mask_test.append(current_mask)\n",
    "\n",
    "            if loss != last_valid_loss:\n",
    "                last_valid_loss = loss\n",
    "            else:\n",
    "                nb_of_epochs_for_valid_loss += 1\n",
    "\n",
    "            valid_loss.append(loss)\n",
    "\n",
    "        # add the mean loss for this training epoch for ploting\n",
    "        plot_valid_loss.append(np.mean(valid_loss))\n",
    "\n",
    "        # check if we have the same loss for validation set\n",
    "        if last_valid_loss == (np.mean(valid_loss)):\n",
    "            nb_of_epochs_for_valid_loss += 1\n",
    "        else:\n",
    "            last_valid_loss = np.mean(valid_loss)\n",
    "\n",
    "        print (\"\\nTraining Loss: \", np.mean(train_loss), \"\\nValid Loss: \", np.mean(valid_loss))\n",
    "        \n",
    "        if(nb_of_epochs_for_valid_loss == 20):\n",
    "            break\n",
    "\n",
    "\n",
    "    plt.plot(plot_train_loss)\n",
    "    plt.title('train losses')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(plot_valid_loss)\n",
    "    plt.title('valid losses')\n",
    "    plt.show()\n",
    "    \n",
    "    return mask, mask_test, network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONSTRUIRE SUNET PE FRAME-URI, FOLOSIND TARGETURILE GENERATE PT SETUL DE ANTRENARE\n",
    "def split_audios_epoch(name, mask):\n",
    "    mask_stack = torch.stack(mask)\n",
    "#     print(mask_stack.shape)\n",
    "\n",
    "    cpu_mask = mask_stack.cpu()\n",
    "#     print(cpu_mask.shape)\n",
    "\n",
    "    n_mask = cpu_mask.detach().numpy()\n",
    "#     print(n_mask.shape)\n",
    "\n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "\n",
    "\n",
    "    for i in range (0, len(mix_frames)):\n",
    "        stft_mix = librosa.stft(librosa.to_mono(mix_frames[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "\n",
    "        # reteaua nu a invatat mastile pentru primele 7(n) bucati [PF] din mix\n",
    "        # deci las matricea STFT asa cum e in mix\n",
    "        if i < nb_of_PFs_per_AF - 1:\n",
    "            y_frame_1_stft_with_mask = stft_mix\n",
    "            y_frame_2_stft_with_mask = stft_mix\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "            \n",
    "        else:\n",
    "            # n_mask[i-7] pentru ca reteaua invata pt AF-uri facute pe cate 8 PF-uri -> 15 items pt AF\n",
    "            # abia de cand ajunge la primul AF care s a putut compune, folosesc masca invata de retea\n",
    "            \n",
    "            y_frame_1_stft_with_mask = np.multiply(n_mask[i-7], stft_mix)\n",
    "            y_frame_2_stft_with_mask = np.multiply((1 -  n_mask[i-7]), stft_mix)\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "\n",
    "\n",
    "    librosa.output.write_wav(\"recordings/DNN-voice1-\"+ str(name) + \".wav\", sound1, sr = 16000)\n",
    "    librosa.output.write_wav(\"recordings/DNN-voice2-\"+ str(name) + \".wav\", sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, test_set):\n",
    "\n",
    "    network.eval()\n",
    "\n",
    "    valid_loss, valid_mask = [], []\n",
    "\n",
    "    for index, (input, target) in enumerate(test_set.items()):\n",
    "\n",
    "        target_view = target.view(-1, target.shape[0] * target.shape[1])\n",
    "\n",
    "        # if cuda is available, send (input, target) to gpu\n",
    "        if torch.cuda.is_available():\n",
    "            input, target_view = input.cuda(), target_view.cuda()\n",
    "\n",
    "        # 1. forward propagation\n",
    "        output = network(input)\n",
    "\n",
    "        # 2. loss calculation\n",
    "        loss = loss_function(target_view[0], output[len(output)-1]).detach().item()\n",
    "\n",
    "        # 3. save the mask for the current PF, meaning the last entry in the output\n",
    "        current_mask = output[len(output)-1].view(513, 11)\n",
    "        valid_mask.append(current_mask)\n",
    "\n",
    "        valid_loss.append(loss)\n",
    "\n",
    "\n",
    "    print(\"Validation set loss:\", np.mean(valid_loss))\n",
    "\n",
    "    plt.plot(valid_loss)\n",
    "    plt.title('valid losses')\n",
    "    plt.show()  \n",
    "    \n",
    "    return valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Epoch 1 ------------------------------\n",
      "\n",
      "Training Loss:  0.4366798513819354 \n",
      "Valid Loss:  0.32489784486396733\n",
      "--------------------------------------Epoch 2 ------------------------------\n",
      "\n",
      "Training Loss:  0.18528033511231073 \n",
      "Valid Loss:  0.20740532852364152\n",
      "--------------------------------------Epoch 3 ------------------------------\n",
      "\n",
      "Training Loss:  0.14844541446740053 \n",
      "Valid Loss:  0.179291674527757\n",
      "--------------------------------------Epoch 4 ------------------------------\n",
      "\n",
      "Training Loss:  0.1445034310983237 \n",
      "Valid Loss:  0.18182272723269127\n",
      "--------------------------------------Epoch 5 ------------------------------\n",
      "\n",
      "Training Loss:  0.14454099723519637 \n",
      "Valid Loss:  0.1783548724262676\n",
      "--------------------------------------Epoch 6 ------------------------------\n",
      "\n",
      "Training Loss:  0.144773628795285 \n",
      "Valid Loss:  0.1897664997456567\n",
      "--------------------------------------Epoch 7 ------------------------------\n",
      "\n",
      "Training Loss:  0.14404785693299554 \n",
      "Valid Loss:  0.1854730018406116\n",
      "--------------------------------------Epoch 8 ------------------------------\n",
      "\n",
      "Training Loss:  0.1446321093817762 \n",
      "Valid Loss:  0.16234072479761738\n",
      "--------------------------------------Epoch 9 ------------------------------\n",
      "\n",
      "Training Loss:  0.1422110061027102 \n",
      "Valid Loss:  0.17132345168154464\n",
      "--------------------------------------Epoch 10 ------------------------------\n",
      "\n",
      "Training Loss:  0.14050474570274413 \n",
      "Valid Loss:  0.1821654514022254\n",
      "--------------------------------------Epoch 11 ------------------------------\n",
      "\n",
      "Training Loss:  0.13969927081746336 \n",
      "Valid Loss:  0.19801920821396907\n",
      "--------------------------------------Epoch 12 ------------------------------\n",
      "\n",
      "Training Loss:  0.13956983282239235 \n",
      "Valid Loss:  0.19920559156562267\n",
      "--------------------------------------Epoch 13 ------------------------------\n",
      "\n",
      "Training Loss:  0.13788694708841626 \n",
      "Valid Loss:  0.19541378510592566\n",
      "--------------------------------------Epoch 14 ------------------------------\n",
      "\n",
      "Training Loss:  0.1346890268038887 \n",
      "Valid Loss:  0.1968165048269587\n",
      "--------------------------------------Epoch 15 ------------------------------\n",
      "\n",
      "Training Loss:  0.134523961529856 \n",
      "Valid Loss:  0.19630306930640432\n",
      "--------------------------------------Epoch 16 ------------------------------\n",
      "\n",
      "Training Loss:  0.13453154535992268 \n",
      "Valid Loss:  0.20325148308017524\n",
      "--------------------------------------Epoch 17 ------------------------------\n",
      "\n",
      "Training Loss:  0.13074371633415316 \n",
      "Valid Loss:  0.20697258192903295\n",
      "--------------------------------------Epoch 18 ------------------------------\n",
      "\n",
      "Training Loss:  0.12765936885115364 \n",
      "Valid Loss:  0.211248686742544\n",
      "--------------------------------------Epoch 19 ------------------------------\n",
      "\n",
      "Training Loss:  0.13023873835835842 \n",
      "Valid Loss:  0.2067221498992838\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "\n",
      "Training Loss:  0.13067108201949076 \n",
      "Valid Loss:  0.20318302032814436\n",
      "--------------------------------------Epoch 21 ------------------------------\n",
      "\n",
      "Training Loss:  0.13091866639025382 \n",
      "Valid Loss:  0.21695521908220416\n",
      "--------------------------------------Epoch 22 ------------------------------\n",
      "\n",
      "Training Loss:  0.1273710557052346 \n",
      "Valid Loss:  0.23497430631686433\n",
      "--------------------------------------Epoch 23 ------------------------------\n",
      "\n",
      "Training Loss:  0.12291621111384016 \n",
      "Valid Loss:  0.22878409797571456\n",
      "--------------------------------------Epoch 24 ------------------------------\n",
      "\n",
      "Training Loss:  0.1199782775191652 \n",
      "Valid Loss:  0.22149262499544406\n",
      "--------------------------------------Epoch 25 ------------------------------\n",
      "\n",
      "Training Loss:  0.11972536896446895 \n",
      "Valid Loss:  0.23353373014704817\n",
      "--------------------------------------Epoch 26 ------------------------------\n",
      "\n",
      "Training Loss:  0.11825881555089343 \n",
      "Valid Loss:  0.22608786198701653\n",
      "--------------------------------------Epoch 27 ------------------------------\n",
      "\n",
      "Training Loss:  0.11722244919699308 \n",
      "Valid Loss:  0.21719953366475553\n",
      "--------------------------------------Epoch 28 ------------------------------\n",
      "\n",
      "Training Loss:  0.11201907134614181 \n",
      "Valid Loss:  0.227288852222095\n",
      "--------------------------------------Epoch 29 ------------------------------\n",
      "\n",
      "Training Loss:  0.11081457903581657 \n",
      "Valid Loss:  0.22297266057494575\n",
      "--------------------------------------Epoch 30 ------------------------------\n",
      "\n",
      "Training Loss:  0.10386935281805851 \n",
      "Valid Loss:  0.24543439405234033\n",
      "--------------------------------------Epoch 31 ------------------------------\n",
      "\n",
      "Training Loss:  0.101731807211221 \n",
      "Valid Loss:  0.24523617323367947\n",
      "--------------------------------------Epoch 32 ------------------------------\n",
      "\n",
      "Training Loss:  0.09909532710652569 \n",
      "Valid Loss:  0.25687611159706286\n",
      "--------------------------------------Epoch 33 ------------------------------\n",
      "\n",
      "Training Loss:  0.11352809221640395 \n",
      "Valid Loss:  0.25215038041746446\n",
      "--------------------------------------Epoch 34 ------------------------------\n",
      "\n",
      "Training Loss:  0.10755428047423403 \n",
      "Valid Loss:  0.26463602567354194\n",
      "--------------------------------------Epoch 35 ------------------------------\n",
      "\n",
      "Training Loss:  0.09859009512388527 \n",
      "Valid Loss:  0.2915056459586936\n",
      "--------------------------------------Epoch 36 ------------------------------\n",
      "\n",
      "Training Loss:  0.10899859771132117 \n",
      "Valid Loss:  0.2431524884976139\n",
      "--------------------------------------Epoch 37 ------------------------------\n",
      "\n",
      "Training Loss:  0.10584490316428646 \n",
      "Valid Loss:  0.37286206459896665\n",
      "--------------------------------------Epoch 38 ------------------------------\n",
      "\n",
      "Training Loss:  0.10223412979946672 \n",
      "Valid Loss:  0.35797647947317957\n",
      "--------------------------------------Epoch 39 ------------------------------\n",
      "\n",
      "Training Loss:  0.09720935019713588 \n",
      "Valid Loss:  0.3336107208236887\n",
      "--------------------------------------Epoch 40 ------------------------------\n",
      "\n",
      "Training Loss:  0.09865030406620555 \n",
      "Valid Loss:  0.3152023602749736\n",
      "--------------------------------------Epoch 41 ------------------------------\n",
      "\n",
      "Training Loss:  0.09222490431547499 \n",
      "Valid Loss:  0.29817202015266886\n",
      "--------------------------------------Epoch 42 ------------------------------\n",
      "\n",
      "Training Loss:  0.09391590952947967 \n",
      "Valid Loss:  0.3827004378365141\n",
      "--------------------------------------Epoch 43 ------------------------------\n",
      "\n",
      "Training Loss:  0.08907178554419469 \n",
      "Valid Loss:  0.3262629187764358\n",
      "--------------------------------------Epoch 44 ------------------------------\n",
      "\n",
      "Training Loss:  0.08748841734481942 \n",
      "Valid Loss:  0.3326556797686604\n",
      "--------------------------------------Epoch 45 ------------------------------\n",
      "\n",
      "Training Loss:  0.089475313895144 \n",
      "Valid Loss:  0.32001165108926866\n",
      "--------------------------------------Epoch 46 ------------------------------\n",
      "\n",
      "Training Loss:  0.08831750892445282 \n",
      "Valid Loss:  0.3413038441637242\n",
      "--------------------------------------Epoch 47 ------------------------------\n",
      "\n",
      "Training Loss:  0.08724824594975664 \n",
      "Valid Loss:  0.358135285884854\n",
      "--------------------------------------Epoch 48 ------------------------------\n",
      "\n",
      "Training Loss:  0.08920691242318114 \n",
      "Valid Loss:  0.33707972784847406\n",
      "--------------------------------------Epoch 49 ------------------------------\n",
      "\n",
      "Training Loss:  0.09204267250648555 \n",
      "Valid Loss:  0.3273061323598635\n",
      "--------------------------------------Epoch 50 ------------------------------\n",
      "\n",
      "Training Loss:  0.09706178156671082 \n",
      "Valid Loss:  0.33355100672459465\n",
      "--------------------------------------Epoch 51 ------------------------------\n",
      "\n",
      "Training Loss:  0.08943366719672315 \n",
      "Valid Loss:  0.3342807189683821\n",
      "--------------------------------------Epoch 52 ------------------------------\n",
      "\n",
      "Training Loss:  0.09031043383315715 \n",
      "Valid Loss:  0.346315287405293\n",
      "--------------------------------------Epoch 53 ------------------------------\n",
      "\n",
      "Training Loss:  0.08445018778380209 \n",
      "Valid Loss:  0.3804122045589752\n",
      "--------------------------------------Epoch 54 ------------------------------\n",
      "\n",
      "Training Loss:  0.08304432784560192 \n",
      "Valid Loss:  0.4853436270773726\n",
      "--------------------------------------Epoch 55 ------------------------------\n",
      "\n",
      "Training Loss:  0.08164360747366309 \n",
      "Valid Loss:  0.45839702396668597\n",
      "--------------------------------------Epoch 56 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08497431474891813 \n",
      "Valid Loss:  0.36029568905656084\n",
      "--------------------------------------Epoch 57 ------------------------------\n",
      "\n",
      "Training Loss:  0.0816831569519077 \n",
      "Valid Loss:  0.3864300908054922\n",
      "--------------------------------------Epoch 58 ------------------------------\n",
      "\n",
      "Training Loss:  0.08028540986453273 \n",
      "Valid Loss:  0.34831763838871765\n",
      "--------------------------------------Epoch 59 ------------------------------\n",
      "\n",
      "Training Loss:  0.09444726180619602 \n",
      "Valid Loss:  0.36320104509941886\n",
      "--------------------------------------Epoch 60 ------------------------------\n",
      "\n",
      "Training Loss:  0.0867284613504577 \n",
      "Valid Loss:  0.4118002212987622\n",
      "--------------------------------------Epoch 61 ------------------------------\n",
      "\n",
      "Training Loss:  0.08161062926109923 \n",
      "Valid Loss:  0.4063214416551068\n",
      "--------------------------------------Epoch 62 ------------------------------\n",
      "\n",
      "Training Loss:  0.07952610769644897 \n",
      "Valid Loss:  0.382425616961676\n",
      "--------------------------------------Epoch 63 ------------------------------\n",
      "\n",
      "Training Loss:  0.07843829640827138 \n",
      "Valid Loss:  0.41200393593137613\n",
      "--------------------------------------Epoch 64 ------------------------------\n",
      "\n",
      "Training Loss:  0.08328436622620912 \n",
      "Valid Loss:  0.38687015529337443\n",
      "--------------------------------------Epoch 65 ------------------------------\n",
      "\n",
      "Training Loss:  0.08000959019828612 \n",
      "Valid Loss:  0.4618760858518695\n",
      "--------------------------------------Epoch 66 ------------------------------\n",
      "\n",
      "Training Loss:  0.080650046777328 \n",
      "Valid Loss:  0.428410895856253\n",
      "--------------------------------------Epoch 67 ------------------------------\n",
      "\n",
      "Training Loss:  0.07815882655833734 \n",
      "Valid Loss:  0.5074602914734933\n",
      "--------------------------------------Epoch 68 ------------------------------\n",
      "\n",
      "Training Loss:  0.08434568981213361 \n",
      "Valid Loss:  3.6929738400466476\n",
      "--------------------------------------Epoch 69 ------------------------------\n",
      "\n",
      "Training Loss:  0.09829119009642887 \n",
      "Valid Loss:  0.4068608166437037\n",
      "--------------------------------------Epoch 70 ------------------------------\n",
      "\n",
      "Training Loss:  0.0851011906093627 \n",
      "Valid Loss:  0.650406835891479\n",
      "--------------------------------------Epoch 71 ------------------------------\n",
      "\n",
      "Training Loss:  0.0944915714298748 \n",
      "Valid Loss:  3.8988443175921628\n",
      "--------------------------------------Epoch 72 ------------------------------\n",
      "\n",
      "Training Loss:  0.08295724293786126 \n",
      "Valid Loss:  0.49959001777091505\n",
      "--------------------------------------Epoch 73 ------------------------------\n",
      "\n",
      "Training Loss:  0.0794776907752065 \n",
      "Valid Loss:  0.5643439576431194\n",
      "--------------------------------------Epoch 74 ------------------------------\n",
      "\n",
      "Training Loss:  0.07690423905262046 \n",
      "Valid Loss:  1.4428638592840726\n",
      "--------------------------------------Epoch 75 ------------------------------\n",
      "\n",
      "Training Loss:  0.0788014032597055 \n",
      "Valid Loss:  0.49840049919074875\n",
      "--------------------------------------Epoch 76 ------------------------------\n",
      "\n",
      "Training Loss:  0.07897148635600962 \n",
      "Valid Loss:  2.5651119480154327\n",
      "--------------------------------------Epoch 77 ------------------------------\n",
      "\n",
      "Training Loss:  0.07812398438237166 \n",
      "Valid Loss:  0.879840956730271\n",
      "--------------------------------------Epoch 78 ------------------------------\n",
      "\n",
      "Training Loss:  0.07745788023008848 \n",
      "Valid Loss:  0.6613795214378597\n",
      "--------------------------------------Epoch 79 ------------------------------\n",
      "\n",
      "Training Loss:  0.08043623101794488 \n",
      "Valid Loss:  1.558164803869272\n",
      "--------------------------------------Epoch 80 ------------------------------\n",
      "\n",
      "Training Loss:  0.08750732123357274 \n",
      "Valid Loss:  3.216527188317766\n",
      "--------------------------------------Epoch 81 ------------------------------\n",
      "\n",
      "Training Loss:  0.0859069944392071 \n",
      "Valid Loss:  1.4528070179012127\n",
      "--------------------------------------Epoch 82 ------------------------------\n",
      "\n",
      "Training Loss:  0.0917024587384128 \n",
      "Valid Loss:  0.5633344019581221\n",
      "--------------------------------------Epoch 83 ------------------------------\n",
      "\n",
      "Training Loss:  0.08275642843659328 \n",
      "Valid Loss:  0.836268487774691\n",
      "--------------------------------------Epoch 84 ------------------------------\n",
      "\n",
      "Training Loss:  0.07912663212920754 \n",
      "Valid Loss:  0.7505842869367905\n",
      "--------------------------------------Epoch 85 ------------------------------\n",
      "\n",
      "Training Loss:  0.08202319850816067 \n",
      "Valid Loss:  2.4263658809366806\n",
      "--------------------------------------Epoch 86 ------------------------------\n",
      "\n",
      "Training Loss:  0.08076350220507149 \n",
      "Valid Loss:  1.9055605021010886\n",
      "--------------------------------------Epoch 87 ------------------------------\n",
      "\n",
      "Training Loss:  0.07594708618904032 \n",
      "Valid Loss:  1.8909306236705017\n",
      "--------------------------------------Epoch 88 ------------------------------\n",
      "\n",
      "Training Loss:  0.0756610797319184 \n",
      "Valid Loss:  0.9360494629446181\n",
      "--------------------------------------Epoch 89 ------------------------------\n",
      "\n",
      "Training Loss:  0.07918079346347746 \n",
      "Valid Loss:  1.828367849766893\n",
      "--------------------------------------Epoch 90 ------------------------------\n",
      "\n",
      "Training Loss:  0.08199447641441784 \n",
      "Valid Loss:  6.489847545204863\n",
      "--------------------------------------Epoch 91 ------------------------------\n",
      "\n",
      "Training Loss:  0.07844960689600365 \n",
      "Valid Loss:  1.5532328447857862\n",
      "--------------------------------------Epoch 92 ------------------------------\n",
      "\n",
      "Training Loss:  0.0917509585348568 \n",
      "Valid Loss:  2.3372935962123274\n",
      "--------------------------------------Epoch 93 ------------------------------\n",
      "\n",
      "Training Loss:  0.07999951705528954 \n",
      "Valid Loss:  1.5422844906062758\n",
      "--------------------------------------Epoch 94 ------------------------------\n",
      "\n",
      "Training Loss:  0.07579094115633263 \n",
      "Valid Loss:  0.8927862993028851\n",
      "--------------------------------------Epoch 95 ------------------------------\n",
      "\n",
      "Training Loss:  0.07523804355846143 \n",
      "Valid Loss:  0.8550646657917614\n",
      "--------------------------------------Epoch 96 ------------------------------\n",
      "\n",
      "Training Loss:  0.0775738733130449 \n",
      "Valid Loss:  0.7145984598434524\n",
      "--------------------------------------Epoch 97 ------------------------------\n",
      "\n",
      "Training Loss:  0.0823385965873548 \n",
      "Valid Loss:  1.8500661502506919\n",
      "--------------------------------------Epoch 98 ------------------------------\n",
      "\n",
      "Training Loss:  0.07905711828484395 \n",
      "Valid Loss:  0.6868563150079153\n",
      "--------------------------------------Epoch 99 ------------------------------\n",
      "\n",
      "Training Loss:  0.09018068601300988 \n",
      "Valid Loss:  1.3810261905480323\n",
      "--------------------------------------Epoch 100 ------------------------------\n",
      "\n",
      "Training Loss:  0.09666733981173112 \n",
      "Valid Loss:  14.584403735865939\n",
      "--------------------------------------Epoch 101 ------------------------------\n",
      "\n",
      "Training Loss:  0.08266725524739912 \n",
      "Valid Loss:  8.664122835639208\n",
      "--------------------------------------Epoch 102 ------------------------------\n",
      "\n",
      "Training Loss:  0.07818242716927724 \n",
      "Valid Loss:  7.373731677239425\n",
      "--------------------------------------Epoch 103 ------------------------------\n",
      "\n",
      "Training Loss:  0.07842337024989135 \n",
      "Valid Loss:  5.6054463816163285\n",
      "--------------------------------------Epoch 104 ------------------------------\n",
      "\n",
      "Training Loss:  0.09140518557846904 \n",
      "Valid Loss:  4.57560048759929\n",
      "--------------------------------------Epoch 105 ------------------------------\n",
      "\n",
      "Training Loss:  0.08101463524619665 \n",
      "Valid Loss:  4.8307732281543325\n",
      "--------------------------------------Epoch 106 ------------------------------\n",
      "\n",
      "Training Loss:  0.07976940749454606 \n",
      "Valid Loss:  3.588355336519763\n",
      "--------------------------------------Epoch 107 ------------------------------\n",
      "\n",
      "Training Loss:  0.07496614365543679 \n",
      "Valid Loss:  5.379967599482559\n",
      "--------------------------------------Epoch 108 ------------------------------\n",
      "\n",
      "Training Loss:  0.07888695518959835 \n",
      "Valid Loss:  2.0263069145032557\n",
      "--------------------------------------Epoch 109 ------------------------------\n",
      "\n",
      "Training Loss:  0.0965838032292758 \n",
      "Valid Loss:  2.237593154849678\n",
      "--------------------------------------Epoch 110 ------------------------------\n",
      "\n",
      "Training Loss:  0.08335520150867963 \n",
      "Valid Loss:  0.5669783712003647\n",
      "--------------------------------------Epoch 111 ------------------------------\n",
      "\n",
      "Training Loss:  0.0926122292864227 \n",
      "Valid Loss:  2.005277506674172\n",
      "--------------------------------------Epoch 112 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.07975173033982286 \n",
      "Valid Loss:  10.87323986043289\n",
      "--------------------------------------Epoch 113 ------------------------------\n",
      "\n",
      "Training Loss:  0.07397109978790217 \n",
      "Valid Loss:  4.299947086549087\n",
      "--------------------------------------Epoch 114 ------------------------------\n",
      "\n",
      "Training Loss:  0.07448885664955512 \n",
      "Valid Loss:  1.8712277049784927\n",
      "--------------------------------------Epoch 115 ------------------------------\n",
      "\n",
      "Training Loss:  0.08283977975839599 \n",
      "Valid Loss:  8.846253092997227\n",
      "--------------------------------------Epoch 116 ------------------------------\n",
      "\n",
      "Training Loss:  0.0969014537132597 \n",
      "Valid Loss:  22.08781914845623\n",
      "--------------------------------------Epoch 117 ------------------------------\n",
      "\n",
      "Training Loss:  0.08153095563749027 \n",
      "Valid Loss:  11.933714428738844\n",
      "--------------------------------------Epoch 118 ------------------------------\n",
      "\n",
      "Training Loss:  0.08155259430621378 \n",
      "Valid Loss:  8.934665858932215\n",
      "--------------------------------------Epoch 119 ------------------------------\n",
      "\n",
      "Training Loss:  0.08812306183406732 \n",
      "Valid Loss:  19.42605954928892\n",
      "--------------------------------------Epoch 120 ------------------------------\n",
      "\n",
      "Training Loss:  0.08723280730135931 \n",
      "Valid Loss:  10.15146000993092\n",
      "--------------------------------------Epoch 121 ------------------------------\n",
      "\n",
      "Training Loss:  0.08348234151679369 \n",
      "Valid Loss:  6.914685855789367\n",
      "--------------------------------------Epoch 122 ------------------------------\n",
      "\n",
      "Training Loss:  0.07930130761837217 \n",
      "Valid Loss:  2.807389431909732\n",
      "--------------------------------------Epoch 123 ------------------------------\n",
      "\n",
      "Training Loss:  0.07965415568817369 \n",
      "Valid Loss:  3.1521203309383847\n",
      "--------------------------------------Epoch 124 ------------------------------\n",
      "\n",
      "Training Loss:  0.0755573920763588 \n",
      "Valid Loss:  3.906559982384421\n",
      "--------------------------------------Epoch 125 ------------------------------\n",
      "\n",
      "Training Loss:  0.07319754593826888 \n",
      "Valid Loss:  3.13750648189548\n",
      "--------------------------------------Epoch 126 ------------------------------\n",
      "\n",
      "Training Loss:  0.08654851187121657 \n",
      "Valid Loss:  8.240652393631278\n",
      "--------------------------------------Epoch 127 ------------------------------\n",
      "\n",
      "Training Loss:  0.07645685383834004 \n",
      "Valid Loss:  5.0917418713082085\n",
      "--------------------------------------Epoch 128 ------------------------------\n",
      "\n",
      "Training Loss:  0.10224938621376803 \n",
      "Valid Loss:  2.8871398423606114\n",
      "--------------------------------------Epoch 129 ------------------------------\n",
      "\n",
      "Training Loss:  0.08016271102776182 \n",
      "Valid Loss:  1.7898678490540345\n",
      "--------------------------------------Epoch 130 ------------------------------\n",
      "\n",
      "Training Loss:  0.07809770129998411 \n",
      "Valid Loss:  4.593588236059566\n",
      "--------------------------------------Epoch 131 ------------------------------\n",
      "\n",
      "Training Loss:  0.07419251336675435 \n",
      "Valid Loss:  5.744250459177513\n",
      "--------------------------------------Epoch 132 ------------------------------\n",
      "\n",
      "Training Loss:  0.07514353211836543 \n",
      "Valid Loss:  8.289828419009616\n",
      "--------------------------------------Epoch 133 ------------------------------\n",
      "\n",
      "Training Loss:  0.0781207552321491 \n",
      "Valid Loss:  5.845461929768459\n",
      "--------------------------------------Epoch 134 ------------------------------\n",
      "\n",
      "Training Loss:  0.07685207507606714 \n",
      "Valid Loss:  8.971927010262439\n",
      "--------------------------------------Epoch 135 ------------------------------\n",
      "\n",
      "Training Loss:  0.07458921037916814 \n",
      "Valid Loss:  7.423649922668866\n",
      "--------------------------------------Epoch 136 ------------------------------\n",
      "\n",
      "Training Loss:  0.08108552673647287 \n",
      "Valid Loss:  9.893361040853875\n",
      "--------------------------------------Epoch 137 ------------------------------\n",
      "\n",
      "Training Loss:  0.0773947632911194 \n",
      "Valid Loss:  20.2942748968663\n",
      "--------------------------------------Epoch 138 ------------------------------\n",
      "\n",
      "Training Loss:  0.09330056443839069 \n",
      "Valid Loss:  23.646110165626943\n",
      "--------------------------------------Epoch 139 ------------------------------\n",
      "\n",
      "Training Loss:  0.11586759922513527 \n",
      "Valid Loss:  30.17604937294192\n",
      "--------------------------------------Epoch 140 ------------------------------\n",
      "\n",
      "Training Loss:  0.0885449813540874 \n",
      "Valid Loss:  14.207117594802924\n",
      "--------------------------------------Epoch 141 ------------------------------\n",
      "\n",
      "Training Loss:  0.08244969699429094 \n",
      "Valid Loss:  11.432375996434557\n",
      "--------------------------------------Epoch 142 ------------------------------\n",
      "\n",
      "Training Loss:  0.12189565799203735 \n",
      "Valid Loss:  10.425460781241332\n",
      "--------------------------------------Epoch 143 ------------------------------\n",
      "\n",
      "Training Loss:  0.10120186667180313 \n",
      "Valid Loss:  13.72637491750607\n",
      "--------------------------------------Epoch 144 ------------------------------\n",
      "\n",
      "Training Loss:  0.08314464917673856 \n",
      "Valid Loss:  14.836324858801834\n",
      "--------------------------------------Epoch 145 ------------------------------\n",
      "\n",
      "Training Loss:  0.07694316203188956 \n",
      "Valid Loss:  12.34809484543262\n",
      "--------------------------------------Epoch 146 ------------------------------\n",
      "\n",
      "Training Loss:  0.09404728531984946 \n",
      "Valid Loss:  27.05850950399862\n",
      "--------------------------------------Epoch 147 ------------------------------\n",
      "\n",
      "Training Loss:  0.08598704544336358 \n",
      "Valid Loss:  15.569022991386882\n",
      "--------------------------------------Epoch 148 ------------------------------\n",
      "\n",
      "Training Loss:  0.07836735228878823 \n",
      "Valid Loss:  14.965985157257856\n",
      "--------------------------------------Epoch 149 ------------------------------\n",
      "\n",
      "Training Loss:  0.07702048003442834 \n",
      "Valid Loss:  12.110182048058867\n",
      "--------------------------------------Epoch 150 ------------------------------\n",
      "\n",
      "Training Loss:  0.07684659492133597 \n",
      "Valid Loss:  12.859302993616218\n",
      "--------------------------------------Epoch 151 ------------------------------\n",
      "\n",
      "Training Loss:  0.09374494633608293 \n",
      "Valid Loss:  14.456118554311589\n",
      "--------------------------------------Epoch 152 ------------------------------\n",
      "\n",
      "Training Loss:  0.08477276788233364 \n",
      "Valid Loss:  7.489510845830936\n",
      "--------------------------------------Epoch 153 ------------------------------\n",
      "\n",
      "Training Loss:  0.10755261938278268 \n",
      "Valid Loss:  7.793673735311722\n",
      "--------------------------------------Epoch 154 ------------------------------\n",
      "\n",
      "Training Loss:  0.10122311262237771 \n",
      "Valid Loss:  1.7235151848756716\n",
      "--------------------------------------Epoch 155 ------------------------------\n",
      "\n",
      "Training Loss:  0.0792236016394546 \n",
      "Valid Loss:  1.476882149174168\n",
      "--------------------------------------Epoch 156 ------------------------------\n",
      "\n",
      "Training Loss:  0.08292558977200086 \n",
      "Valid Loss:  1.584866414365264\n",
      "--------------------------------------Epoch 157 ------------------------------\n",
      "\n",
      "Training Loss:  0.07849241933727465 \n",
      "Valid Loss:  5.6158565841324455\n",
      "--------------------------------------Epoch 158 ------------------------------\n",
      "\n",
      "Training Loss:  0.08474366692832014 \n",
      "Valid Loss:  4.534742060759877\n",
      "--------------------------------------Epoch 159 ------------------------------\n",
      "\n",
      "Training Loss:  0.08500079989298702 \n",
      "Valid Loss:  3.5234051806390783\n",
      "--------------------------------------Epoch 160 ------------------------------\n",
      "\n",
      "Training Loss:  0.08455820056206048 \n",
      "Valid Loss:  3.780818239266141\n",
      "--------------------------------------Epoch 161 ------------------------------\n",
      "\n",
      "Training Loss:  0.08283764276206156 \n",
      "Valid Loss:  3.350183424640218\n",
      "--------------------------------------Epoch 162 ------------------------------\n",
      "\n",
      "Training Loss:  0.08910406552619055 \n",
      "Valid Loss:  6.393471942858138\n",
      "--------------------------------------Epoch 163 ------------------------------\n",
      "\n",
      "Training Loss:  0.08911056230374596 \n",
      "Valid Loss:  4.866137971894296\n",
      "--------------------------------------Epoch 164 ------------------------------\n",
      "\n",
      "Training Loss:  0.10925215167763211 \n",
      "Valid Loss:  17.34203464338933\n",
      "--------------------------------------Epoch 165 ------------------------------\n",
      "\n",
      "Training Loss:  0.08164560050768768 \n",
      "Valid Loss:  7.287705673268749\n",
      "--------------------------------------Epoch 166 ------------------------------\n",
      "\n",
      "Training Loss:  0.07711676286119866 \n",
      "Valid Loss:  17.94178768459704\n",
      "--------------------------------------Epoch 167 ------------------------------\n",
      "\n",
      "Training Loss:  0.09953950884192056 \n",
      "Valid Loss:  17.302932908682553\n",
      "--------------------------------------Epoch 168 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.10042178207384245 \n",
      "Valid Loss:  11.420873003195847\n",
      "--------------------------------------Epoch 169 ------------------------------\n",
      "\n",
      "Training Loss:  0.08857589160361348 \n",
      "Valid Loss:  10.342682843089051\n",
      "--------------------------------------Epoch 170 ------------------------------\n",
      "\n",
      "Training Loss:  0.08554379330021362 \n",
      "Valid Loss:  9.791686405388363\n",
      "--------------------------------------Epoch 171 ------------------------------\n",
      "\n",
      "Training Loss:  0.0926388117293302 \n",
      "Valid Loss:  30.458761430132576\n",
      "--------------------------------------Epoch 172 ------------------------------\n",
      "\n",
      "Training Loss:  0.0961280720208069 \n",
      "Valid Loss:  30.62764961744048\n",
      "--------------------------------------Epoch 173 ------------------------------\n",
      "\n",
      "Training Loss:  0.12676627713783498 \n",
      "Valid Loss:  10748.466238518993\n",
      "--------------------------------------Epoch 174 ------------------------------\n",
      "\n",
      "Training Loss:  0.10059262854154977 \n",
      "Valid Loss:  19.5196080429321\n",
      "--------------------------------------Epoch 175 ------------------------------\n",
      "\n",
      "Training Loss:  0.0864589621766854 \n",
      "Valid Loss:  12.683319237096796\n",
      "--------------------------------------Epoch 176 ------------------------------\n",
      "\n",
      "Training Loss:  0.08428110128790534 \n",
      "Valid Loss:  14.114866626508954\n",
      "--------------------------------------Epoch 177 ------------------------------\n",
      "\n",
      "Training Loss:  0.08064163035140087 \n",
      "Valid Loss:  14.944105852361064\n",
      "--------------------------------------Epoch 178 ------------------------------\n",
      "\n",
      "Training Loss:  0.0841914377559102 \n",
      "Valid Loss:  12.21321429897143\n",
      "--------------------------------------Epoch 179 ------------------------------\n",
      "\n",
      "Training Loss:  0.09297455105358925 \n",
      "Valid Loss:  14.090075448796918\n",
      "--------------------------------------Epoch 180 ------------------------------\n",
      "\n",
      "Training Loss:  0.10846354385805908 \n",
      "Valid Loss:  69.83285719575876\n",
      "--------------------------------------Epoch 181 ------------------------------\n",
      "\n",
      "Training Loss:  0.1319266640097475 \n",
      "Valid Loss:  32.034539677219584\n",
      "--------------------------------------Epoch 182 ------------------------------\n",
      "\n",
      "Training Loss:  0.11928466666936625 \n",
      "Valid Loss:  145.65543322255394\n",
      "--------------------------------------Epoch 183 ------------------------------\n",
      "\n",
      "Training Loss:  0.09846303744353203 \n",
      "Valid Loss:  19.7288589294529\n",
      "--------------------------------------Epoch 184 ------------------------------\n",
      "\n",
      "Training Loss:  0.09832987356072803 \n",
      "Valid Loss:  23.64472400189883\n",
      "--------------------------------------Epoch 185 ------------------------------\n",
      "\n",
      "Training Loss:  0.09078149302205595 \n",
      "Valid Loss:  28.359838932434666\n",
      "--------------------------------------Epoch 186 ------------------------------\n",
      "\n",
      "Training Loss:  0.10607466286439626 \n",
      "Valid Loss:  31.164773383921094\n",
      "--------------------------------------Epoch 187 ------------------------------\n",
      "\n",
      "Training Loss:  0.09598932707434181 \n",
      "Valid Loss:  20.300035290598252\n",
      "--------------------------------------Epoch 188 ------------------------------\n",
      "\n",
      "Training Loss:  0.09382116372395993 \n",
      "Valid Loss:  18.041412481162155\n",
      "--------------------------------------Epoch 189 ------------------------------\n",
      "\n",
      "Training Loss:  0.08837757278740226 \n",
      "Valid Loss:  35.78116149006811\n",
      "--------------------------------------Epoch 190 ------------------------------\n",
      "\n",
      "Training Loss:  0.08628831590898148 \n",
      "Valid Loss:  12.65857465917522\n",
      "--------------------------------------Epoch 191 ------------------------------\n",
      "\n",
      "Training Loss:  0.08396508705073992 \n",
      "Valid Loss:  13.442365956470212\n",
      "--------------------------------------Epoch 192 ------------------------------\n",
      "\n",
      "Training Loss:  0.08836417973676015 \n",
      "Valid Loss:  14.757411529864338\n",
      "--------------------------------------Epoch 193 ------------------------------\n",
      "\n",
      "Training Loss:  0.09047089594978819 \n",
      "Valid Loss:  12.749604041237372\n",
      "--------------------------------------Epoch 194 ------------------------------\n",
      "\n",
      "Training Loss:  0.08767858958882369 \n",
      "Valid Loss:  13.943918883215499\n",
      "--------------------------------------Epoch 195 ------------------------------\n",
      "\n",
      "Training Loss:  0.10038002707488076 \n",
      "Valid Loss:  5.39848627236063\n",
      "--------------------------------------Epoch 196 ------------------------------\n",
      "\n",
      "Training Loss:  0.08502689978503598 \n",
      "Valid Loss:  10.92210762177745\n",
      "--------------------------------------Epoch 197 ------------------------------\n",
      "\n",
      "Training Loss:  0.08838339444143888 \n",
      "Valid Loss:  7.046995506820729\n",
      "--------------------------------------Epoch 198 ------------------------------\n",
      "\n",
      "Training Loss:  0.08280214046286129 \n",
      "Valid Loss:  6.697872058828413\n",
      "--------------------------------------Epoch 199 ------------------------------\n",
      "\n",
      "Training Loss:  0.0809120937267671 \n",
      "Valid Loss:  6.018051409236439\n",
      "--------------------------------------Epoch 200 ------------------------------\n",
      "\n",
      "Training Loss:  0.13010732492845606 \n",
      "Valid Loss:  7.975829326653663\n",
      "--------------------------------------Epoch 201 ------------------------------\n",
      "\n",
      "Training Loss:  0.0924777374742365 \n",
      "Valid Loss:  3.37838842390032\n",
      "--------------------------------------Epoch 202 ------------------------------\n",
      "\n",
      "Training Loss:  0.08367041470790104 \n",
      "Valid Loss:  3.8157622140671865\n",
      "--------------------------------------Epoch 203 ------------------------------\n",
      "\n",
      "Training Loss:  0.08098178781584948 \n",
      "Valid Loss:  4.487767658255008\n",
      "--------------------------------------Epoch 204 ------------------------------\n",
      "\n",
      "Training Loss:  0.08008485736640983 \n",
      "Valid Loss:  5.209846140143873\n",
      "--------------------------------------Epoch 205 ------------------------------\n",
      "\n",
      "Training Loss:  0.0789413259373809 \n",
      "Valid Loss:  5.221774008543834\n",
      "--------------------------------------Epoch 206 ------------------------------\n",
      "\n",
      "Training Loss:  0.07832581371707656 \n",
      "Valid Loss:  4.575237493578922\n",
      "--------------------------------------Epoch 207 ------------------------------\n",
      "\n",
      "Training Loss:  0.0904936969813901 \n",
      "Valid Loss:  9.243744491720488\n",
      "--------------------------------------Epoch 208 ------------------------------\n",
      "\n",
      "Training Loss:  0.11106655168047992 \n",
      "Valid Loss:  1.0933232700137079\n",
      "--------------------------------------Epoch 209 ------------------------------\n",
      "\n",
      "Training Loss:  0.09050073933958575 \n",
      "Valid Loss:  1.6344353320590086\n",
      "--------------------------------------Epoch 210 ------------------------------\n",
      "\n",
      "Training Loss:  0.086013467159239 \n",
      "Valid Loss:  2.390396011439935\n",
      "--------------------------------------Epoch 211 ------------------------------\n",
      "\n",
      "Training Loss:  0.08249315072844238 \n",
      "Valid Loss:  2.233840366107508\n",
      "--------------------------------------Epoch 212 ------------------------------\n",
      "\n",
      "Training Loss:  0.08024077351950203 \n",
      "Valid Loss:  1.5247534152771245\n",
      "--------------------------------------Epoch 213 ------------------------------\n",
      "\n",
      "Training Loss:  0.07944439463401805 \n",
      "Valid Loss:  1.9458261877162362\n",
      "--------------------------------------Epoch 214 ------------------------------\n",
      "\n",
      "Training Loss:  0.08664577565913736 \n",
      "Valid Loss:  1.2644650795682701\n",
      "--------------------------------------Epoch 215 ------------------------------\n",
      "\n",
      "Training Loss:  0.0822352781481028 \n",
      "Valid Loss:  1.620125749695217\n",
      "--------------------------------------Epoch 216 ------------------------------\n",
      "\n",
      "Training Loss:  0.1161569642026844 \n",
      "Valid Loss:  14.559729645585815\n",
      "--------------------------------------Epoch 217 ------------------------------\n",
      "\n",
      "Training Loss:  0.10271416412530329 \n",
      "Valid Loss:  6.2589983947355625\n",
      "--------------------------------------Epoch 218 ------------------------------\n",
      "\n",
      "Training Loss:  0.09346635150224906 \n",
      "Valid Loss:  4.923711594791608\n",
      "--------------------------------------Epoch 219 ------------------------------\n",
      "\n",
      "Training Loss:  0.0843052061589778 \n",
      "Valid Loss:  3.879941591051335\n",
      "--------------------------------------Epoch 220 ------------------------------\n",
      "\n",
      "Training Loss:  0.07919820153772501 \n",
      "Valid Loss:  3.503423244954994\n",
      "--------------------------------------Epoch 221 ------------------------------\n",
      "\n",
      "Training Loss:  0.07716612953693612 \n",
      "Valid Loss:  3.4032559588641558\n",
      "--------------------------------------Epoch 222 ------------------------------\n",
      "\n",
      "Training Loss:  0.11276038114039165 \n",
      "Valid Loss:  3.6479458150107784\n",
      "--------------------------------------Epoch 223 ------------------------------\n",
      "\n",
      "Training Loss:  0.08134234579531373 \n",
      "Valid Loss:  2.5543190837145593\n",
      "--------------------------------------Epoch 224 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.09144474337161645 \n",
      "Valid Loss:  6.146316439182519\n",
      "--------------------------------------Epoch 225 ------------------------------\n",
      "\n",
      "Training Loss:  0.08437222401526628 \n",
      "Valid Loss:  1.385988454859186\n",
      "--------------------------------------Epoch 226 ------------------------------\n",
      "\n",
      "Training Loss:  0.08565764067513298 \n",
      "Valid Loss:  2.775992495157875\n",
      "--------------------------------------Epoch 227 ------------------------------\n",
      "\n",
      "Training Loss:  0.08273583024607507 \n",
      "Valid Loss:  2.24302365089188\n",
      "--------------------------------------Epoch 228 ------------------------------\n",
      "\n",
      "Training Loss:  0.07981374551455818 \n",
      "Valid Loss:  5.675505206715747\n",
      "--------------------------------------Epoch 229 ------------------------------\n",
      "\n",
      "Training Loss:  0.07756669320246301 \n",
      "Valid Loss:  3.0807737518403933\n",
      "--------------------------------------Epoch 230 ------------------------------\n",
      "\n",
      "Training Loss:  0.08109826336402357 \n",
      "Valid Loss:  7.491636056697779\n",
      "--------------------------------------Epoch 231 ------------------------------\n",
      "\n",
      "Training Loss:  0.10385176995164205 \n",
      "Valid Loss:  8.952749443612806\n",
      "--------------------------------------Epoch 232 ------------------------------\n",
      "\n",
      "Training Loss:  0.08404386722192464 \n",
      "Valid Loss:  7.002203517069164\n",
      "--------------------------------------Epoch 233 ------------------------------\n",
      "\n",
      "Training Loss:  0.07841316083153524 \n",
      "Valid Loss:  5.614192374784515\n",
      "--------------------------------------Epoch 234 ------------------------------\n",
      "\n",
      "Training Loss:  0.11348696170422348 \n",
      "Valid Loss:  4.639437971807348\n",
      "--------------------------------------Epoch 235 ------------------------------\n",
      "\n",
      "Training Loss:  0.08826647988381756 \n",
      "Valid Loss:  4.434648033428922\n",
      "--------------------------------------Epoch 236 ------------------------------\n",
      "\n",
      "Training Loss:  0.08324972509740863 \n",
      "Valid Loss:  4.580995410959792\n",
      "--------------------------------------Epoch 237 ------------------------------\n",
      "\n",
      "Training Loss:  0.09672572909476149 \n",
      "Valid Loss:  4.049027746366496\n",
      "--------------------------------------Epoch 238 ------------------------------\n",
      "\n",
      "Training Loss:  0.08515098209041269 \n",
      "Valid Loss:  4.074001592365192\n",
      "--------------------------------------Epoch 239 ------------------------------\n",
      "\n",
      "Training Loss:  0.08288131353212286 \n",
      "Valid Loss:  7.009734418170015\n",
      "--------------------------------------Epoch 240 ------------------------------\n",
      "\n",
      "Training Loss:  0.07966411525542094 \n",
      "Valid Loss:  3.2300355514767745\n",
      "--------------------------------------Epoch 241 ------------------------------\n",
      "\n",
      "Training Loss:  0.07989089319638135 \n",
      "Valid Loss:  3.8744935193422654\n",
      "--------------------------------------Epoch 242 ------------------------------\n",
      "\n",
      "Training Loss:  0.07788268046105169 \n",
      "Valid Loss:  3.6990103087029707\n",
      "--------------------------------------Epoch 243 ------------------------------\n",
      "\n",
      "Training Loss:  0.08296500825630791 \n",
      "Valid Loss:  4.255873109870529\n",
      "--------------------------------------Epoch 244 ------------------------------\n",
      "\n",
      "Training Loss:  0.08398334687310276 \n",
      "Valid Loss:  3.939531209499248\n",
      "--------------------------------------Epoch 245 ------------------------------\n",
      "\n",
      "Training Loss:  0.10529015682505684 \n",
      "Valid Loss:  3.448013974734219\n",
      "--------------------------------------Epoch 246 ------------------------------\n",
      "\n",
      "Training Loss:  0.08103481195688864 \n",
      "Valid Loss:  3.481485242057359\n",
      "--------------------------------------Epoch 247 ------------------------------\n",
      "\n",
      "Training Loss:  0.0833167091525729 \n",
      "Valid Loss:  3.553233609435384\n",
      "--------------------------------------Epoch 248 ------------------------------\n",
      "\n",
      "Training Loss:  0.08215591589163347 \n",
      "Valid Loss:  3.6284341464233694\n",
      "--------------------------------------Epoch 249 ------------------------------\n",
      "\n",
      "Training Loss:  0.0828625216158876 \n",
      "Valid Loss:  3.6831042997155445\n",
      "--------------------------------------Epoch 250 ------------------------------\n",
      "\n",
      "Training Loss:  0.09586264112511038 \n",
      "Valid Loss:  4.0333788836204185\n",
      "--------------------------------------Epoch 251 ------------------------------\n",
      "\n",
      "Training Loss:  0.08499713006093142 \n",
      "Valid Loss:  3.4327076064049447\n",
      "--------------------------------------Epoch 252 ------------------------------\n",
      "\n",
      "Training Loss:  0.08086672724608691 \n",
      "Valid Loss:  3.045611726329498\n",
      "--------------------------------------Epoch 253 ------------------------------\n",
      "\n",
      "Training Loss:  0.08084507799303592 \n",
      "Valid Loss:  2.8310899756574948\n",
      "--------------------------------------Epoch 254 ------------------------------\n",
      "\n",
      "Training Loss:  0.13330026933407996 \n",
      "Valid Loss:  2.834361690447327\n",
      "--------------------------------------Epoch 255 ------------------------------\n",
      "\n",
      "Training Loss:  0.15108748071466846 \n",
      "Valid Loss:  3.4409629293911586\n",
      "--------------------------------------Epoch 256 ------------------------------\n",
      "\n",
      "Training Loss:  0.09281446169996174 \n",
      "Valid Loss:  3.283339137919547\n",
      "--------------------------------------Epoch 257 ------------------------------\n",
      "\n",
      "Training Loss:  0.08713120919821572 \n",
      "Valid Loss:  2.1536470808783754\n",
      "--------------------------------------Epoch 258 ------------------------------\n",
      "\n",
      "Training Loss:  0.11401936385960178 \n",
      "Valid Loss:  2.0869181298862762\n",
      "--------------------------------------Epoch 259 ------------------------------\n",
      "\n",
      "Training Loss:  0.08419941406388001 \n",
      "Valid Loss:  1.6286516057665967\n",
      "--------------------------------------Epoch 260 ------------------------------\n",
      "\n",
      "Training Loss:  0.10231108778807703 \n",
      "Valid Loss:  1.91088880004018\n",
      "--------------------------------------Epoch 261 ------------------------------\n",
      "\n",
      "Training Loss:  0.0799262868906376 \n",
      "Valid Loss:  1.5462350139576353\n",
      "--------------------------------------Epoch 262 ------------------------------\n",
      "\n",
      "Training Loss:  0.07662747662082083 \n",
      "Valid Loss:  2.0756526125922297\n",
      "--------------------------------------Epoch 263 ------------------------------\n",
      "\n",
      "Training Loss:  0.07501716948909665 \n",
      "Valid Loss:  2.1419766072436137\n",
      "--------------------------------------Epoch 264 ------------------------------\n",
      "\n",
      "Training Loss:  0.07827990624654103 \n",
      "Valid Loss:  2.84093636088636\n",
      "--------------------------------------Epoch 265 ------------------------------\n",
      "\n",
      "Training Loss:  0.07844625295009483 \n",
      "Valid Loss:  1.7383152783820444\n",
      "--------------------------------------Epoch 266 ------------------------------\n",
      "\n",
      "Training Loss:  0.09141744029896254 \n",
      "Valid Loss:  1.0417815334339928\n",
      "--------------------------------------Epoch 267 ------------------------------\n",
      "\n",
      "Training Loss:  0.09236896182123777 \n",
      "Valid Loss:  0.9397845818845917\n",
      "--------------------------------------Epoch 268 ------------------------------\n",
      "\n",
      "Training Loss:  0.1290012002509455 \n",
      "Valid Loss:  0.5580320899010882\n",
      "--------------------------------------Epoch 269 ------------------------------\n",
      "\n",
      "Training Loss:  0.0919477515862148 \n",
      "Valid Loss:  0.7390239008058478\n",
      "--------------------------------------Epoch 270 ------------------------------\n",
      "\n",
      "Training Loss:  0.09019579287055197 \n",
      "Valid Loss:  1.0499213955799833\n",
      "--------------------------------------Epoch 271 ------------------------------\n",
      "\n",
      "Training Loss:  0.08828721955494322 \n",
      "Valid Loss:  2.215084209513906\n",
      "--------------------------------------Epoch 272 ------------------------------\n",
      "\n",
      "Training Loss:  0.08806347132531255 \n",
      "Valid Loss:  2.5467848688908474\n",
      "--------------------------------------Epoch 273 ------------------------------\n",
      "\n",
      "Training Loss:  0.08242225256295498 \n",
      "Valid Loss:  2.8499096385393226\n",
      "--------------------------------------Epoch 274 ------------------------------\n",
      "\n",
      "Training Loss:  0.10165651455160028 \n",
      "Valid Loss:  2.7277847641529394\n",
      "--------------------------------------Epoch 275 ------------------------------\n",
      "\n",
      "Training Loss:  0.08109512017823639 \n",
      "Valid Loss:  2.3329934230264677\n",
      "--------------------------------------Epoch 276 ------------------------------\n",
      "\n",
      "Training Loss:  0.08536546624348615 \n",
      "Valid Loss:  1.3486346600662582\n",
      "--------------------------------------Epoch 277 ------------------------------\n",
      "\n",
      "Training Loss:  0.08812468016349212 \n",
      "Valid Loss:  1.0477607948656316\n",
      "--------------------------------------Epoch 278 ------------------------------\n",
      "\n",
      "Training Loss:  0.09919324686620871 \n",
      "Valid Loss:  0.9001087296157625\n",
      "--------------------------------------Epoch 279 ------------------------------\n",
      "\n",
      "Training Loss:  0.08284778288654207 \n",
      "Valid Loss:  1.0564234175717915\n",
      "--------------------------------------Epoch 280 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08686957664014949 \n",
      "Valid Loss:  2.930221371852567\n",
      "--------------------------------------Epoch 281 ------------------------------\n",
      "\n",
      "Training Loss:  0.0835975637943845 \n",
      "Valid Loss:  3.9308418168319146\n",
      "--------------------------------------Epoch 282 ------------------------------\n",
      "\n",
      "Training Loss:  0.12612207636271378 \n",
      "Valid Loss:  3.765924049439828\n",
      "--------------------------------------Epoch 283 ------------------------------\n",
      "\n",
      "Training Loss:  0.07950887380555659 \n",
      "Valid Loss:  3.903018878318917\n",
      "--------------------------------------Epoch 284 ------------------------------\n",
      "\n",
      "Training Loss:  0.0843422370182007 \n",
      "Valid Loss:  1.2482705070406914\n",
      "--------------------------------------Epoch 285 ------------------------------\n",
      "\n",
      "Training Loss:  0.08512875529028163 \n",
      "Valid Loss:  5.3869967345703555\n",
      "--------------------------------------Epoch 286 ------------------------------\n",
      "\n",
      "Training Loss:  0.08024151306020233 \n",
      "Valid Loss:  2.26097021908028\n",
      "--------------------------------------Epoch 287 ------------------------------\n",
      "\n",
      "Training Loss:  0.08867867786547709 \n",
      "Valid Loss:  1.9745792689699677\n",
      "--------------------------------------Epoch 288 ------------------------------\n",
      "\n",
      "Training Loss:  0.09731153858305505 \n",
      "Valid Loss:  3.496382813293896\n",
      "--------------------------------------Epoch 289 ------------------------------\n",
      "\n",
      "Training Loss:  0.10098532866721753 \n",
      "Valid Loss:  4.57954347904674\n",
      "--------------------------------------Epoch 290 ------------------------------\n",
      "\n",
      "Training Loss:  0.08174138346359637 \n",
      "Valid Loss:  2.9131749514110523\n",
      "--------------------------------------Epoch 291 ------------------------------\n",
      "\n",
      "Training Loss:  0.07838417707955557 \n",
      "Valid Loss:  2.3675788542338294\n",
      "--------------------------------------Epoch 292 ------------------------------\n",
      "\n",
      "Training Loss:  0.08660856220441658 \n",
      "Valid Loss:  2.0816893100089975\n",
      "--------------------------------------Epoch 293 ------------------------------\n",
      "\n",
      "Training Loss:  0.07838659502221422 \n",
      "Valid Loss:  2.042050608770485\n",
      "--------------------------------------Epoch 294 ------------------------------\n",
      "\n",
      "Training Loss:  0.0823028031575999 \n",
      "Valid Loss:  2.884186606849511\n",
      "--------------------------------------Epoch 295 ------------------------------\n",
      "\n",
      "Training Loss:  0.08110284947141656 \n",
      "Valid Loss:  3.4744639355330076\n",
      "--------------------------------------Epoch 296 ------------------------------\n",
      "\n",
      "Training Loss:  0.08731140611772514 \n",
      "Valid Loss:  1.9174004980435169\n",
      "--------------------------------------Epoch 297 ------------------------------\n",
      "\n",
      "Training Loss:  0.13548727745759093 \n",
      "Valid Loss:  5.405618333859155\n",
      "--------------------------------------Epoch 298 ------------------------------\n",
      "\n",
      "Training Loss:  0.0795296921046809 \n",
      "Valid Loss:  6.309908004413375\n",
      "--------------------------------------Epoch 299 ------------------------------\n",
      "\n",
      "Training Loss:  0.07729203149245832 \n",
      "Valid Loss:  6.286032664712711\n",
      "--------------------------------------Epoch 300 ------------------------------\n",
      "\n",
      "Training Loss:  0.08320700034767874 \n",
      "Valid Loss:  5.377523084572532\n",
      "--------------------------------------Epoch 301 ------------------------------\n",
      "\n",
      "Training Loss:  0.13183937758694553 \n",
      "Valid Loss:  11.777882570143852\n",
      "--------------------------------------Epoch 302 ------------------------------\n",
      "\n",
      "Training Loss:  0.09524210663973086 \n",
      "Valid Loss:  4.707091801918711\n",
      "--------------------------------------Epoch 303 ------------------------------\n",
      "\n",
      "Training Loss:  0.08707706387234948 \n",
      "Valid Loss:  4.122975704218434\n",
      "--------------------------------------Epoch 304 ------------------------------\n",
      "\n",
      "Training Loss:  0.07925082481661315 \n",
      "Valid Loss:  4.143691152943371\n",
      "--------------------------------------Epoch 305 ------------------------------\n",
      "\n",
      "Training Loss:  0.07618189218157691 \n",
      "Valid Loss:  3.692417560287349\n",
      "--------------------------------------Epoch 306 ------------------------------\n",
      "\n",
      "Training Loss:  0.07478198107619922 \n",
      "Valid Loss:  2.675502717138567\n",
      "--------------------------------------Epoch 307 ------------------------------\n",
      "\n",
      "Training Loss:  0.07363933606320863 \n",
      "Valid Loss:  2.5381568037822264\n",
      "--------------------------------------Epoch 308 ------------------------------\n",
      "\n",
      "Training Loss:  0.07760683983805414 \n",
      "Valid Loss:  5.552437226620971\n",
      "--------------------------------------Epoch 309 ------------------------------\n",
      "\n",
      "Training Loss:  0.10099573276599016 \n",
      "Valid Loss:  3.1678017434839454\n",
      "--------------------------------------Epoch 310 ------------------------------\n",
      "\n",
      "Training Loss:  0.0972544260472289 \n",
      "Valid Loss:  5.769953759039179\n",
      "--------------------------------------Epoch 311 ------------------------------\n",
      "\n",
      "Training Loss:  0.08705332275531147 \n",
      "Valid Loss:  3.1684676231380293\n",
      "--------------------------------------Epoch 312 ------------------------------\n",
      "\n",
      "Training Loss:  0.09309099881390667 \n",
      "Valid Loss:  8.948149985899212\n",
      "--------------------------------------Epoch 313 ------------------------------\n",
      "\n",
      "Training Loss:  0.08699891751834678 \n",
      "Valid Loss:  8.784986597480682\n",
      "--------------------------------------Epoch 314 ------------------------------\n",
      "\n",
      "Training Loss:  0.08653170695794045 \n",
      "Valid Loss:  4.895262798807449\n",
      "--------------------------------------Epoch 315 ------------------------------\n",
      "\n",
      "Training Loss:  0.08014608065574032 \n",
      "Valid Loss:  5.887650071936383\n",
      "--------------------------------------Epoch 316 ------------------------------\n",
      "\n",
      "Training Loss:  0.07829299535225301 \n",
      "Valid Loss:  5.341313996511697\n",
      "--------------------------------------Epoch 317 ------------------------------\n",
      "\n",
      "Training Loss:  0.07444549538781313 \n",
      "Valid Loss:  5.760803491981514\n",
      "--------------------------------------Epoch 318 ------------------------------\n",
      "\n",
      "Training Loss:  0.07399427788606437 \n",
      "Valid Loss:  2.741698753537492\n",
      "--------------------------------------Epoch 319 ------------------------------\n",
      "\n",
      "Training Loss:  0.0953895755109592 \n",
      "Valid Loss:  5.8831569174751746\n",
      "--------------------------------------Epoch 320 ------------------------------\n",
      "\n",
      "Training Loss:  0.13370849655142517 \n",
      "Valid Loss:  79.2504770182648\n",
      "--------------------------------------Epoch 321 ------------------------------\n",
      "\n",
      "Training Loss:  0.10012036642923244 \n",
      "Valid Loss:  17.132275207534203\n",
      "--------------------------------------Epoch 322 ------------------------------\n",
      "\n",
      "Training Loss:  0.08538502556958151 \n",
      "Valid Loss:  9.968579984540616\n",
      "--------------------------------------Epoch 323 ------------------------------\n",
      "\n",
      "Training Loss:  0.08570190411594941 \n",
      "Valid Loss:  11.48057398376194\n",
      "--------------------------------------Epoch 324 ------------------------------\n",
      "\n",
      "Training Loss:  0.08266263255778084 \n",
      "Valid Loss:  12.875802659355047\n",
      "--------------------------------------Epoch 325 ------------------------------\n",
      "\n",
      "Training Loss:  0.0771774994529463 \n",
      "Valid Loss:  12.308993045703488\n",
      "--------------------------------------Epoch 326 ------------------------------\n",
      "\n",
      "Training Loss:  0.07702206037388758 \n",
      "Valid Loss:  9.684366548351365\n",
      "--------------------------------------Epoch 327 ------------------------------\n",
      "\n",
      "Training Loss:  0.08790172962811828 \n",
      "Valid Loss:  9.658018838574835\n",
      "--------------------------------------Epoch 328 ------------------------------\n",
      "\n",
      "Training Loss:  0.0892943564285339 \n",
      "Valid Loss:  20.44324401576702\n",
      "--------------------------------------Epoch 329 ------------------------------\n",
      "\n",
      "Training Loss:  0.08057083576747187 \n",
      "Valid Loss:  8.436431288429604\n",
      "--------------------------------------Epoch 330 ------------------------------\n",
      "\n",
      "Training Loss:  0.07959790142700414 \n",
      "Valid Loss:  6.255655583815578\n",
      "--------------------------------------Epoch 331 ------------------------------\n",
      "\n",
      "Training Loss:  0.0771391277930916 \n",
      "Valid Loss:  5.602550584243982\n",
      "--------------------------------------Epoch 332 ------------------------------\n",
      "\n",
      "Training Loss:  0.07467059489715448 \n",
      "Valid Loss:  7.826122428852341\n",
      "--------------------------------------Epoch 333 ------------------------------\n",
      "\n",
      "Training Loss:  0.09140428063782796 \n",
      "Valid Loss:  7.7743970367243636\n",
      "--------------------------------------Epoch 334 ------------------------------\n",
      "\n",
      "Training Loss:  0.1184434200424142 \n",
      "Valid Loss:  15.19702959754237\n",
      "--------------------------------------Epoch 335 ------------------------------\n",
      "\n",
      "Training Loss:  0.09681512144857769 \n",
      "Valid Loss:  15.532649391468649\n",
      "--------------------------------------Epoch 336 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08960677847017774 \n",
      "Valid Loss:  10.257500842543298\n",
      "--------------------------------------Epoch 337 ------------------------------\n",
      "\n",
      "Training Loss:  0.07898449367836065 \n",
      "Valid Loss:  9.04324848097463\n",
      "--------------------------------------Epoch 338 ------------------------------\n",
      "\n",
      "Training Loss:  0.07619746700822576 \n",
      "Valid Loss:  8.647237065512089\n",
      "--------------------------------------Epoch 339 ------------------------------\n",
      "\n",
      "Training Loss:  0.07764502520924331 \n",
      "Valid Loss:  11.87651588771753\n",
      "--------------------------------------Epoch 340 ------------------------------\n",
      "\n",
      "Training Loss:  0.0779516448577245 \n",
      "Valid Loss:  10.057759336504452\n",
      "--------------------------------------Epoch 341 ------------------------------\n",
      "\n",
      "Training Loss:  0.12337418376874462 \n",
      "Valid Loss:  20.7650719817272\n",
      "--------------------------------------Epoch 342 ------------------------------\n",
      "\n",
      "Training Loss:  0.08166669296407425 \n",
      "Valid Loss:  13.899704250120179\n",
      "--------------------------------------Epoch 343 ------------------------------\n",
      "\n",
      "Training Loss:  0.10265600611537803 \n",
      "Valid Loss:  17.599270576900032\n",
      "--------------------------------------Epoch 344 ------------------------------\n",
      "\n",
      "Training Loss:  0.0798963208817422 \n",
      "Valid Loss:  16.61740635654304\n",
      "--------------------------------------Epoch 345 ------------------------------\n",
      "\n",
      "Training Loss:  0.08586738746630146 \n",
      "Valid Loss:  19.35505052587704\n",
      "--------------------------------------Epoch 346 ------------------------------\n",
      "\n",
      "Training Loss:  0.07636352962568545 \n",
      "Valid Loss:  15.75213725079708\n",
      "--------------------------------------Epoch 347 ------------------------------\n",
      "\n",
      "Training Loss:  0.07654758158429692 \n",
      "Valid Loss:  15.240782287735952\n",
      "--------------------------------------Epoch 348 ------------------------------\n",
      "\n",
      "Training Loss:  0.07717791922391165 \n",
      "Valid Loss:  17.602121765165514\n",
      "--------------------------------------Epoch 349 ------------------------------\n",
      "\n",
      "Training Loss:  0.08763455823097849 \n",
      "Valid Loss:  17.828136611575108\n",
      "--------------------------------------Epoch 350 ------------------------------\n",
      "\n",
      "Training Loss:  0.09848580051320246 \n",
      "Valid Loss:  15.918220805309756\n",
      "--------------------------------------Epoch 351 ------------------------------\n",
      "\n",
      "Training Loss:  0.08800514490139758 \n",
      "Valid Loss:  24.035886922797744\n",
      "--------------------------------------Epoch 352 ------------------------------\n",
      "\n",
      "Training Loss:  0.0782100472851677 \n",
      "Valid Loss:  13.722244814681433\n",
      "--------------------------------------Epoch 353 ------------------------------\n",
      "\n",
      "Training Loss:  0.073881786542078 \n",
      "Valid Loss:  15.209194837337828\n",
      "--------------------------------------Epoch 354 ------------------------------\n",
      "\n",
      "Training Loss:  0.08261168299135349 \n",
      "Valid Loss:  17.295799511940146\n",
      "--------------------------------------Epoch 355 ------------------------------\n",
      "\n",
      "Training Loss:  0.07512854117185462 \n",
      "Valid Loss:  20.950183464156524\n",
      "--------------------------------------Epoch 356 ------------------------------\n",
      "\n",
      "Training Loss:  0.10870345033883902 \n",
      "Valid Loss:  60.699083197732485\n",
      "--------------------------------------Epoch 357 ------------------------------\n",
      "\n",
      "Training Loss:  0.08250217255462132 \n",
      "Valid Loss:  14.80739688936317\n",
      "--------------------------------------Epoch 358 ------------------------------\n",
      "\n",
      "Training Loss:  0.0782509685581581 \n",
      "Valid Loss:  12.794605359909067\n",
      "--------------------------------------Epoch 359 ------------------------------\n",
      "\n",
      "Training Loss:  0.09153624777396656 \n",
      "Valid Loss:  17.376539529771577\n",
      "--------------------------------------Epoch 360 ------------------------------\n",
      "\n",
      "Training Loss:  0.07966216931138671 \n",
      "Valid Loss:  18.722178198051548\n",
      "--------------------------------------Epoch 361 ------------------------------\n",
      "\n",
      "Training Loss:  0.07763323422094848 \n",
      "Valid Loss:  18.675881740527156\n",
      "--------------------------------------Epoch 362 ------------------------------\n",
      "\n",
      "Training Loss:  0.07515074024655718 \n",
      "Valid Loss:  18.654112449297795\n",
      "--------------------------------------Epoch 363 ------------------------------\n",
      "\n",
      "Training Loss:  0.07446963141598689 \n",
      "Valid Loss:  16.720497119134833\n",
      "--------------------------------------Epoch 364 ------------------------------\n",
      "\n",
      "Training Loss:  0.07706572591751056 \n",
      "Valid Loss:  19.129668471023574\n",
      "--------------------------------------Epoch 365 ------------------------------\n",
      "\n",
      "Training Loss:  0.0754402411339827 \n",
      "Valid Loss:  17.073266815939544\n",
      "--------------------------------------Epoch 366 ------------------------------\n",
      "\n",
      "Training Loss:  0.07627162847862896 \n",
      "Valid Loss:  16.719022389082216\n",
      "--------------------------------------Epoch 367 ------------------------------\n",
      "\n",
      "Training Loss:  0.07557063053860559 \n",
      "Valid Loss:  18.974149359217098\n",
      "--------------------------------------Epoch 368 ------------------------------\n",
      "\n",
      "Training Loss:  0.08904046967859153 \n",
      "Valid Loss:  16.788447291857338\n",
      "--------------------------------------Epoch 369 ------------------------------\n",
      "\n",
      "Training Loss:  0.08499568033875984 \n",
      "Valid Loss:  15.352772211161005\n",
      "--------------------------------------Epoch 370 ------------------------------\n",
      "\n",
      "Training Loss:  0.0914619029345132 \n",
      "Valid Loss:  20.830517631324714\n",
      "--------------------------------------Epoch 371 ------------------------------\n",
      "\n",
      "Training Loss:  0.09447734949764236 \n",
      "Valid Loss:  16.018628363205405\n",
      "--------------------------------------Epoch 372 ------------------------------\n",
      "\n",
      "Training Loss:  0.07836229032383152 \n",
      "Valid Loss:  18.996619025214358\n",
      "--------------------------------------Epoch 373 ------------------------------\n",
      "\n",
      "Training Loss:  0.08426425759869906 \n",
      "Valid Loss:  25.382988155842924\n",
      "--------------------------------------Epoch 374 ------------------------------\n",
      "\n",
      "Training Loss:  0.08923982012553154 \n",
      "Valid Loss:  21.417899482548922\n",
      "--------------------------------------Epoch 375 ------------------------------\n",
      "\n",
      "Training Loss:  0.07864265495960245 \n",
      "Valid Loss:  17.0986598927991\n",
      "--------------------------------------Epoch 376 ------------------------------\n",
      "\n",
      "Training Loss:  0.09086048126587418 \n",
      "Valid Loss:  19.986704569995545\n",
      "--------------------------------------Epoch 377 ------------------------------\n",
      "\n",
      "Training Loss:  0.0834279596546012 \n",
      "Valid Loss:  17.279585493914688\n",
      "--------------------------------------Epoch 378 ------------------------------\n",
      "\n",
      "Training Loss:  0.07635994873341165 \n",
      "Valid Loss:  13.261204984113045\n",
      "--------------------------------------Epoch 379 ------------------------------\n",
      "\n",
      "Training Loss:  0.07321530022770485 \n",
      "Valid Loss:  13.010840142613056\n",
      "--------------------------------------Epoch 380 ------------------------------\n",
      "\n",
      "Training Loss:  0.0740213578134953 \n",
      "Valid Loss:  14.391230110106484\n",
      "--------------------------------------Epoch 381 ------------------------------\n",
      "\n",
      "Training Loss:  0.07309158919778304 \n",
      "Valid Loss:  11.620094176716417\n",
      "--------------------------------------Epoch 382 ------------------------------\n",
      "\n",
      "Training Loss:  0.09536224599581936 \n",
      "Valid Loss:  27.301740679548995\n",
      "--------------------------------------Epoch 383 ------------------------------\n",
      "\n",
      "Training Loss:  0.09493744842965912 \n",
      "Valid Loss:  16.79446606109637\n",
      "--------------------------------------Epoch 384 ------------------------------\n",
      "\n",
      "Training Loss:  0.08630436805415943 \n",
      "Valid Loss:  11.06735781792817\n",
      "--------------------------------------Epoch 385 ------------------------------\n",
      "\n",
      "Training Loss:  0.09914631145151753 \n",
      "Valid Loss:  15.522121949736581\n",
      "--------------------------------------Epoch 386 ------------------------------\n",
      "\n",
      "Training Loss:  0.08757205691355284 \n",
      "Valid Loss:  16.61243217891846\n",
      "--------------------------------------Epoch 387 ------------------------------\n",
      "\n",
      "Training Loss:  0.07752990144841168 \n",
      "Valid Loss:  15.15615408801793\n",
      "--------------------------------------Epoch 388 ------------------------------\n",
      "\n",
      "Training Loss:  0.07765437413580539 \n",
      "Valid Loss:  15.402302377060298\n",
      "--------------------------------------Epoch 389 ------------------------------\n",
      "\n",
      "Training Loss:  0.07635222059301282 \n",
      "Valid Loss:  17.367537954838596\n",
      "--------------------------------------Epoch 390 ------------------------------\n",
      "\n",
      "Training Loss:  0.09274325698913306 \n",
      "Valid Loss:  9.763520411373932\n",
      "--------------------------------------Epoch 391 ------------------------------\n",
      "\n",
      "Training Loss:  0.07907698110648931 \n",
      "Valid Loss:  11.528068608403428\n",
      "--------------------------------------Epoch 392 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08863410143523894 \n",
      "Valid Loss:  17.691003066034494\n",
      "--------------------------------------Epoch 393 ------------------------------\n",
      "\n",
      "Training Loss:  0.08492545677040172 \n",
      "Valid Loss:  24.23916704538405\n",
      "--------------------------------------Epoch 394 ------------------------------\n",
      "\n",
      "Training Loss:  0.07639007961629793 \n",
      "Valid Loss:  17.952899282098038\n",
      "--------------------------------------Epoch 395 ------------------------------\n",
      "\n",
      "Training Loss:  0.0907307033207931 \n",
      "Valid Loss:  17.198821941388054\n",
      "--------------------------------------Epoch 396 ------------------------------\n",
      "\n",
      "Training Loss:  0.08543395063106425 \n",
      "Valid Loss:  14.765299051833102\n",
      "--------------------------------------Epoch 397 ------------------------------\n",
      "\n",
      "Training Loss:  0.0766902380187509 \n",
      "Valid Loss:  16.965483036823336\n",
      "--------------------------------------Epoch 398 ------------------------------\n",
      "\n",
      "Training Loss:  0.08164428396487874 \n",
      "Valid Loss:  19.164791451943877\n",
      "--------------------------------------Epoch 399 ------------------------------\n",
      "\n",
      "Training Loss:  0.07465333324956824 \n",
      "Valid Loss:  17.835928211169183\n",
      "--------------------------------------Epoch 400 ------------------------------\n",
      "\n",
      "Training Loss:  0.08462071354642922 \n",
      "Valid Loss:  19.968297040799946\n",
      "--------------------------------------Epoch 401 ------------------------------\n",
      "\n",
      "Training Loss:  0.08840308062439013 \n",
      "Valid Loss:  23.521785949306206\n",
      "--------------------------------------Epoch 402 ------------------------------\n",
      "\n",
      "Training Loss:  0.08905526430590274 \n",
      "Valid Loss:  20.802186663898436\n",
      "--------------------------------------Epoch 403 ------------------------------\n",
      "\n",
      "Training Loss:  0.084163215378131 \n",
      "Valid Loss:  16.461460251633824\n",
      "--------------------------------------Epoch 404 ------------------------------\n",
      "\n",
      "Training Loss:  0.07882328246568197 \n",
      "Valid Loss:  15.853307309356955\n",
      "--------------------------------------Epoch 405 ------------------------------\n",
      "\n",
      "Training Loss:  0.08545897303285156 \n",
      "Valid Loss:  21.719833207619985\n",
      "--------------------------------------Epoch 406 ------------------------------\n",
      "\n",
      "Training Loss:  0.08874044654359113 \n",
      "Valid Loss:  41.50763673490862\n",
      "--------------------------------------Epoch 407 ------------------------------\n",
      "\n",
      "Training Loss:  0.07681168922009078 \n",
      "Valid Loss:  21.315201973612442\n",
      "--------------------------------------Epoch 408 ------------------------------\n",
      "\n",
      "Training Loss:  0.07604264432555233 \n",
      "Valid Loss:  24.90084274599895\n",
      "--------------------------------------Epoch 409 ------------------------------\n",
      "\n",
      "Training Loss:  0.07770642685766185 \n",
      "Valid Loss:  33.49773392538199\n",
      "--------------------------------------Epoch 410 ------------------------------\n",
      "\n",
      "Training Loss:  0.08679798064901248 \n",
      "Valid Loss:  40.667385554214526\n",
      "--------------------------------------Epoch 411 ------------------------------\n",
      "\n",
      "Training Loss:  0.07610496981252333 \n",
      "Valid Loss:  19.615599654070248\n",
      "--------------------------------------Epoch 412 ------------------------------\n",
      "\n",
      "Training Loss:  0.07743075360112128 \n",
      "Valid Loss:  21.79939104168519\n",
      "--------------------------------------Epoch 413 ------------------------------\n",
      "\n",
      "Training Loss:  0.090890302724514 \n",
      "Valid Loss:  20.6965138247956\n",
      "--------------------------------------Epoch 414 ------------------------------\n",
      "\n",
      "Training Loss:  0.08133364931601948 \n",
      "Valid Loss:  16.80666630683478\n",
      "--------------------------------------Epoch 415 ------------------------------\n",
      "\n",
      "Training Loss:  0.07830237697457992 \n",
      "Valid Loss:  18.05491165354335\n",
      "--------------------------------------Epoch 416 ------------------------------\n",
      "\n",
      "Training Loss:  0.08549181290788244 \n",
      "Valid Loss:  20.40522272423499\n",
      "--------------------------------------Epoch 417 ------------------------------\n",
      "\n",
      "Training Loss:  0.08771332231096896 \n",
      "Valid Loss:  19.467112985606544\n",
      "--------------------------------------Epoch 418 ------------------------------\n",
      "\n",
      "Training Loss:  0.07947263669331388 \n",
      "Valid Loss:  17.273363730577802\n",
      "--------------------------------------Epoch 419 ------------------------------\n",
      "\n",
      "Training Loss:  0.07667923402487865 \n",
      "Valid Loss:  22.63448279687182\n",
      "--------------------------------------Epoch 420 ------------------------------\n",
      "\n",
      "Training Loss:  0.08098438295265163 \n",
      "Valid Loss:  26.30560080109967\n",
      "--------------------------------------Epoch 421 ------------------------------\n",
      "\n",
      "Training Loss:  0.1045736439612777 \n",
      "Valid Loss:  37.42276962603417\n",
      "--------------------------------------Epoch 422 ------------------------------\n",
      "\n",
      "Training Loss:  0.0837273821325561 \n",
      "Valid Loss:  30.538653756779773\n",
      "--------------------------------------Epoch 423 ------------------------------\n",
      "\n",
      "Training Loss:  0.07673462348052723 \n",
      "Valid Loss:  31.94048583435508\n",
      "--------------------------------------Epoch 424 ------------------------------\n",
      "\n",
      "Training Loss:  0.07601581728845565 \n",
      "Valid Loss:  18.692880919703526\n",
      "--------------------------------------Epoch 425 ------------------------------\n",
      "\n",
      "Training Loss:  0.07777048405129716 \n",
      "Valid Loss:  22.01495014191563\n",
      "--------------------------------------Epoch 426 ------------------------------\n",
      "\n",
      "Training Loss:  0.07402895926339607 \n",
      "Valid Loss:  25.223962802028666\n",
      "--------------------------------------Epoch 427 ------------------------------\n",
      "\n",
      "Training Loss:  0.10223698826592434 \n",
      "Valid Loss:  43.816442993981624\n",
      "--------------------------------------Epoch 428 ------------------------------\n",
      "\n",
      "Training Loss:  0.07921511831772837 \n",
      "Valid Loss:  30.646456671829924\n",
      "--------------------------------------Epoch 429 ------------------------------\n",
      "\n",
      "Training Loss:  0.07849636756414538 \n",
      "Valid Loss:  33.738590438251855\n",
      "--------------------------------------Epoch 430 ------------------------------\n",
      "\n",
      "Training Loss:  0.08128202296220177 \n",
      "Valid Loss:  31.828618985993746\n",
      "--------------------------------------Epoch 431 ------------------------------\n",
      "\n",
      "Training Loss:  0.09068036347924012 \n",
      "Valid Loss:  39.32958089638584\n",
      "--------------------------------------Epoch 432 ------------------------------\n",
      "\n",
      "Training Loss:  0.07733570969569069 \n",
      "Valid Loss:  37.13842713881532\n",
      "--------------------------------------Epoch 433 ------------------------------\n",
      "\n",
      "Training Loss:  0.07553940229101458 \n",
      "Valid Loss:  22.036400806597946\n",
      "--------------------------------------Epoch 434 ------------------------------\n",
      "\n",
      "Training Loss:  0.07262059911872867 \n",
      "Valid Loss:  23.597533156162115\n",
      "--------------------------------------Epoch 435 ------------------------------\n",
      "\n",
      "Training Loss:  0.07477523482397967 \n",
      "Valid Loss:  26.4008162285024\n",
      "--------------------------------------Epoch 436 ------------------------------\n",
      "\n",
      "Training Loss:  0.07656214130559466 \n",
      "Valid Loss:  16.82938184992744\n",
      "--------------------------------------Epoch 437 ------------------------------\n",
      "\n",
      "Training Loss:  0.10553911906297878 \n",
      "Valid Loss:  24.4919859303388\n",
      "--------------------------------------Epoch 438 ------------------------------\n",
      "\n",
      "Training Loss:  0.08505575742531161 \n",
      "Valid Loss:  23.14264785195818\n",
      "--------------------------------------Epoch 439 ------------------------------\n",
      "\n",
      "Training Loss:  0.07820434683595276 \n",
      "Valid Loss:  25.628729430581597\n",
      "--------------------------------------Epoch 440 ------------------------------\n",
      "\n",
      "Training Loss:  0.08321694361493447 \n",
      "Valid Loss:  24.07592874949527\n",
      "--------------------------------------Epoch 441 ------------------------------\n",
      "\n",
      "Training Loss:  0.0754338874693112 \n",
      "Valid Loss:  22.757860033425867\n",
      "--------------------------------------Epoch 442 ------------------------------\n",
      "\n",
      "Training Loss:  0.08036017360462087 \n",
      "Valid Loss:  27.183090482376777\n",
      "--------------------------------------Epoch 443 ------------------------------\n",
      "\n",
      "Training Loss:  0.08167981341666325 \n",
      "Valid Loss:  28.121998427062945\n",
      "--------------------------------------Epoch 444 ------------------------------\n",
      "\n",
      "Training Loss:  0.07684997895925727 \n",
      "Valid Loss:  24.873154487184642\n",
      "--------------------------------------Epoch 445 ------------------------------\n",
      "\n",
      "Training Loss:  0.07960701691581608 \n",
      "Valid Loss:  24.237789679919384\n",
      "--------------------------------------Epoch 446 ------------------------------\n",
      "\n",
      "Training Loss:  0.0735871727692178 \n",
      "Valid Loss:  20.585425829121885\n",
      "--------------------------------------Epoch 447 ------------------------------\n",
      "\n",
      "Training Loss:  0.0778995064558618 \n",
      "Valid Loss:  20.161002916499854\n",
      "--------------------------------------Epoch 448 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.07945852655658783 \n",
      "Valid Loss:  22.95635999260894\n",
      "--------------------------------------Epoch 449 ------------------------------\n",
      "\n",
      "Training Loss:  0.0767895906376908 \n",
      "Valid Loss:  21.01256016730251\n",
      "--------------------------------------Epoch 450 ------------------------------\n",
      "\n",
      "Training Loss:  0.07484628599469315 \n",
      "Valid Loss:  18.255650896583717\n",
      "--------------------------------------Epoch 451 ------------------------------\n",
      "\n",
      "Training Loss:  0.07720081408092871 \n",
      "Valid Loss:  18.75924049683074\n",
      "--------------------------------------Epoch 452 ------------------------------\n",
      "\n",
      "Training Loss:  0.07287594809300409 \n",
      "Valid Loss:  19.722645444280587\n",
      "--------------------------------------Epoch 453 ------------------------------\n",
      "\n",
      "Training Loss:  0.07864871146431716 \n",
      "Valid Loss:  24.207648982267642\n",
      "--------------------------------------Epoch 454 ------------------------------\n",
      "\n",
      "Training Loss:  0.08028381097377024 \n",
      "Valid Loss:  16.472301082438573\n",
      "--------------------------------------Epoch 455 ------------------------------\n",
      "\n",
      "Training Loss:  0.10028113278432318 \n",
      "Valid Loss:  17.16760536330231\n",
      "--------------------------------------Epoch 456 ------------------------------\n",
      "\n",
      "Training Loss:  0.0826743592779304 \n",
      "Valid Loss:  16.555918135350122\n",
      "--------------------------------------Epoch 457 ------------------------------\n",
      "\n",
      "Training Loss:  0.07180692661350334 \n",
      "Valid Loss:  18.50686361693026\n",
      "--------------------------------------Epoch 458 ------------------------------\n",
      "\n",
      "Training Loss:  0.07366885306149035 \n",
      "Valid Loss:  14.947893566080094\n",
      "--------------------------------------Epoch 459 ------------------------------\n",
      "\n",
      "Training Loss:  0.08506003812645738 \n",
      "Valid Loss:  17.382088127020328\n",
      "--------------------------------------Epoch 460 ------------------------------\n",
      "\n",
      "Training Loss:  0.07347934131145013 \n",
      "Valid Loss:  19.720946526985845\n",
      "--------------------------------------Epoch 461 ------------------------------\n",
      "\n",
      "Training Loss:  0.07343446671695322 \n",
      "Valid Loss:  22.482012300652688\n",
      "--------------------------------------Epoch 462 ------------------------------\n",
      "\n",
      "Training Loss:  0.07453668297808673 \n",
      "Valid Loss:  15.549739153586067\n",
      "--------------------------------------Epoch 463 ------------------------------\n",
      "\n",
      "Training Loss:  0.09425220546670904 \n",
      "Valid Loss:  20.985665262299275\n",
      "--------------------------------------Epoch 464 ------------------------------\n",
      "\n",
      "Training Loss:  0.08236806034205447 \n",
      "Valid Loss:  22.093306999435285\n",
      "--------------------------------------Epoch 465 ------------------------------\n",
      "\n",
      "Training Loss:  0.07455362752249955 \n",
      "Valid Loss:  20.24977530391647\n",
      "--------------------------------------Epoch 466 ------------------------------\n",
      "\n",
      "Training Loss:  0.07760496667255896 \n",
      "Valid Loss:  20.532846429792524\n",
      "--------------------------------------Epoch 467 ------------------------------\n",
      "\n",
      "Training Loss:  0.0752320186445332 \n",
      "Valid Loss:  18.68566274542485\n",
      "--------------------------------------Epoch 468 ------------------------------\n",
      "\n",
      "Training Loss:  0.07832247039177975 \n",
      "Valid Loss:  14.326001480873112\n",
      "--------------------------------------Epoch 469 ------------------------------\n",
      "\n",
      "Training Loss:  0.09837143563319663 \n",
      "Valid Loss:  16.810816694677538\n",
      "--------------------------------------Epoch 470 ------------------------------\n",
      "\n",
      "Training Loss:  0.08319840217438271 \n",
      "Valid Loss:  15.586467542292125\n",
      "--------------------------------------Epoch 471 ------------------------------\n",
      "\n",
      "Training Loss:  0.09599617361358376 \n",
      "Valid Loss:  21.928583758606734\n",
      "--------------------------------------Epoch 472 ------------------------------\n",
      "\n",
      "Training Loss:  0.07928864030226782 \n",
      "Valid Loss:  14.279297117750684\n",
      "--------------------------------------Epoch 473 ------------------------------\n",
      "\n",
      "Training Loss:  0.11973990611839863 \n",
      "Valid Loss:  23.51231539345929\n",
      "--------------------------------------Epoch 474 ------------------------------\n",
      "\n",
      "Training Loss:  0.09741678736667353 \n",
      "Valid Loss:  22.658771680674093\n",
      "--------------------------------------Epoch 475 ------------------------------\n",
      "\n",
      "Training Loss:  0.11232233185155556 \n",
      "Valid Loss:  31.805385170272793\n",
      "--------------------------------------Epoch 476 ------------------------------\n",
      "\n",
      "Training Loss:  0.08627666617971812 \n",
      "Valid Loss:  21.876135520134326\n",
      "--------------------------------------Epoch 477 ------------------------------\n",
      "\n",
      "Training Loss:  0.07790091768582891 \n",
      "Valid Loss:  15.426912680337926\n",
      "--------------------------------------Epoch 478 ------------------------------\n",
      "\n",
      "Training Loss:  0.07543846431553124 \n",
      "Valid Loss:  15.293967300225031\n",
      "--------------------------------------Epoch 479 ------------------------------\n",
      "\n",
      "Training Loss:  0.09449560987945527 \n",
      "Valid Loss:  16.82204696065174\n",
      "--------------------------------------Epoch 480 ------------------------------\n",
      "\n",
      "Training Loss:  0.08936787716494986 \n",
      "Valid Loss:  23.91393834349398\n",
      "--------------------------------------Epoch 481 ------------------------------\n",
      "\n",
      "Training Loss:  0.09083321738406319 \n",
      "Valid Loss:  16.190263916615\n",
      "--------------------------------------Epoch 482 ------------------------------\n",
      "\n",
      "Training Loss:  0.0823806057464775 \n",
      "Valid Loss:  16.234282743425155\n",
      "--------------------------------------Epoch 483 ------------------------------\n",
      "\n",
      "Training Loss:  0.08077998679347101 \n",
      "Valid Loss:  20.286079490896828\n",
      "--------------------------------------Epoch 484 ------------------------------\n",
      "\n",
      "Training Loss:  0.07787750372808513 \n",
      "Valid Loss:  85.79594571670107\n",
      "--------------------------------------Epoch 485 ------------------------------\n",
      "\n",
      "Training Loss:  0.08323654842932032 \n",
      "Valid Loss:  15.92485112567141\n",
      "--------------------------------------Epoch 486 ------------------------------\n",
      "\n",
      "Training Loss:  0.08029108876042682 \n",
      "Valid Loss:  13.474789200694143\n",
      "--------------------------------------Epoch 487 ------------------------------\n",
      "\n",
      "Training Loss:  0.07843513136971339 \n",
      "Valid Loss:  13.745538829161148\n",
      "--------------------------------------Epoch 488 ------------------------------\n",
      "\n",
      "Training Loss:  0.11895028930905975 \n",
      "Valid Loss:  15.9037401435557\n",
      "--------------------------------------Epoch 489 ------------------------------\n",
      "\n",
      "Training Loss:  0.10856180000944253 \n",
      "Valid Loss:  118.59538786852141\n",
      "--------------------------------------Epoch 490 ------------------------------\n",
      "\n",
      "Training Loss:  0.09199083928638517 \n",
      "Valid Loss:  18.257862504201913\n",
      "--------------------------------------Epoch 491 ------------------------------\n",
      "\n",
      "Training Loss:  0.08360658474929498 \n",
      "Valid Loss:  16.729658307324748\n",
      "--------------------------------------Epoch 492 ------------------------------\n",
      "\n",
      "Training Loss:  0.076359117336333 \n",
      "Valid Loss:  15.983435642772587\n",
      "--------------------------------------Epoch 493 ------------------------------\n",
      "\n",
      "Training Loss:  0.10631808841684018 \n",
      "Valid Loss:  29.282362642291883\n",
      "--------------------------------------Epoch 494 ------------------------------\n",
      "\n",
      "Training Loss:  0.08038693781906255 \n",
      "Valid Loss:  17.34558087343412\n",
      "--------------------------------------Epoch 495 ------------------------------\n",
      "\n",
      "Training Loss:  0.08109951032581669 \n",
      "Valid Loss:  21.675457345973605\n",
      "--------------------------------------Epoch 496 ------------------------------\n",
      "\n",
      "Training Loss:  0.07739911032464282 \n",
      "Valid Loss:  24.076679725115998\n",
      "--------------------------------------Epoch 497 ------------------------------\n",
      "\n",
      "Training Loss:  0.10994181665392594 \n",
      "Valid Loss:  28.210045626897916\n",
      "--------------------------------------Epoch 498 ------------------------------\n",
      "\n",
      "Training Loss:  0.0825030190592551 \n",
      "Valid Loss:  10.519077919745978\n",
      "--------------------------------------Epoch 499 ------------------------------\n",
      "\n",
      "Training Loss:  0.07684359216369963 \n",
      "Valid Loss:  10.980105795284166\n",
      "--------------------------------------Epoch 500 ------------------------------\n",
      "\n",
      "Training Loss:  0.11118662765622186 \n",
      "Valid Loss:  16.007949119369048\n",
      "--------------------------------------Epoch 501 ------------------------------\n",
      "\n",
      "Training Loss:  0.0787131040992355 \n",
      "Valid Loss:  16.78930071525816\n",
      "--------------------------------------Epoch 502 ------------------------------\n",
      "\n",
      "Training Loss:  0.08253718799685643 \n",
      "Valid Loss:  20.35220648567422\n",
      "--------------------------------------Epoch 503 ------------------------------\n",
      "\n",
      "Training Loss:  0.07821935299825682 \n",
      "Valid Loss:  13.459688268722882\n",
      "--------------------------------------Epoch 504 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08204630266890621 \n",
      "Valid Loss:  16.412168468959013\n",
      "--------------------------------------Epoch 505 ------------------------------\n",
      "\n",
      "Training Loss:  0.07916866568133352 \n",
      "Valid Loss:  16.807678622046854\n",
      "--------------------------------------Epoch 506 ------------------------------\n",
      "\n",
      "Training Loss:  0.08384820516685773 \n",
      "Valid Loss:  20.601075816840922\n",
      "--------------------------------------Epoch 507 ------------------------------\n",
      "\n",
      "Training Loss:  0.07979263334467886 \n",
      "Valid Loss:  21.50971898202684\n",
      "--------------------------------------Epoch 508 ------------------------------\n",
      "\n",
      "Training Loss:  0.07507345018750582 \n",
      "Valid Loss:  22.74012563406787\n",
      "--------------------------------------Epoch 509 ------------------------------\n",
      "\n",
      "Training Loss:  0.07735161318024655 \n",
      "Valid Loss:  27.18408448181949\n",
      "--------------------------------------Epoch 510 ------------------------------\n",
      "\n",
      "Training Loss:  0.08429881501837654 \n",
      "Valid Loss:  15.071381114485645\n",
      "--------------------------------------Epoch 511 ------------------------------\n",
      "\n",
      "Training Loss:  0.07726614759476552 \n",
      "Valid Loss:  20.739003811768526\n",
      "--------------------------------------Epoch 512 ------------------------------\n",
      "\n",
      "Training Loss:  0.07984771171581442 \n",
      "Valid Loss:  16.418253297872994\n",
      "--------------------------------------Epoch 513 ------------------------------\n",
      "\n",
      "Training Loss:  0.08350960234267317 \n",
      "Valid Loss:  16.794126383120368\n",
      "--------------------------------------Epoch 514 ------------------------------\n",
      "\n",
      "Training Loss:  0.08141415253880552 \n",
      "Valid Loss:  15.748638438698526\n",
      "--------------------------------------Epoch 515 ------------------------------\n",
      "\n",
      "Training Loss:  0.08729907181645624 \n",
      "Valid Loss:  31.459682259506998\n",
      "--------------------------------------Epoch 516 ------------------------------\n",
      "\n",
      "Training Loss:  0.08656883596622655 \n",
      "Valid Loss:  23.27978205533294\n",
      "--------------------------------------Epoch 517 ------------------------------\n",
      "\n",
      "Training Loss:  0.0770990621709874 \n",
      "Valid Loss:  36.46826641774602\n",
      "--------------------------------------Epoch 518 ------------------------------\n",
      "\n",
      "Training Loss:  0.08754514409401497 \n",
      "Valid Loss:  23.185557384504317\n",
      "--------------------------------------Epoch 519 ------------------------------\n",
      "\n",
      "Training Loss:  0.0771351488479045 \n",
      "Valid Loss:  22.946473770457427\n",
      "--------------------------------------Epoch 520 ------------------------------\n",
      "\n",
      "Training Loss:  0.07439119670140788 \n",
      "Valid Loss:  26.412339808848195\n",
      "--------------------------------------Epoch 521 ------------------------------\n",
      "\n",
      "Training Loss:  0.07542908807140461 \n",
      "Valid Loss:  25.16604055359318\n",
      "--------------------------------------Epoch 522 ------------------------------\n",
      "\n",
      "Training Loss:  0.09298674302338131 \n",
      "Valid Loss:  22.3794858144958\n",
      "--------------------------------------Epoch 523 ------------------------------\n",
      "\n",
      "Training Loss:  0.08771008996326712 \n",
      "Valid Loss:  36.24935407794342\n",
      "--------------------------------------Epoch 524 ------------------------------\n",
      "\n",
      "Training Loss:  0.10554526685421708 \n",
      "Valid Loss:  25.697405320421762\n",
      "--------------------------------------Epoch 525 ------------------------------\n",
      "\n",
      "Training Loss:  0.07957684212723702 \n",
      "Valid Loss:  26.980036250161323\n",
      "--------------------------------------Epoch 526 ------------------------------\n",
      "\n",
      "Training Loss:  0.07649845522120295 \n",
      "Valid Loss:  23.75125088379648\n",
      "--------------------------------------Epoch 527 ------------------------------\n",
      "\n",
      "Training Loss:  0.07387466200251996 \n",
      "Valid Loss:  35.889204867218865\n",
      "--------------------------------------Epoch 528 ------------------------------\n",
      "\n",
      "Training Loss:  0.07337328043189753 \n",
      "Valid Loss:  23.708437090496226\n",
      "--------------------------------------Epoch 529 ------------------------------\n",
      "\n",
      "Training Loss:  0.0788701657703604 \n",
      "Valid Loss:  30.115736481628343\n",
      "--------------------------------------Epoch 530 ------------------------------\n",
      "\n",
      "Training Loss:  0.08433997457792367 \n",
      "Valid Loss:  47.41178204910314\n",
      "--------------------------------------Epoch 531 ------------------------------\n",
      "\n",
      "Training Loss:  0.11029416988596737 \n",
      "Valid Loss:  52.28771853500655\n",
      "--------------------------------------Epoch 532 ------------------------------\n",
      "\n",
      "Training Loss:  0.10962266964598279 \n",
      "Valid Loss:  47.1341711451639\n",
      "--------------------------------------Epoch 533 ------------------------------\n",
      "\n",
      "Training Loss:  0.07898651533388493 \n",
      "Valid Loss:  38.87075800767866\n",
      "--------------------------------------Epoch 534 ------------------------------\n",
      "\n",
      "Training Loss:  0.07763388437302905 \n",
      "Valid Loss:  26.57885891716662\n",
      "--------------------------------------Epoch 535 ------------------------------\n",
      "\n",
      "Training Loss:  0.09193447427796003 \n",
      "Valid Loss:  50.88059201382508\n",
      "--------------------------------------Epoch 536 ------------------------------\n",
      "\n",
      "Training Loss:  0.08096107068193292 \n",
      "Valid Loss:  39.94876959502007\n",
      "--------------------------------------Epoch 537 ------------------------------\n",
      "\n",
      "Training Loss:  0.08233515542715789 \n",
      "Valid Loss:  37.502235300724756\n",
      "--------------------------------------Epoch 538 ------------------------------\n",
      "\n",
      "Training Loss:  0.07493136929311064 \n",
      "Valid Loss:  29.68984599812599\n",
      "--------------------------------------Epoch 539 ------------------------------\n",
      "\n",
      "Training Loss:  0.08762252416290484 \n",
      "Valid Loss:  40.45365738059457\n",
      "--------------------------------------Epoch 540 ------------------------------\n",
      "\n",
      "Training Loss:  0.07680978197025859 \n",
      "Valid Loss:  32.701231302155136\n",
      "--------------------------------------Epoch 541 ------------------------------\n",
      "\n",
      "Training Loss:  0.08151388708968653 \n",
      "Valid Loss:  31.820139493307423\n",
      "--------------------------------------Epoch 542 ------------------------------\n",
      "\n",
      "Training Loss:  0.09900541176659211 \n",
      "Valid Loss:  35.946274492667364\n",
      "--------------------------------------Epoch 543 ------------------------------\n",
      "\n",
      "Training Loss:  0.07620148983275685 \n",
      "Valid Loss:  28.76312772996352\n",
      "--------------------------------------Epoch 544 ------------------------------\n",
      "\n",
      "Training Loss:  0.07355248006566006 \n",
      "Valid Loss:  21.2544662919454\n",
      "--------------------------------------Epoch 545 ------------------------------\n",
      "\n",
      "Training Loss:  0.09003824089203134 \n",
      "Valid Loss:  32.835621470472915\n",
      "--------------------------------------Epoch 546 ------------------------------\n",
      "\n",
      "Training Loss:  0.08019151691450997 \n",
      "Valid Loss:  27.053321135099527\n",
      "--------------------------------------Epoch 547 ------------------------------\n",
      "\n",
      "Training Loss:  0.07561667236778041 \n",
      "Valid Loss:  23.56727691751451\n",
      "--------------------------------------Epoch 548 ------------------------------\n",
      "\n",
      "Training Loss:  0.0731469320290073 \n",
      "Valid Loss:  31.362589666619662\n",
      "--------------------------------------Epoch 549 ------------------------------\n",
      "\n",
      "Training Loss:  0.07479747230817671 \n",
      "Valid Loss:  30.66823399803636\n",
      "--------------------------------------Epoch 550 ------------------------------\n",
      "\n",
      "Training Loss:  0.10984161802904478 \n",
      "Valid Loss:  26.144782300789846\n",
      "--------------------------------------Epoch 551 ------------------------------\n",
      "\n",
      "Training Loss:  0.08138329481017496 \n",
      "Valid Loss:  28.998264464566603\n",
      "--------------------------------------Epoch 552 ------------------------------\n",
      "\n",
      "Training Loss:  0.10162366235493668 \n",
      "Valid Loss:  29.79996567428926\n",
      "--------------------------------------Epoch 553 ------------------------------\n",
      "\n",
      "Training Loss:  0.08989911847717967 \n",
      "Valid Loss:  28.567725988442813\n",
      "--------------------------------------Epoch 554 ------------------------------\n",
      "\n",
      "Training Loss:  0.0816566923690722 \n",
      "Valid Loss:  24.65951209633343\n",
      "--------------------------------------Epoch 555 ------------------------------\n",
      "\n",
      "Training Loss:  0.0751983417532888 \n",
      "Valid Loss:  24.294328398902667\n",
      "--------------------------------------Epoch 556 ------------------------------\n",
      "\n",
      "Training Loss:  0.07492004691816356 \n",
      "Valid Loss:  24.436786019832763\n",
      "--------------------------------------Epoch 557 ------------------------------\n",
      "\n",
      "Training Loss:  0.08118103050833383 \n",
      "Valid Loss:  24.0744721092276\n",
      "--------------------------------------Epoch 558 ------------------------------\n",
      "\n",
      "Training Loss:  0.08466005356818689 \n",
      "Valid Loss:  24.272820472813653\n",
      "--------------------------------------Epoch 559 ------------------------------\n",
      "\n",
      "Training Loss:  0.08750137383662716 \n",
      "Valid Loss:  23.84873603779247\n",
      "--------------------------------------Epoch 560 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.08670559575359059 \n",
      "Valid Loss:  22.86932758061114\n",
      "--------------------------------------Epoch 561 ------------------------------\n",
      "\n",
      "Training Loss:  0.08366788617417442 \n",
      "Valid Loss:  23.667986031069397\n",
      "--------------------------------------Epoch 562 ------------------------------\n",
      "\n",
      "Training Loss:  0.07994388985200335 \n",
      "Valid Loss:  23.446513178230763\n",
      "--------------------------------------Epoch 563 ------------------------------\n",
      "\n",
      "Training Loss:  0.07655466169476216 \n",
      "Valid Loss:  28.60850249251706\n",
      "--------------------------------------Epoch 564 ------------------------------\n",
      "\n",
      "Training Loss:  0.07706785411439125 \n",
      "Valid Loss:  28.60278390561468\n",
      "--------------------------------------Epoch 565 ------------------------------\n",
      "\n",
      "Training Loss:  0.08266476604569688 \n",
      "Valid Loss:  29.38407413009179\n",
      "--------------------------------------Epoch 566 ------------------------------\n",
      "\n",
      "Training Loss:  0.0837493578722013 \n",
      "Valid Loss:  27.86495784396556\n",
      "--------------------------------------Epoch 567 ------------------------------\n",
      "\n",
      "Training Loss:  0.07701466295684449 \n",
      "Valid Loss:  31.169257371528833\n",
      "--------------------------------------Epoch 568 ------------------------------\n",
      "\n",
      "Training Loss:  0.08303398940460918 \n",
      "Valid Loss:  29.45492209855154\n",
      "--------------------------------------Epoch 569 ------------------------------\n",
      "\n",
      "Training Loss:  0.08259111489179265 \n",
      "Valid Loss:  39.156411550987386\n",
      "--------------------------------------Epoch 570 ------------------------------\n",
      "\n",
      "Training Loss:  0.09517339815429955 \n",
      "Valid Loss:  35.20873099245088\n",
      "--------------------------------------Epoch 571 ------------------------------\n",
      "\n",
      "Training Loss:  0.07816987313816234 \n",
      "Valid Loss:  33.051481274080864\n",
      "--------------------------------------Epoch 572 ------------------------------\n",
      "\n",
      "Training Loss:  0.09202837656499278 \n",
      "Valid Loss:  40.94452408317444\n",
      "--------------------------------------Epoch 573 ------------------------------\n",
      "\n",
      "Training Loss:  0.07933513146046922 \n",
      "Valid Loss:  30.595064833501404\n",
      "--------------------------------------Epoch 574 ------------------------------\n",
      "\n",
      "Training Loss:  0.11201280902277243 \n",
      "Valid Loss:  44.79751847951588\n",
      "--------------------------------------Epoch 575 ------------------------------\n",
      "\n",
      "Training Loss:  0.08589900090666427 \n",
      "Valid Loss:  39.019221028519375\n",
      "--------------------------------------Epoch 576 ------------------------------\n",
      "\n",
      "Training Loss:  0.08326870099047465 \n",
      "Valid Loss:  31.241610383200822\n",
      "--------------------------------------Epoch 577 ------------------------------\n",
      "\n",
      "Training Loss:  0.08014045696754116 \n",
      "Valid Loss:  28.79795221879601\n",
      "--------------------------------------Epoch 578 ------------------------------\n",
      "\n",
      "Training Loss:  0.07825771884171247 \n",
      "Valid Loss:  29.294795965965534\n",
      "--------------------------------------Epoch 579 ------------------------------\n",
      "\n",
      "Training Loss:  0.07490018511288082 \n",
      "Valid Loss:  30.457684129953464\n",
      "--------------------------------------Epoch 580 ------------------------------\n",
      "\n",
      "Training Loss:  0.07898327880976144 \n",
      "Valid Loss:  27.6153912352021\n",
      "--------------------------------------Epoch 581 ------------------------------\n",
      "\n",
      "Training Loss:  0.07574945629014206 \n",
      "Valid Loss:  30.56023214496897\n",
      "--------------------------------------Epoch 582 ------------------------------\n",
      "\n",
      "Training Loss:  0.08497140687142503 \n",
      "Valid Loss:  31.20312624300473\n",
      "--------------------------------------Epoch 583 ------------------------------\n",
      "\n",
      "Training Loss:  0.08178757575670237 \n",
      "Valid Loss:  29.467269332450602\n",
      "--------------------------------------Epoch 584 ------------------------------\n",
      "\n",
      "Training Loss:  0.08005252279576162 \n",
      "Valid Loss:  31.49240671495592\n",
      "--------------------------------------Epoch 585 ------------------------------\n",
      "\n",
      "Training Loss:  0.0901496912412707 \n",
      "Valid Loss:  36.97256995768011\n",
      "--------------------------------------Epoch 586 ------------------------------\n",
      "\n",
      "Training Loss:  0.08182260117970486 \n",
      "Valid Loss:  32.80472263391997\n",
      "--------------------------------------Epoch 587 ------------------------------\n",
      "\n",
      "Training Loss:  0.07643153584623909 \n",
      "Valid Loss:  35.21617125557578\n",
      "--------------------------------------Epoch 588 ------------------------------\n",
      "\n",
      "Training Loss:  0.09082734000518912 \n",
      "Valid Loss:  43.24605058557434\n",
      "--------------------------------------Epoch 589 ------------------------------\n",
      "\n",
      "Training Loss:  0.08449410261810933 \n",
      "Valid Loss:  30.542783409366802\n",
      "--------------------------------------Epoch 590 ------------------------------\n",
      "\n",
      "Training Loss:  0.07885046095711817 \n",
      "Valid Loss:  27.69484569558891\n",
      "--------------------------------------Epoch 591 ------------------------------\n",
      "\n",
      "Training Loss:  0.07519045800669588 \n",
      "Valid Loss:  30.363678937004355\n",
      "--------------------------------------Epoch 592 ------------------------------\n",
      "\n",
      "Training Loss:  0.07651223784282359 \n",
      "Valid Loss:  32.762836468884345\n",
      "--------------------------------------Epoch 593 ------------------------------\n",
      "\n",
      "Training Loss:  0.07569360913994745 \n",
      "Valid Loss:  34.97970157409589\n",
      "--------------------------------------Epoch 594 ------------------------------\n",
      "\n",
      "Training Loss:  0.12643712834728937 \n",
      "Valid Loss:  89.08819656637343\n",
      "--------------------------------------Epoch 595 ------------------------------\n",
      "\n",
      "Training Loss:  0.08720092591659606 \n",
      "Valid Loss:  41.083619515741226\n",
      "--------------------------------------Epoch 596 ------------------------------\n",
      "\n",
      "Training Loss:  0.11089276345075653 \n",
      "Valid Loss:  45.1052812304238\n",
      "--------------------------------------Epoch 597 ------------------------------\n",
      "\n",
      "Training Loss:  0.08325477871859319 \n",
      "Valid Loss:  36.128464444628605\n",
      "--------------------------------------Epoch 598 ------------------------------\n",
      "\n",
      "Training Loss:  0.07872132617900052 \n",
      "Valid Loss:  30.066672967559512\n",
      "--------------------------------------Epoch 599 ------------------------------\n",
      "\n",
      "Training Loss:  0.0876059134870398 \n",
      "Valid Loss:  31.672261465655748\n",
      "--------------------------------------Epoch 600 ------------------------------\n",
      "\n",
      "Training Loss:  0.08079398352124523 \n",
      "Valid Loss:  34.17761231600077\n",
      "--------------------------------------Epoch 601 ------------------------------\n",
      "\n",
      "Training Loss:  0.08391423025791588 \n",
      "Valid Loss:  39.09052504296016\n",
      "--------------------------------------Epoch 602 ------------------------------\n",
      "\n",
      "Training Loss:  0.08528312949151526 \n",
      "Valid Loss:  44.13351552800697\n",
      "--------------------------------------Epoch 603 ------------------------------\n",
      "\n",
      "Training Loss:  0.08289581743277204 \n",
      "Valid Loss:  31.308986175615175\n",
      "--------------------------------------Epoch 604 ------------------------------\n",
      "\n",
      "Training Loss:  0.07857393801102343 \n",
      "Valid Loss:  38.897794297362196\n",
      "--------------------------------------Epoch 605 ------------------------------\n",
      "\n",
      "Training Loss:  0.07544112023725132 \n",
      "Valid Loss:  32.03988805174671\n",
      "--------------------------------------Epoch 606 ------------------------------\n",
      "\n",
      "Training Loss:  0.07847215937289212 \n",
      "Valid Loss:  45.796178760613365\n",
      "--------------------------------------Epoch 607 ------------------------------\n",
      "\n",
      "Training Loss:  0.0754392670127746 \n",
      "Valid Loss:  32.03531485133779\n",
      "--------------------------------------Epoch 608 ------------------------------\n",
      "\n",
      "Training Loss:  0.07991586075610344 \n",
      "Valid Loss:  33.95659753471924\n",
      "--------------------------------------Epoch 609 ------------------------------\n",
      "\n",
      "Training Loss:  0.0930998670598464 \n",
      "Valid Loss:  47.68200419753746\n",
      "--------------------------------------Epoch 610 ------------------------------\n",
      "\n",
      "Training Loss:  0.08656202051235215 \n",
      "Valid Loss:  47.0533290046285\n",
      "--------------------------------------Epoch 611 ------------------------------\n",
      "\n",
      "Training Loss:  0.07967351057126129 \n",
      "Valid Loss:  40.418526281972206\n",
      "--------------------------------------Epoch 612 ------------------------------\n",
      "\n",
      "Training Loss:  0.08199174320277189 \n",
      "Valid Loss:  42.352479558188115\n",
      "--------------------------------------Epoch 613 ------------------------------\n",
      "\n",
      "Training Loss:  0.07643251574296019 \n",
      "Valid Loss:  32.08662613644921\n",
      "--------------------------------------Epoch 614 ------------------------------\n",
      "\n",
      "Training Loss:  0.07905991334275976 \n",
      "Valid Loss:  28.839333182279805\n",
      "--------------------------------------Epoch 615 ------------------------------\n",
      "\n",
      "Training Loss:  0.08166248231370885 \n",
      "Valid Loss:  31.66780391439124\n",
      "--------------------------------------Epoch 616 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.07706163940222138 \n",
      "Valid Loss:  56.447926140255284\n",
      "--------------------------------------Epoch 617 ------------------------------\n",
      "\n",
      "Training Loss:  0.08111629249389243 \n",
      "Valid Loss:  39.7902585544456\n",
      "--------------------------------------Epoch 618 ------------------------------\n",
      "\n",
      "Training Loss:  0.0854466437516417 \n",
      "Valid Loss:  47.064030569708414\n",
      "--------------------------------------Epoch 619 ------------------------------\n",
      "\n",
      "Training Loss:  0.0802016025019586 \n",
      "Valid Loss:  49.527723665272276\n",
      "--------------------------------------Epoch 620 ------------------------------\n",
      "\n",
      "Training Loss:  0.07544435467043459 \n",
      "Valid Loss:  25.945702500430674\n",
      "--------------------------------------Epoch 621 ------------------------------\n",
      "\n",
      "Training Loss:  0.08470691191526092 \n",
      "Valid Loss:  50.592702235601664\n",
      "--------------------------------------Epoch 622 ------------------------------\n",
      "\n",
      "Training Loss:  0.07717169637887711 \n",
      "Valid Loss:  26.78744479503613\n",
      "--------------------------------------Epoch 623 ------------------------------\n",
      "\n",
      "Training Loss:  0.08102453625049937 \n",
      "Valid Loss:  32.168212454624886\n",
      "--------------------------------------Epoch 624 ------------------------------\n",
      "\n",
      "Training Loss:  0.08428290966862563 \n",
      "Valid Loss:  32.661295838233514\n",
      "--------------------------------------Epoch 625 ------------------------------\n",
      "\n",
      "Training Loss:  0.07522493592474688 \n",
      "Valid Loss:  40.743752383876476\n",
      "--------------------------------------Epoch 626 ------------------------------\n",
      "\n",
      "Training Loss:  0.07536771355306097 \n",
      "Valid Loss:  36.76847811748132\n",
      "--------------------------------------Epoch 627 ------------------------------\n",
      "\n",
      "Training Loss:  0.08273348899329928 \n",
      "Valid Loss:  43.886588672645416\n",
      "--------------------------------------Epoch 628 ------------------------------\n",
      "\n",
      "Training Loss:  0.07946944093967817 \n",
      "Valid Loss:  34.71673631627551\n",
      "--------------------------------------Epoch 629 ------------------------------\n",
      "\n",
      "Training Loss:  0.07434513048313522 \n",
      "Valid Loss:  29.565266499864425\n",
      "--------------------------------------Epoch 630 ------------------------------\n",
      "\n",
      "Training Loss:  0.07316692821877988 \n",
      "Valid Loss:  28.485716739818567\n",
      "--------------------------------------Epoch 631 ------------------------------\n",
      "\n",
      "Training Loss:  0.09148127429220065 \n",
      "Valid Loss:  38.54361580121134\n",
      "--------------------------------------Epoch 632 ------------------------------\n",
      "\n",
      "Training Loss:  0.07719308482842943 \n",
      "Valid Loss:  35.47778331225821\n",
      "--------------------------------------Epoch 633 ------------------------------\n",
      "\n",
      "Training Loss:  0.08178832116726133 \n",
      "Valid Loss:  40.18913957137523\n",
      "--------------------------------------Epoch 634 ------------------------------\n",
      "\n",
      "Training Loss:  0.07668859169284803 \n",
      "Valid Loss:  33.124866443322404\n",
      "--------------------------------------Epoch 635 ------------------------------\n",
      "\n",
      "Training Loss:  0.10845365242844762 \n",
      "Valid Loss:  52.29906832042159\n",
      "--------------------------------------Epoch 636 ------------------------------\n",
      "\n",
      "Training Loss:  0.08471076949082187 \n",
      "Valid Loss:  33.22933710860942\n",
      "--------------------------------------Epoch 637 ------------------------------\n",
      "\n",
      "Training Loss:  0.07847696940445323 \n",
      "Valid Loss:  36.93245149688225\n",
      "--------------------------------------Epoch 638 ------------------------------\n",
      "\n",
      "Training Loss:  0.07561371262944495 \n",
      "Valid Loss:  37.86742255167402\n",
      "--------------------------------------Epoch 639 ------------------------------\n",
      "\n",
      "Training Loss:  0.07583550132554558 \n",
      "Valid Loss:  36.33716428360301\n",
      "--------------------------------------Epoch 640 ------------------------------\n",
      "\n",
      "Training Loss:  0.0835778103608048 \n",
      "Valid Loss:  36.86321705226197\n",
      "--------------------------------------Epoch 641 ------------------------------\n",
      "\n",
      "Training Loss:  0.07917298389245143 \n",
      "Valid Loss:  35.887256751146474\n",
      "--------------------------------------Epoch 642 ------------------------------\n",
      "\n",
      "Training Loss:  0.07817093295617074 \n",
      "Valid Loss:  34.53262891354565\n",
      "--------------------------------------Epoch 643 ------------------------------\n",
      "\n",
      "Training Loss:  0.07684670564575985 \n",
      "Valid Loss:  33.56219962089133\n",
      "--------------------------------------Epoch 644 ------------------------------\n",
      "\n",
      "Training Loss:  0.07563767665084466 \n",
      "Valid Loss:  29.550720928228166\n",
      "--------------------------------------Epoch 645 ------------------------------\n",
      "\n",
      "Training Loss:  0.08601103561418857 \n",
      "Valid Loss:  38.13954737968708\n",
      "--------------------------------------Epoch 646 ------------------------------\n",
      "\n",
      "Training Loss:  0.12072665423987441 \n",
      "Valid Loss:  46.65633950610284\n",
      "--------------------------------------Epoch 647 ------------------------------\n",
      "\n",
      "Training Loss:  0.07795720855797587 \n",
      "Valid Loss:  31.9930781246147\n",
      "--------------------------------------Epoch 648 ------------------------------\n",
      "\n",
      "Training Loss:  0.09285754252978168 \n",
      "Valid Loss:  36.12590893631128\n",
      "--------------------------------------Epoch 649 ------------------------------\n",
      "\n",
      "Training Loss:  0.08060301494555926 \n",
      "Valid Loss:  42.43446383889566\n",
      "--------------------------------------Epoch 650 ------------------------------\n",
      "\n",
      "Training Loss:  0.08923008847967154 \n",
      "Valid Loss:  46.745931320373074\n",
      "--------------------------------------Epoch 651 ------------------------------\n",
      "\n",
      "Training Loss:  0.08268006918703329 \n",
      "Valid Loss:  40.0146529125181\n",
      "--------------------------------------Epoch 652 ------------------------------\n",
      "\n",
      "Training Loss:  0.0772385173840664 \n",
      "Valid Loss:  35.53011917048495\n",
      "--------------------------------------Epoch 653 ------------------------------\n",
      "\n",
      "Training Loss:  0.07654947390867077 \n",
      "Valid Loss:  34.227611907259565\n",
      "--------------------------------------Epoch 654 ------------------------------\n",
      "\n",
      "Training Loss:  0.07264672933544492 \n",
      "Valid Loss:  34.25126218736877\n",
      "--------------------------------------Epoch 655 ------------------------------\n",
      "\n",
      "Training Loss:  0.07325935781616126 \n",
      "Valid Loss:  31.078078050896337\n",
      "--------------------------------------Epoch 656 ------------------------------\n",
      "\n",
      "Training Loss:  0.08519323914838685 \n",
      "Valid Loss:  39.261130912897194\n",
      "--------------------------------------Epoch 657 ------------------------------\n",
      "\n",
      "Training Loss:  0.07865250132162468 \n",
      "Valid Loss:  47.64329147290425\n",
      "--------------------------------------Epoch 658 ------------------------------\n",
      "\n",
      "Training Loss:  0.07543554613975177 \n",
      "Valid Loss:  34.53392130315767\n",
      "--------------------------------------Epoch 659 ------------------------------\n",
      "\n",
      "Training Loss:  0.08333127822223788 \n",
      "Valid Loss:  41.047825755513\n",
      "--------------------------------------Epoch 660 ------------------------------\n",
      "\n",
      "Training Loss:  0.11847979997398195 \n",
      "Valid Loss:  44.576260799631285\n",
      "--------------------------------------Epoch 661 ------------------------------\n",
      "\n",
      "Training Loss:  0.08238389876042516 \n",
      "Valid Loss:  28.02776969510317\n",
      "--------------------------------------Epoch 662 ------------------------------\n",
      "\n",
      "Training Loss:  0.07580186725720249 \n",
      "Valid Loss:  33.18034977272499\n",
      "--------------------------------------Epoch 663 ------------------------------\n",
      "\n",
      "Training Loss:  0.08815974755597668 \n",
      "Valid Loss:  84.2867568915359\n",
      "--------------------------------------Epoch 664 ------------------------------\n",
      "\n",
      "Training Loss:  0.07821375516223114 \n",
      "Valid Loss:  40.90366598411275\n",
      "--------------------------------------Epoch 665 ------------------------------\n",
      "\n",
      "Training Loss:  0.08813254283880921 \n",
      "Valid Loss:  47.6280777997085\n",
      "--------------------------------------Epoch 666 ------------------------------\n",
      "\n",
      "Training Loss:  0.08497318303719452 \n",
      "Valid Loss:  40.03524805475092\n",
      "--------------------------------------Epoch 667 ------------------------------\n",
      "\n",
      "Training Loss:  0.10911373989159487 \n",
      "Valid Loss:  43.67619202987475\n",
      "--------------------------------------Epoch 668 ------------------------------\n",
      "\n",
      "Training Loss:  0.07737399049033857 \n",
      "Valid Loss:  32.36271227443495\n",
      "--------------------------------------Epoch 669 ------------------------------\n",
      "\n",
      "Training Loss:  0.08138902738940323 \n",
      "Valid Loss:  36.044595119886644\n",
      "--------------------------------------Epoch 670 ------------------------------\n",
      "\n",
      "Training Loss:  0.0783667278290006 \n",
      "Valid Loss:  34.808221851332746\n",
      "--------------------------------------Epoch 671 ------------------------------\n",
      "\n",
      "Training Loss:  0.0799273063531516 \n",
      "Valid Loss:  36.735081250469825\n",
      "--------------------------------------Epoch 672 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.09031506864922492 \n",
      "Valid Loss:  42.171193043243896\n",
      "--------------------------------------Epoch 673 ------------------------------\n",
      "\n",
      "Training Loss:  0.08146319247703447 \n",
      "Valid Loss:  37.76528941430405\n",
      "--------------------------------------Epoch 674 ------------------------------\n",
      "\n",
      "Training Loss:  0.07803659351379165 \n",
      "Valid Loss:  31.558575958335464\n",
      "--------------------------------------Epoch 675 ------------------------------\n",
      "\n",
      "Training Loss:  0.07578584273270268 \n",
      "Valid Loss:  31.566494607222655\n",
      "--------------------------------------Epoch 676 ------------------------------\n",
      "\n",
      "Training Loss:  0.08186367783725472 \n",
      "Valid Loss:  37.084173193356406\n",
      "--------------------------------------Epoch 677 ------------------------------\n",
      "\n",
      "Training Loss:  0.07858574920842609 \n",
      "Valid Loss:  39.83034010277264\n",
      "--------------------------------------Epoch 678 ------------------------------\n",
      "\n",
      "Training Loss:  0.07841059059219543 \n",
      "Valid Loss:  41.111690521525354\n",
      "--------------------------------------Epoch 679 ------------------------------\n",
      "\n",
      "Training Loss:  0.09543693283268448 \n",
      "Valid Loss:  75.85342820613268\n",
      "--------------------------------------Epoch 680 ------------------------------\n",
      "\n",
      "Training Loss:  0.07854589001202444 \n",
      "Valid Loss:  49.92528699723017\n",
      "--------------------------------------Epoch 681 ------------------------------\n",
      "\n",
      "Training Loss:  0.07465973677379074 \n",
      "Valid Loss:  47.627341969682924\n",
      "--------------------------------------Epoch 682 ------------------------------\n",
      "\n",
      "Training Loss:  0.07569356005808127 \n",
      "Valid Loss:  52.211401048719445\n",
      "--------------------------------------Epoch 683 ------------------------------\n",
      "\n",
      "Training Loss:  0.07496699236535251 \n",
      "Valid Loss:  43.89417294035375\n",
      "--------------------------------------Epoch 684 ------------------------------\n",
      "\n",
      "Training Loss:  0.07539261503158347 \n",
      "Valid Loss:  52.74659526779917\n",
      "--------------------------------------Epoch 685 ------------------------------\n",
      "\n",
      "Training Loss:  0.08557151945557329 \n",
      "Valid Loss:  46.102023719701386\n",
      "--------------------------------------Epoch 686 ------------------------------\n",
      "\n",
      "Training Loss:  0.08739507314428129 \n",
      "Valid Loss:  53.79585640545098\n",
      "--------------------------------------Epoch 687 ------------------------------\n",
      "\n",
      "Training Loss:  0.08226586130041111 \n",
      "Valid Loss:  60.7393814233007\n",
      "--------------------------------------Epoch 688 ------------------------------\n",
      "\n",
      "Training Loss:  0.11831239928221302 \n",
      "Valid Loss:  112.94683537530138\n",
      "--------------------------------------Epoch 689 ------------------------------\n",
      "\n",
      "Training Loss:  0.08657268630974942 \n",
      "Valid Loss:  53.52883969363592\n",
      "--------------------------------------Epoch 690 ------------------------------\n",
      "\n",
      "Training Loss:  0.08406998446815102 \n",
      "Valid Loss:  45.43450735185402\n",
      "--------------------------------------Epoch 691 ------------------------------\n",
      "\n",
      "Training Loss:  0.08079926320342867 \n",
      "Valid Loss:  53.48795980500425\n",
      "--------------------------------------Epoch 692 ------------------------------\n",
      "\n",
      "Training Loss:  0.07976584236212834 \n",
      "Valid Loss:  38.92585568117566\n",
      "--------------------------------------Epoch 693 ------------------------------\n",
      "\n",
      "Training Loss:  0.1075087468801507 \n",
      "Valid Loss:  79.36551183567843\n",
      "--------------------------------------Epoch 694 ------------------------------\n",
      "\n",
      "Training Loss:  0.08823210015127549 \n",
      "Valid Loss:  50.16309359365247\n",
      "--------------------------------------Epoch 695 ------------------------------\n",
      "\n",
      "Training Loss:  0.0989251813459084 \n",
      "Valid Loss:  68.29842140572146\n",
      "--------------------------------------Epoch 696 ------------------------------\n",
      "\n",
      "Training Loss:  0.081653321193813 \n",
      "Valid Loss:  42.66188776622665\n",
      "--------------------------------------Epoch 697 ------------------------------\n",
      "\n",
      "Training Loss:  0.0790446502396186 \n",
      "Valid Loss:  48.22206624527298\n",
      "--------------------------------------Epoch 698 ------------------------------\n",
      "\n",
      "Training Loss:  0.08527658538742393 \n",
      "Valid Loss:  41.00965689253887\n",
      "--------------------------------------Epoch 699 ------------------------------\n",
      "\n",
      "Training Loss:  0.08535068856190219 \n",
      "Valid Loss:  47.24544881469446\n",
      "--------------------------------------Epoch 700 ------------------------------\n",
      "\n",
      "Training Loss:  0.08433506725556925 \n",
      "Valid Loss:  41.72791184353866\n",
      "--------------------------------------Epoch 701 ------------------------------\n",
      "\n",
      "Training Loss:  0.082625624124217 \n",
      "Valid Loss:  46.382966190711606\n",
      "--------------------------------------Epoch 702 ------------------------------\n",
      "\n",
      "Training Loss:  0.07663987987445693 \n",
      "Valid Loss:  64.11007143598948\n",
      "--------------------------------------Epoch 703 ------------------------------\n",
      "\n",
      "Training Loss:  0.07713395246291206 \n",
      "Valid Loss:  39.93310581824321\n",
      "--------------------------------------Epoch 704 ------------------------------\n",
      "\n",
      "Training Loss:  0.08673922841105734 \n",
      "Valid Loss:  46.84855670011605\n",
      "--------------------------------------Epoch 705 ------------------------------\n",
      "\n",
      "Training Loss:  0.07905715571569648 \n",
      "Valid Loss:  44.871364072091595\n",
      "--------------------------------------Epoch 706 ------------------------------\n",
      "\n",
      "Training Loss:  0.08667673859474449 \n",
      "Valid Loss:  56.66140299745388\n",
      "--------------------------------------Epoch 707 ------------------------------\n",
      "\n",
      "Training Loss:  0.07744594642220483 \n",
      "Valid Loss:  40.81148434697964\n",
      "--------------------------------------Epoch 708 ------------------------------\n",
      "\n",
      "Training Loss:  0.09051376818032131 \n",
      "Valid Loss:  49.92450222959095\n",
      "--------------------------------------Epoch 709 ------------------------------\n",
      "\n",
      "Training Loss:  0.08254546037264199 \n",
      "Valid Loss:  47.575229822149666\n",
      "--------------------------------------Epoch 710 ------------------------------\n",
      "\n",
      "Training Loss:  0.08899738057375832 \n",
      "Valid Loss:  45.32968349662686\n",
      "--------------------------------------Epoch 711 ------------------------------\n",
      "\n",
      "Training Loss:  0.07885782220733234 \n",
      "Valid Loss:  38.02602793400604\n",
      "--------------------------------------Epoch 712 ------------------------------\n",
      "\n",
      "Training Loss:  0.07816689711446055 \n",
      "Valid Loss:  35.96774307485355\n",
      "--------------------------------------Epoch 713 ------------------------------\n",
      "\n",
      "Training Loss:  0.07544936173674505 \n",
      "Valid Loss:  36.42816123036032\n",
      "--------------------------------------Epoch 714 ------------------------------\n",
      "\n",
      "Training Loss:  0.10002934655791508 \n",
      "Valid Loss:  44.91258609321082\n",
      "--------------------------------------Epoch 715 ------------------------------\n",
      "\n",
      "Training Loss:  0.0802768515369891 \n",
      "Valid Loss:  45.957597030022846\n",
      "--------------------------------------Epoch 716 ------------------------------\n",
      "\n",
      "Training Loss:  0.08721524419184222 \n",
      "Valid Loss:  41.41924912727171\n",
      "--------------------------------------Epoch 717 ------------------------------\n",
      "\n",
      "Training Loss:  0.07966915431595618 \n",
      "Valid Loss:  34.29846444364927\n",
      "--------------------------------------Epoch 718 ------------------------------\n",
      "\n",
      "Training Loss:  0.09765987600069043 \n",
      "Valid Loss:  44.61075282541152\n",
      "--------------------------------------Epoch 719 ------------------------------\n",
      "\n",
      "Training Loss:  0.0782014198277323 \n",
      "Valid Loss:  35.19425521014105\n",
      "--------------------------------------Epoch 720 ------------------------------\n",
      "\n",
      "Training Loss:  0.07546986547539766 \n",
      "Valid Loss:  36.870462679980164\n",
      "--------------------------------------Epoch 721 ------------------------------\n",
      "\n",
      "Training Loss:  0.07797943593816122 \n",
      "Valid Loss:  32.0886137667989\n",
      "--------------------------------------Epoch 722 ------------------------------\n",
      "\n",
      "Training Loss:  0.07781277447832234 \n",
      "Valid Loss:  32.315284629515816\n",
      "--------------------------------------Epoch 723 ------------------------------\n",
      "\n",
      "Training Loss:  0.07735566272401374 \n",
      "Valid Loss:  34.71110295478563\n",
      "--------------------------------------Epoch 724 ------------------------------\n",
      "\n",
      "Training Loss:  0.0759255459453535 \n",
      "Valid Loss:  30.623753919366752\n",
      "--------------------------------------Epoch 725 ------------------------------\n",
      "\n",
      "Training Loss:  0.11510997840537701 \n",
      "Valid Loss:  55.03152563995264\n",
      "--------------------------------------Epoch 726 ------------------------------\n",
      "\n",
      "Training Loss:  0.08142829531467143 \n",
      "Valid Loss:  31.957540555487828\n",
      "--------------------------------------Epoch 727 ------------------------------\n",
      "\n",
      "Training Loss:  0.07514406748408872 \n",
      "Valid Loss:  32.324752480443\n",
      "--------------------------------------Epoch 728 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.07590502303052991 \n",
      "Valid Loss:  31.15489727191506\n",
      "--------------------------------------Epoch 729 ------------------------------\n",
      "\n",
      "Training Loss:  0.0736412062790467 \n",
      "Valid Loss:  35.40912193893328\n",
      "--------------------------------------Epoch 730 ------------------------------\n",
      "\n",
      "Training Loss:  0.07378239720573973 \n",
      "Valid Loss:  34.22426270543947\n",
      "--------------------------------------Epoch 731 ------------------------------\n",
      "\n",
      "Training Loss:  0.09104872720257669 \n",
      "Valid Loss:  38.494054883208165\n",
      "--------------------------------------Epoch 732 ------------------------------\n",
      "\n",
      "Training Loss:  0.07780190391859583 \n",
      "Valid Loss:  32.378316507568066\n",
      "--------------------------------------Epoch 733 ------------------------------\n",
      "\n",
      "Training Loss:  0.08317286209281265 \n",
      "Valid Loss:  32.98447646129788\n",
      "--------------------------------------Epoch 734 ------------------------------\n",
      "\n",
      "Training Loss:  0.09451103191937658 \n",
      "Valid Loss:  41.768926118775276\n",
      "--------------------------------------Epoch 735 ------------------------------\n",
      "\n",
      "Training Loss:  0.08300090794085055 \n",
      "Valid Loss:  40.88389396973091\n",
      "--------------------------------------Epoch 736 ------------------------------\n",
      "\n",
      "Training Loss:  0.07869673576470922 \n",
      "Valid Loss:  32.221764168401236\n",
      "--------------------------------------Epoch 737 ------------------------------\n",
      "\n",
      "Training Loss:  0.07609924244850805 \n",
      "Valid Loss:  31.24762248049006\n",
      "--------------------------------------Epoch 738 ------------------------------\n",
      "\n",
      "Training Loss:  0.0835425393530571 \n",
      "Valid Loss:  33.513897819795424\n",
      "--------------------------------------Epoch 739 ------------------------------\n",
      "\n",
      "Training Loss:  0.0786492403178459 \n",
      "Valid Loss:  35.854672142324176\n",
      "--------------------------------------Epoch 740 ------------------------------\n",
      "\n",
      "Training Loss:  0.07756434883613422 \n",
      "Valid Loss:  32.21866516877358\n",
      "--------------------------------------Epoch 741 ------------------------------\n",
      "\n",
      "Training Loss:  0.09529529032747032 \n",
      "Valid Loss:  37.19769481758138\n",
      "--------------------------------------Epoch 742 ------------------------------\n",
      "\n",
      "Training Loss:  0.08352172859818492 \n",
      "Valid Loss:  34.33705993997337\n",
      "--------------------------------------Epoch 743 ------------------------------\n",
      "\n",
      "Training Loss:  0.07556336196380961 \n",
      "Valid Loss:  31.552008746256103\n",
      "--------------------------------------Epoch 744 ------------------------------\n",
      "\n",
      "Training Loss:  0.076327465903953 \n",
      "Valid Loss:  28.372285587074067\n",
      "--------------------------------------Epoch 745 ------------------------------\n",
      "\n",
      "Training Loss:  0.11382604434234883 \n",
      "Valid Loss:  41.69905065579461\n",
      "--------------------------------------Epoch 746 ------------------------------\n",
      "\n",
      "Training Loss:  0.08136621759584842 \n",
      "Valid Loss:  29.211731752603654\n",
      "--------------------------------------Epoch 747 ------------------------------\n",
      "\n",
      "Training Loss:  0.07645194185422902 \n",
      "Valid Loss:  30.818822521063705\n",
      "--------------------------------------Epoch 748 ------------------------------\n",
      "\n",
      "Training Loss:  0.07696805088735098 \n",
      "Valid Loss:  31.431173565378156\n",
      "--------------------------------------Epoch 749 ------------------------------\n",
      "\n",
      "Training Loss:  0.07641190567840156 \n",
      "Valid Loss:  37.598274083655895\n",
      "--------------------------------------Epoch 750 ------------------------------\n",
      "\n",
      "Training Loss:  0.07546748372046526 \n",
      "Valid Loss:  33.485355573912194\n",
      "--------------------------------------Epoch 751 ------------------------------\n",
      "\n",
      "Training Loss:  0.09882162440280277 \n",
      "Valid Loss:  56.62577168350467\n",
      "--------------------------------------Epoch 752 ------------------------------\n",
      "\n",
      "Training Loss:  0.08694232819427329 \n",
      "Valid Loss:  36.82079325088587\n",
      "--------------------------------------Epoch 753 ------------------------------\n",
      "\n",
      "Training Loss:  0.09120471982400506 \n",
      "Valid Loss:  40.08985392196683\n",
      "--------------------------------------Epoch 754 ------------------------------\n",
      "\n",
      "Training Loss:  0.08811901871944766 \n",
      "Valid Loss:  36.97523494117166\n",
      "--------------------------------------Epoch 755 ------------------------------\n",
      "\n",
      "Training Loss:  0.08241726909293409 \n",
      "Valid Loss:  37.44019974268103\n",
      "--------------------------------------Epoch 756 ------------------------------\n",
      "\n",
      "Training Loss:  0.08041183519605519 \n",
      "Valid Loss:  40.98152087200789\n",
      "--------------------------------------Epoch 757 ------------------------------\n",
      "\n",
      "Training Loss:  0.07761145044202107 \n",
      "Valid Loss:  37.04060651178632\n",
      "--------------------------------------Epoch 758 ------------------------------\n",
      "\n",
      "Training Loss:  0.07500586777054194 \n",
      "Valid Loss:  34.422085728095134\n",
      "--------------------------------------Epoch 759 ------------------------------\n",
      "\n",
      "Training Loss:  0.0738595319123543 \n",
      "Valid Loss:  34.30535830958856\n",
      "--------------------------------------Epoch 760 ------------------------------\n",
      "\n",
      "Training Loss:  0.08365538122252236 \n",
      "Valid Loss:  40.282297448161096\n",
      "--------------------------------------Epoch 761 ------------------------------\n",
      "\n",
      "Training Loss:  0.07562868530341037 \n",
      "Valid Loss:  46.24278849324663\n",
      "--------------------------------------Epoch 762 ------------------------------\n",
      "\n",
      "Training Loss:  0.07585281898780592 \n",
      "Valid Loss:  33.84674699712521\n",
      "--------------------------------------Epoch 763 ------------------------------\n",
      "\n",
      "Training Loss:  0.08301755682100315 \n",
      "Valid Loss:  35.52575698796929\n",
      "--------------------------------------Epoch 764 ------------------------------\n",
      "\n",
      "Training Loss:  0.07623780433343295 \n",
      "Valid Loss:  34.90676181329497\n",
      "--------------------------------------Epoch 765 ------------------------------\n",
      "\n",
      "Training Loss:  0.07572904230395101 \n",
      "Valid Loss:  52.29737358966989\n",
      "--------------------------------------Epoch 766 ------------------------------\n",
      "\n",
      "Training Loss:  0.07915887423750662 \n",
      "Valid Loss:  33.56229327133449\n",
      "--------------------------------------Epoch 767 ------------------------------\n",
      "\n",
      "Training Loss:  0.08085410077984642 \n",
      "Valid Loss:  36.727756782185054\n",
      "--------------------------------------Epoch 768 ------------------------------\n",
      "\n",
      "Training Loss:  0.08645824700014099 \n",
      "Valid Loss:  45.530499446885884\n",
      "--------------------------------------Epoch 769 ------------------------------\n",
      "\n",
      "Training Loss:  0.10028497419017109 \n",
      "Valid Loss:  44.01731341391729\n",
      "--------------------------------------Epoch 770 ------------------------------\n",
      "\n",
      "Training Loss:  0.08995148933505849 \n",
      "Valid Loss:  40.306242606226284\n",
      "--------------------------------------Epoch 771 ------------------------------\n",
      "\n",
      "Training Loss:  0.09178985059954187 \n",
      "Valid Loss:  61.10487029666769\n",
      "--------------------------------------Epoch 772 ------------------------------\n",
      "\n",
      "Training Loss:  0.08194341195937413 \n",
      "Valid Loss:  37.25449738120881\n",
      "--------------------------------------Epoch 773 ------------------------------\n",
      "\n",
      "Training Loss:  0.07632229718602894 \n",
      "Valid Loss:  34.69344229223619\n",
      "--------------------------------------Epoch 774 ------------------------------\n",
      "\n",
      "Training Loss:  0.10648783199134595 \n",
      "Valid Loss:  53.72892231209023\n",
      "--------------------------------------Epoch 775 ------------------------------\n",
      "\n",
      "Training Loss:  0.07661444761665831 \n",
      "Valid Loss:  31.383695724514507\n",
      "--------------------------------------Epoch 776 ------------------------------\n",
      "\n",
      "Training Loss:  0.07550188534207734 \n",
      "Valid Loss:  34.68439986381548\n",
      "--------------------------------------Epoch 777 ------------------------------\n",
      "\n",
      "Training Loss:  0.07768808519468298 \n",
      "Valid Loss:  48.911719250970606\n",
      "--------------------------------------Epoch 778 ------------------------------\n",
      "\n",
      "Training Loss:  0.07557197283513911 \n",
      "Valid Loss:  30.937208508718843\n",
      "--------------------------------------Epoch 779 ------------------------------\n",
      "\n",
      "Training Loss:  0.08854584454333463 \n",
      "Valid Loss:  46.18663639426236\n",
      "--------------------------------------Epoch 780 ------------------------------\n",
      "\n",
      "Training Loss:  0.07613923447227133 \n",
      "Valid Loss:  39.33506829924985\n",
      "--------------------------------------Epoch 781 ------------------------------\n",
      "\n",
      "Training Loss:  0.07456050176867603 \n",
      "Valid Loss:  35.2590488672456\n",
      "--------------------------------------Epoch 782 ------------------------------\n",
      "\n",
      "Training Loss:  0.075928161223589 \n",
      "Valid Loss:  40.86471970245704\n",
      "--------------------------------------Epoch 783 ------------------------------\n",
      "\n",
      "Training Loss:  0.07655919116369776 \n",
      "Valid Loss:  35.29598846108665\n",
      "--------------------------------------Epoch 784 ------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss:  0.10620055762930865 \n",
      "Valid Loss:  37.58966862686017\n",
      "--------------------------------------Epoch 785 ------------------------------\n",
      "\n",
      "Training Loss:  0.08682284049586837 \n",
      "Valid Loss:  35.75273909398168\n",
      "--------------------------------------Epoch 786 ------------------------------\n",
      "\n",
      "Training Loss:  0.10169035432593426 \n",
      "Valid Loss:  56.17832542094965\n",
      "--------------------------------------Epoch 787 ------------------------------\n",
      "\n",
      "Training Loss:  0.08133091928973354 \n",
      "Valid Loss:  31.173189268434562\n",
      "--------------------------------------Epoch 788 ------------------------------\n",
      "\n",
      "Training Loss:  0.08735617091402098 \n",
      "Valid Loss:  42.965705299839776\n",
      "--------------------------------------Epoch 789 ------------------------------\n",
      "\n",
      "Training Loss:  0.08892657240379198 \n",
      "Valid Loss:  43.158598535280106\n",
      "--------------------------------------Epoch 790 ------------------------------\n",
      "\n",
      "Training Loss:  0.08123422090877068 \n",
      "Valid Loss:  37.84784158653592\n",
      "--------------------------------------Epoch 791 ------------------------------\n",
      "\n",
      "Training Loss:  0.08500278209772688 \n",
      "Valid Loss:  34.81881766856922\n",
      "--------------------------------------Epoch 792 ------------------------------\n",
      "\n",
      "Training Loss:  0.09571785599628486 \n",
      "Valid Loss:  75.55147372598292\n",
      "--------------------------------------Epoch 793 ------------------------------\n",
      "\n",
      "Training Loss:  0.11961887174375986 \n",
      "Valid Loss:  154.74813699307228\n",
      "--------------------------------------Epoch 794 ------------------------------\n",
      "\n",
      "Training Loss:  0.08934358498124356 \n",
      "Valid Loss:  54.700535993710766\n",
      "--------------------------------------Epoch 795 ------------------------------\n",
      "\n",
      "Training Loss:  0.07839262449864415 \n",
      "Valid Loss:  37.52640996187079\n",
      "--------------------------------------Epoch 796 ------------------------------\n",
      "\n",
      "Training Loss:  0.07516636978881762 \n",
      "Valid Loss:  40.48330693630303\n",
      "--------------------------------------Epoch 797 ------------------------------\n",
      "\n",
      "Training Loss:  0.0747140577344448 \n",
      "Valid Loss:  36.32922622257579\n",
      "--------------------------------------Epoch 798 ------------------------------\n",
      "\n",
      "Training Loss:  0.08068805403423247 \n",
      "Valid Loss:  37.77203071036766\n",
      "--------------------------------------Epoch 799 ------------------------------\n",
      "\n",
      "Training Loss:  0.0824870529050225 \n",
      "Valid Loss:  53.31443243786554\n",
      "--------------------------------------Epoch 800 ------------------------------\n",
      "\n",
      "Training Loss:  0.07809657366122874 \n",
      "Valid Loss:  38.97382507975516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993\n",
      "torch.Size([513, 11])\n",
      "993\n",
      "torch.Size([513, 11])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'split_audios_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2d01b4cbe37a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# apply generate mask from training, testing after training and validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msplit_audios_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training-mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msplit_audios_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training-TEST-mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'split_audios_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "mask, mask_test, network = train_network(nr_epochs=800, train_set=train_set, test_set=test_set)\n",
    "\n",
    "print(len(mask))\n",
    "print(mask[0].shape)\n",
    "\n",
    "print(len(mask_test))\n",
    "print(mask_test[0].shape)\n",
    "\n",
    "# apply generate mask from training, testing after training and validation \n",
    "split_audios_epoch(\"training-mask\", mask)\n",
    "split_audios_epoch(\"training-TEST-mask\", mask_test)\n",
    "\n",
    "valid_mask = eval(network=network, test_set=test_set)\n",
    "split_audios_epoch(\"validation-mask\", valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set loss: 38.97382507975516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply generate mask from training, testing after training and validation \n",
    "split_audios_epoch(\"training-mask\", mask)\n",
    "split_audios_epoch(\"training-TEST-mask\", mask_test)\n",
    "\n",
    "valid_mask = eval(network=network, test_set=test_set)\n",
    "split_audios_epoch(\"validation-mask\", valid_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input and target sent to CUDA\n",
      "Train Epoch: 1 [0/997 (0%)]\tLoss: 0.045482\n",
      "Train Epoch: 1 [10/997 (1%)]\tLoss: 0.040284\n",
      "Train Epoch: 1 [20/997 (2%)]\tLoss: 0.108915\n",
      "Train Epoch: 1 [30/997 (3%)]\tLoss: 0.386990\n",
      "Train Epoch: 1 [40/997 (4%)]\tLoss: 0.535919\n",
      "Train Epoch: 1 [50/997 (5%)]\tLoss: 0.502154\n",
      "Train Epoch: 1 [60/997 (6%)]\tLoss: 0.428798\n",
      "Train Epoch: 1 [70/997 (7%)]\tLoss: 0.342384\n",
      "Train Epoch: 1 [80/997 (8%)]\tLoss: 0.279553\n",
      "Train Epoch: 1 [90/997 (9%)]\tLoss: 0.338721\n",
      "Train Epoch: 1 [100/997 (10%)]\tLoss: 0.207496\n",
      "Train Epoch: 1 [110/997 (11%)]\tLoss: 0.104407\n",
      "Train Epoch: 1 [120/997 (12%)]\tLoss: 0.052740\n",
      "Train Epoch: 1 [130/997 (13%)]\tLoss: 0.093411\n",
      "Train Epoch: 1 [140/997 (14%)]\tLoss: 0.328593\n",
      "Train Epoch: 1 [150/997 (15%)]\tLoss: 0.057406\n",
      "Train Epoch: 1 [160/997 (16%)]\tLoss: 0.247350\n",
      "Train Epoch: 1 [170/997 (17%)]\tLoss: 0.368980\n",
      "Train Epoch: 1 [180/997 (18%)]\tLoss: 0.216839\n",
      "Train Epoch: 1 [190/997 (19%)]\tLoss: 0.076148\n",
      "Train Epoch: 1 [200/997 (20%)]\tLoss: 0.066559\n",
      "Train Epoch: 1 [210/997 (21%)]\tLoss: 0.080155\n",
      "Train Epoch: 1 [220/997 (22%)]\tLoss: 0.149601\n",
      "Train Epoch: 1 [230/997 (23%)]\tLoss: 0.275532\n",
      "Train Epoch: 1 [240/997 (24%)]\tLoss: 0.091165\n",
      "Train Epoch: 1 [250/997 (25%)]\tLoss: 0.192868\n",
      "Train Epoch: 1 [260/997 (26%)]\tLoss: 0.248300\n",
      "Train Epoch: 1 [270/997 (27%)]\tLoss: 0.109356\n",
      "Train Epoch: 1 [280/997 (28%)]\tLoss: 0.104185\n",
      "Train Epoch: 1 [290/997 (29%)]\tLoss: 0.212662\n",
      "Train Epoch: 1 [300/997 (30%)]\tLoss: 0.117739\n",
      "Train Epoch: 1 [310/997 (31%)]\tLoss: 0.063100\n",
      "Train Epoch: 1 [320/997 (32%)]\tLoss: 0.088730\n",
      "Train Epoch: 1 [330/997 (33%)]\tLoss: 0.083038\n",
      "Train Epoch: 1 [340/997 (34%)]\tLoss: 0.158974\n",
      "Train Epoch: 1 [350/997 (35%)]\tLoss: 0.181319\n",
      "Train Epoch: 1 [360/997 (36%)]\tLoss: 0.093876\n",
      "Train Epoch: 1 [370/997 (37%)]\tLoss: 0.111343\n",
      "Train Epoch: 1 [380/997 (38%)]\tLoss: 0.066091\n",
      "Train Epoch: 1 [390/997 (39%)]\tLoss: 0.086840\n",
      "Train Epoch: 1 [400/997 (40%)]\tLoss: 0.142160\n",
      "Train Epoch: 1 [410/997 (41%)]\tLoss: 0.149704\n",
      "Train Epoch: 1 [420/997 (42%)]\tLoss: 0.100268\n",
      "Train Epoch: 1 [430/997 (43%)]\tLoss: 0.169860\n",
      "Train Epoch: 1 [440/997 (44%)]\tLoss: 0.191761\n",
      "Train Epoch: 1 [450/997 (45%)]\tLoss: 0.132187\n",
      "Train Epoch: 1 [460/997 (46%)]\tLoss: 0.132330\n",
      "Train Epoch: 1 [470/997 (47%)]\tLoss: 0.073979\n",
      "Train Epoch: 1 [480/997 (48%)]\tLoss: 0.119663\n",
      "Train Epoch: 1 [490/997 (49%)]\tLoss: 0.080200\n",
      "Train Epoch: 1 [500/997 (50%)]\tLoss: 0.128514\n",
      "Train Epoch: 1 [510/997 (51%)]\tLoss: 0.114722\n",
      "Train Epoch: 1 [520/997 (52%)]\tLoss: 0.109767\n",
      "Train Epoch: 1 [530/997 (53%)]\tLoss: 0.106231\n",
      "Train Epoch: 1 [540/997 (54%)]\tLoss: 0.128016\n",
      "Train Epoch: 1 [550/997 (55%)]\tLoss: 0.075906\n",
      "Train Epoch: 1 [560/997 (56%)]\tLoss: 0.077291\n",
      "Train Epoch: 1 [570/997 (57%)]\tLoss: 0.105438\n",
      "Train Epoch: 1 [580/997 (58%)]\tLoss: 0.150372\n",
      "Train Epoch: 1 [590/997 (59%)]\tLoss: 0.119494\n",
      "Train Epoch: 1 [600/997 (60%)]\tLoss: 0.083358\n",
      "Train Epoch: 1 [610/997 (61%)]\tLoss: 0.079597\n",
      "Train Epoch: 1 [620/997 (62%)]\tLoss: 0.169866\n",
      "Train Epoch: 1 [630/997 (63%)]\tLoss: 0.169321\n",
      "Train Epoch: 1 [640/997 (64%)]\tLoss: 0.132657\n",
      "Train Epoch: 1 [650/997 (65%)]\tLoss: 0.086482\n",
      "Train Epoch: 1 [660/997 (66%)]\tLoss: 0.075783\n",
      "Train Epoch: 1 [670/997 (67%)]\tLoss: 0.061614\n",
      "Train Epoch: 1 [680/997 (68%)]\tLoss: 0.076773\n",
      "Train Epoch: 1 [690/997 (69%)]\tLoss: 0.178952\n",
      "Train Epoch: 1 [700/997 (70%)]\tLoss: 0.178935\n",
      "Train Epoch: 1 [710/997 (71%)]\tLoss: 0.181738\n",
      "Train Epoch: 1 [720/997 (72%)]\tLoss: 0.226983\n",
      "Train Epoch: 1 [730/997 (73%)]\tLoss: 0.122210\n",
      "Train Epoch: 1 [740/997 (74%)]\tLoss: 0.284340\n",
      "Train Epoch: 1 [750/997 (75%)]\tLoss: 0.246078\n",
      "Train Epoch: 1 [760/997 (76%)]\tLoss: 0.261696\n",
      "Train Epoch: 1 [770/997 (77%)]\tLoss: 0.227542\n",
      "Train Epoch: 1 [780/997 (78%)]\tLoss: 0.168967\n",
      "Train Epoch: 1 [790/997 (79%)]\tLoss: 0.157010\n",
      "Train Epoch: 1 [800/997 (80%)]\tLoss: 0.200121\n",
      "Train Epoch: 1 [810/997 (81%)]\tLoss: 0.167542\n",
      "Train Epoch: 1 [820/997 (82%)]\tLoss: 0.189853\n",
      "Train Epoch: 1 [830/997 (83%)]\tLoss: 0.154120\n",
      "Train Epoch: 1 [840/997 (84%)]\tLoss: 0.116849\n",
      "Train Epoch: 1 [850/997 (85%)]\tLoss: 0.146261\n",
      "Train Epoch: 1 [860/997 (86%)]\tLoss: 0.149794\n",
      "Train Epoch: 1 [870/997 (87%)]\tLoss: 0.101054\n",
      "Train Epoch: 1 [880/997 (88%)]\tLoss: 0.116234\n",
      "Train Epoch: 1 [890/997 (89%)]\tLoss: 0.084451\n",
      "Train Epoch: 1 [900/997 (90%)]\tLoss: 0.095311\n",
      "Train Epoch: 1 [910/997 (91%)]\tLoss: 0.117290\n",
      "Train Epoch: 1 [920/997 (92%)]\tLoss: 0.073523\n",
      "Train Epoch: 1 [930/997 (93%)]\tLoss: 0.107564\n",
      "Train Epoch: 1 [940/997 (94%)]\tLoss: 0.063144\n",
      "Train Epoch: 1 [950/997 (95%)]\tLoss: 0.072459\n",
      "Train Epoch: 1 [960/997 (96%)]\tLoss: 0.055890\n",
      "Train Epoch: 1 [970/997 (97%)]\tLoss: 0.061158\n",
      "Train Epoch: 1 [980/997 (98%)]\tLoss: 0.083958\n",
      "Train Epoch: 1 [990/997 (99%)]\tLoss: 0.055460\n",
      "input and target sent to CUDA\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1536, 0.1540, 0.1440,  ..., 0.2061, 0.2061, 0.1963], device='cuda:0')\n",
      "t tensor([0.0047, 0.0047, 0.0047,  ..., 0.3258, 0.3257, 0.3256], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1825, 0.1646, 0.1739,  ..., 0.2643, 0.2697, 0.2780], device='cuda:0')\n",
      "t tensor([0.0247, 0.0247, 0.0247,  ..., 0.0017, 0.0020, 0.0021], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1559, 0.1521, 0.1487,  ..., 0.2155, 0.2347, 0.2326], device='cuda:0')\n",
      "t tensor([0.0348, 0.0348, 0.0348,  ..., 0.4665, 0.4665, 0.4665], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1768, 0.1629, 0.1742,  ..., 0.2606, 0.2661, 0.2753], device='cuda:0')\n",
      "t tensor([0.6048, 0.6048, 0.6047,  ..., 0.9539, 0.9540, 0.9540], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1337, 0.1453, 0.1371,  ..., 0.1957, 0.1968, 0.1870], device='cuda:0')\n",
      "t tensor([0.7523, 0.7524, 0.7524,  ..., 0.9628, 0.9628, 0.9628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1317, 0.1452, 0.1375,  ..., 0.1952, 0.1945, 0.1849], device='cuda:0')\n",
      "t tensor([0.5879, 0.5898, 0.5951,  ..., 0.9336, 0.9336, 0.9336], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1386, 0.1462, 0.1372,  ..., 0.1966, 0.1988, 0.1883], device='cuda:0')\n",
      "t tensor([0.3946, 0.3929, 0.3882,  ..., 0.9903, 0.9904, 0.9904], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1658, 0.1542, 0.1503,  ..., 0.2408, 0.2741, 0.2569], device='cuda:0')\n",
      "t tensor([0.0886, 0.0886, 0.0887,  ..., 0.8846, 0.8844, 0.8844], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1427, 0.1467, 0.1370,  ..., 0.1974, 0.2001, 0.1885], device='cuda:0')\n",
      "t tensor([0.7348, 0.7348, 0.7347,  ..., 0.5635, 0.5635, 0.5635], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1374, 0.1458, 0.1371,  ..., 0.1963, 0.1985, 0.1882], device='cuda:0')\n",
      "t tensor([0.5335, 0.5334, 0.5330,  ..., 0.6007, 0.6014, 0.6016], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1402, 0.1461, 0.1372,  ..., 0.1965, 0.1983, 0.1871], device='cuda:0')\n",
      "t tensor([0.4988, 0.4988, 0.4991,  ..., 0.9337, 0.9338, 0.9338], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1393, 0.1461, 0.1373,  ..., 0.1969, 0.1981, 0.1890], device='cuda:0')\n",
      "t tensor([0.0616, 0.0617, 0.0620,  ..., 0.6313, 0.6312, 0.6312], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1357, 0.1460, 0.1373,  ..., 0.1961, 0.1968, 0.1876], device='cuda:0')\n",
      "t tensor([0.2780, 0.2779, 0.2775,  ..., 0.3864, 0.3865, 0.3865], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1395, 0.1460, 0.1372,  ..., 0.1969, 0.1987, 0.1891], device='cuda:0')\n",
      "t tensor([0.2567, 0.2565, 0.2558,  ..., 0.2739, 0.2738, 0.2738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1442, 0.1470, 0.1369,  ..., 0.1980, 0.2003, 0.1896], device='cuda:0')\n",
      "t tensor([0.7539, 0.7537, 0.7530,  ..., 0.9571, 0.9571, 0.9571], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1389, 0.1460, 0.1373,  ..., 0.1967, 0.1989, 0.1889], device='cuda:0')\n",
      "t tensor([0.2040, 0.2035, 0.2020,  ..., 0.4414, 0.4413, 0.4413], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1387, 0.1459, 0.1371,  ..., 0.1967, 0.1987, 0.1887], device='cuda:0')\n",
      "t tensor([0.2856, 0.2856, 0.2854,  ..., 0.8735, 0.8735, 0.8735], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1374, 0.1458, 0.1372,  ..., 0.1963, 0.1985, 0.1882], device='cuda:0')\n",
      "t tensor([0.1827, 0.1823, 0.1809,  ..., 0.9637, 0.9637, 0.9637], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1460, 0.1374,  ..., 0.1966, 0.1982, 0.1886], device='cuda:0')\n",
      "t tensor([0.3747, 0.3743, 0.3730,  ..., 0.6949, 0.6949, 0.6949], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1386, 0.1459, 0.1373,  ..., 0.1966, 0.1988, 0.1887], device='cuda:0')\n",
      "t tensor([0.2302, 0.2302, 0.2301,  ..., 0.6374, 0.6371, 0.6370], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o tensor([0.1374, 0.1458, 0.1371,  ..., 0.1963, 0.1985, 0.1882], device='cuda:0')\n",
      "t tensor([0.2914, 0.2912, 0.2906,  ..., 0.3812, 0.3812, 0.3811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1425, 0.1464, 0.1369,  ..., 0.1971, 0.1989, 0.1881], device='cuda:0')\n",
      "t tensor([0.8507, 0.8507, 0.8507,  ..., 0.1821, 0.1822, 0.1823], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1394, 0.1460, 0.1372,  ..., 0.1968, 0.1987, 0.1891], device='cuda:0')\n",
      "t tensor([0.9335, 0.9334, 0.9333,  ..., 0.0684, 0.0683, 0.0683], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1397, 0.1463, 0.1370,  ..., 0.1966, 0.1964, 0.1866], device='cuda:0')\n",
      "t tensor([0.9413, 0.9413, 0.9414,  ..., 0.7688, 0.7688, 0.7688], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1366, 0.1458, 0.1374,  ..., 0.1962, 0.1964, 0.1873], device='cuda:0')\n",
      "t tensor([0.6306, 0.6306, 0.6305,  ..., 0.6907, 0.6909, 0.6909], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1379, 0.1466, 0.1382,  ..., 0.1965, 0.2003, 0.1882], device='cuda:0')\n",
      "t tensor([0.0256, 0.0256, 0.0255,  ..., 0.9322, 0.9322, 0.9322], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1294, 0.1448, 0.1374,  ..., 0.1947, 0.1931, 0.1823], device='cuda:0')\n",
      "t tensor([0.1775, 0.1775, 0.1775,  ..., 0.9676, 0.9676, 0.9676], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1413, 0.1463, 0.1373,  ..., 0.1976, 0.1990, 0.1900], device='cuda:0')\n",
      "t tensor([0.5727, 0.5722, 0.5708,  ..., 0.3124, 0.3121, 0.3120], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1342, 0.1458, 0.1375,  ..., 0.1958, 0.1947, 0.1860], device='cuda:0')\n",
      "t tensor([0.2348, 0.2342, 0.2325,  ..., 0.4525, 0.4524, 0.4524], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1394, 0.1461, 0.1373,  ..., 0.1969, 0.1982, 0.1890], device='cuda:0')\n",
      "t tensor([0.7909, 0.7908, 0.7906,  ..., 0.8627, 0.8628, 0.8628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1460, 0.1374,  ..., 0.1966, 0.1982, 0.1886], device='cuda:0')\n",
      "t tensor([0.4285, 0.4283, 0.4279,  ..., 0.8922, 0.8919, 0.8919], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1395, 0.1460, 0.1372,  ..., 0.1969, 0.1987, 0.1891], device='cuda:0')\n",
      "t tensor([0.1388, 0.1376, 0.1339,  ..., 0.4811, 0.4811, 0.4811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1374, 0.1458, 0.1371,  ..., 0.1963, 0.1985, 0.1882], device='cuda:0')\n",
      "t tensor([0.1970, 0.1972, 0.1978,  ..., 0.3019, 0.3019, 0.3019], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1460, 0.1374,  ..., 0.1966, 0.1982, 0.1886], device='cuda:0')\n",
      "t tensor([0.4834, 0.4836, 0.4842,  ..., 0.2392, 0.2392, 0.2392], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1666, 0.1529, 0.1483,  ..., 0.2137, 0.2340, 0.2208], device='cuda:0')\n",
      "t tensor([0.2179, 0.2179, 0.2179,  ..., 0.2706, 0.2705, 0.2703], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1804, 0.1582, 0.1603,  ..., 0.2512, 0.2741, 0.2702], device='cuda:0')\n",
      "t tensor([0.0409, 0.0409, 0.0409,  ..., 0.7987, 0.7987, 0.7987], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1300, 0.1453, 0.1370,  ..., 0.1948, 0.1936, 0.1834], device='cuda:0')\n",
      "t tensor([0.0342, 0.0342, 0.0342,  ..., 0.9659, 0.9659, 0.9659], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1355, 0.1458, 0.1373,  ..., 0.1959, 0.1955, 0.1861], device='cuda:0')\n",
      "t tensor([0.3493, 0.3492, 0.3487,  ..., 0.2131, 0.2133, 0.2134], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1360, 0.1459, 0.1373,  ..., 0.1961, 0.1974, 0.1877], device='cuda:0')\n",
      "t tensor([0.5021, 0.5020, 0.5020,  ..., 0.3519, 0.3519, 0.3519], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1385, 0.1460, 0.1374,  ..., 0.1967, 0.1983, 0.1887], device='cuda:0')\n",
      "t tensor([0.5981, 0.5980, 0.5979,  ..., 0.7961, 0.7961, 0.7961], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1420, 0.1463, 0.1371,  ..., 0.1973, 0.2006, 0.1893], device='cuda:0')\n",
      "t tensor([0.7488, 0.7488, 0.7488,  ..., 0.8285, 0.8285, 0.8285], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1365, 0.1456, 0.1369,  ..., 0.1958, 0.1976, 0.1868], device='cuda:0')\n",
      "t tensor([0.0456, 0.0458, 0.0463,  ..., 0.0027, 0.0027, 0.0027], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1352, 0.1456, 0.1411,  ..., 0.1949, 0.1936, 0.1864], device='cuda:0')\n",
      "t tensor([0.5312, 0.5311, 0.5311,  ..., 0.1408, 0.1408, 0.1408], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1872, 0.1666, 0.1749,  ..., 0.2751, 0.2777, 0.2953], device='cuda:0')\n",
      "t tensor([0.2914, 0.2914, 0.2913,  ..., 0.9984, 0.9984, 0.9984], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1903, 0.1688, 0.1758,  ..., 0.2749, 0.2778, 0.2957], device='cuda:0')\n",
      "t tensor([0.5180, 0.5180, 0.5180,  ..., 0.9702, 0.9702, 0.9702], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1915, 0.1677, 0.1770,  ..., 0.2758, 0.2778, 0.2944], device='cuda:0')\n",
      "t tensor([0.1826, 0.1826, 0.1827,  ..., 0.9062, 0.9062, 0.9063], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1651, 0.1554, 0.1679,  ..., 0.2399, 0.2714, 0.2688], device='cuda:0')\n",
      "t tensor([0.1136, 0.1137, 0.1137,  ..., 0.9989, 0.9989, 0.9989], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1320, 0.1454, 0.1370,  ..., 0.1954, 0.1952, 0.1859], device='cuda:0')\n",
      "t tensor([0.4704, 0.4702, 0.4699,  ..., 0.0199, 0.0199, 0.0199], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1386, 0.1459, 0.1373,  ..., 0.1966, 0.1988, 0.1887], device='cuda:0')\n",
      "t tensor([0.9487, 0.9486, 0.9482,  ..., 0.5739, 0.5738, 0.5738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1395, 0.1460, 0.1372,  ..., 0.1969, 0.1987, 0.1891], device='cuda:0')\n",
      "t tensor([0.2798, 0.2796, 0.2791,  ..., 0.7839, 0.7840, 0.7840], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1460, 0.1374,  ..., 0.1966, 0.1982, 0.1886], device='cuda:0')\n",
      "t tensor([0.1696, 0.1689, 0.1668,  ..., 0.8651, 0.8650, 0.8650], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1394, 0.1461, 0.1373,  ..., 0.1969, 0.1983, 0.1891], device='cuda:0')\n",
      "t tensor([0.7236, 0.7236, 0.7235,  ..., 0.6560, 0.6561, 0.6562], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1449, 0.1467, 0.1368,  ..., 0.1978, 0.2011, 0.1889], device='cuda:0')\n",
      "t tensor([0.6936, 0.6936, 0.6935,  ..., 0.7810, 0.7810, 0.7810], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1874, 0.1677, 0.1745,  ..., 0.2748, 0.2778, 0.2955], device='cuda:0')\n",
      "t tensor([0.0778, 0.0778, 0.0777,  ..., 0.9969, 0.9969, 0.9969], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1389, 0.1460, 0.1373,  ..., 0.1967, 0.1984, 0.1887], device='cuda:0')\n",
      "t tensor([0.9165, 0.9165, 0.9165,  ..., 0.3030, 0.3032, 0.3032], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1332, 0.1454, 0.1371,  ..., 0.1957, 0.1959, 0.1868], device='cuda:0')\n",
      "t tensor([0.4204, 0.4204, 0.4205,  ..., 0.3603, 0.3601, 0.3601], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1428, 0.1466, 0.1369,  ..., 0.1972, 0.1993, 0.1883], device='cuda:0')\n",
      "t tensor([0.6500, 0.6501, 0.6502,  ..., 0.7238, 0.7240, 0.7240], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1900, 0.1679, 0.1737,  ..., 0.2759, 0.2778, 0.2916], device='cuda:0')\n",
      "t tensor([0.2068, 0.2069, 0.2069,  ..., 0.8895, 0.8895, 0.8894], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1405, 0.1468, 0.1374,  ..., 0.1973, 0.1983, 0.1887], device='cuda:0')\n",
      "t tensor([0.0011, 0.0011, 0.0011,  ..., 0.9777, 0.9777, 0.9777], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1320, 0.1454, 0.1370,  ..., 0.1954, 0.1952, 0.1859], device='cuda:0')\n",
      "t tensor([0.0587, 0.0587, 0.0587,  ..., 0.9461, 0.9463, 0.9464], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1358, 0.1460, 0.1373,  ..., 0.1961, 0.1968, 0.1876], device='cuda:0')\n",
      "t tensor([0.1505, 0.1516, 0.1547,  ..., 0.3629, 0.3629, 0.3630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1385, 0.1460, 0.1374,  ..., 0.1967, 0.1983, 0.1887], device='cuda:0')\n",
      "t tensor([0.2263, 0.2268, 0.2284,  ..., 0.6039, 0.6040, 0.6041], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1408, 0.1463, 0.1371,  ..., 0.1968, 0.1983, 0.1880], device='cuda:0')\n",
      "t tensor([0.6393, 0.6394, 0.6397,  ..., 0.9386, 0.9385, 0.9385], device='cuda:0')\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1373, 0.1460, 0.1374,  ..., 0.1964, 0.1980, 0.1884], device='cuda:0')\n",
      "t tensor([0.6337, 0.6337, 0.6334,  ..., 0.2633, 0.2631, 0.2630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1458, 0.1376,  ..., 0.1963, 0.1968, 0.1874], device='cuda:0')\n",
      "t tensor([0.7495, 0.7496, 0.7497,  ..., 0.1181, 0.1182, 0.1182], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1363, 0.1465, 0.1370,  ..., 0.1962, 0.1959, 0.1865], device='cuda:0')\n",
      "t tensor([0.8907, 0.8907, 0.8908,  ..., 0.0620, 0.0618, 0.0618], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1384, 0.1460, 0.1374,  ..., 0.1966, 0.1982, 0.1886], device='cuda:0')\n",
      "t tensor([0.2725, 0.2721, 0.2709,  ..., 0.5479, 0.5479, 0.5479], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1422, 0.1466, 0.1367,  ..., 0.1967, 0.1966, 0.1862], device='cuda:0')\n",
      "t tensor([0.8225, 0.8225, 0.8223,  ..., 0.2745, 0.2745, 0.2745], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1365, 0.1463, 0.1365,  ..., 0.1958, 0.1962, 0.1837], device='cuda:0')\n",
      "t tensor([0.4347, 0.4347, 0.4347,  ..., 0.5438, 0.5438, 0.5439], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1369, 0.1456, 0.1383,  ..., 0.1954, 0.1956, 0.1874], device='cuda:0')\n",
      "t tensor([0.1683, 0.1683, 0.1683,  ..., 0.0104, 0.0104, 0.0104], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1625, 0.1524, 0.1449,  ..., 0.2140, 0.2290, 0.2225], device='cuda:0')\n",
      "t tensor([0.0155, 0.0155, 0.0155,  ..., 0.2109, 0.2109, 0.2109], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1361, 0.1461, 0.1375,  ..., 0.1959, 0.1947, 0.1851], device='cuda:0')\n",
      "t tensor([0.0041, 0.0041, 0.0041,  ..., 0.1236, 0.1236, 0.1236], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1392, 0.1460, 0.1373,  ..., 0.1972, 0.1980, 0.1901], device='cuda:0')\n",
      "t tensor([0.2529, 0.2529, 0.2529,  ..., 0.0449, 0.0448, 0.0447], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1454, 0.1521, 0.1460,  ..., 0.2080, 0.2194, 0.2182], device='cuda:0')\n",
      "t tensor([7.9046e-05, 7.8999e-05, 7.8867e-05,  ..., 4.1099e-01, 4.1101e-01,\n",
      "        4.1101e-01], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1691, 0.1581, 0.1599,  ..., 0.2411, 0.2480, 0.2513], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1413, 0.1463, 0.1372,  ..., 0.1976, 0.1989, 0.1900], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1391, 0.1462, 0.1374,  ..., 0.1968, 0.1980, 0.1890], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1372, 0.1458, 0.1376,  ..., 0.1961, 0.1964, 0.1872], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1334, 0.1453, 0.1370,  ..., 0.1956, 0.1968, 0.1865], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1310, 0.1452, 0.1375,  ..., 0.1951, 0.1939, 0.1841], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1474, 0.1482, 0.1392,  ..., 0.1990, 0.2033, 0.1958], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1816, 0.1591, 0.1606,  ..., 0.2504, 0.2640, 0.2666], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1801, 0.1591, 0.1608,  ..., 0.2482, 0.2543, 0.2691], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1582, 0.1556, 0.1470,  ..., 0.2117, 0.2208, 0.2112], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1442, 0.1615, 0.1616,  ..., 0.2170, 0.2051, 0.2076], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1783, 0.1658, 0.1797,  ..., 0.2678, 0.2697, 0.2803], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1753, 0.1574, 0.1587,  ..., 0.2399, 0.2533, 0.2603], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1541, 0.1651, 0.1707,  ..., 0.2375, 0.2197, 0.2232], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1739, 0.1594, 0.1655,  ..., 0.2469, 0.2607, 0.2707], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1513, 0.1577, 0.1575,  ..., 0.2244, 0.2329, 0.2325], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1443, 0.1604, 0.1609,  ..., 0.2224, 0.2110, 0.2120], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1789, 0.1600, 0.1669,  ..., 0.2555, 0.2674, 0.2746], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1665, 0.1660, 0.1661,  ..., 0.2300, 0.2127, 0.2128], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1832, 0.1640, 0.1747,  ..., 0.2660, 0.2717, 0.2829], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1372, 0.1572, 0.1502,  ..., 0.2017, 0.1963, 0.1896], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1683, 0.1563, 0.1555,  ..., 0.2250, 0.2440, 0.2440], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1675, 0.1627, 0.1597,  ..., 0.2273, 0.2258, 0.2169], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1641, 0.1565, 0.1520,  ..., 0.2261, 0.2387, 0.2324], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1791, 0.1674, 0.1741,  ..., 0.2613, 0.2590, 0.2542], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1465, 0.1530, 0.1484,  ..., 0.2153, 0.2260, 0.2213], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "[0.3525697973107502, 0.20350569114462663, 0.19294637319264762, tensor(0.1915, device='cuda:0'), tensor(0.1936, device='cuda:0'), tensor(0.1925, device='cuda:0'), tensor(0.1946, device='cuda:0')]\n",
      "\n",
      "Test set: Avg. loss: 0.1946, Accuracy: 0/997 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input and target sent to CUDA\n",
      "Train Epoch: 2 [0/997 (0%)]\tLoss: 0.046808\n",
      "Train Epoch: 2 [10/997 (1%)]\tLoss: 0.041776\n",
      "Train Epoch: 2 [20/997 (2%)]\tLoss: 0.111372\n",
      "Train Epoch: 2 [30/997 (3%)]\tLoss: 0.398673\n",
      "Train Epoch: 2 [40/997 (4%)]\tLoss: 0.554127\n",
      "Train Epoch: 2 [50/997 (5%)]\tLoss: 0.486398\n",
      "Train Epoch: 2 [60/997 (6%)]\tLoss: 0.422419\n",
      "Train Epoch: 2 [70/997 (7%)]\tLoss: 0.338737\n",
      "Train Epoch: 2 [80/997 (8%)]\tLoss: 0.268588\n",
      "Train Epoch: 2 [90/997 (9%)]\tLoss: 0.358855\n",
      "Train Epoch: 2 [100/997 (10%)]\tLoss: 0.185204\n",
      "Train Epoch: 2 [110/997 (11%)]\tLoss: 0.099064\n",
      "Train Epoch: 2 [120/997 (12%)]\tLoss: 0.053698\n",
      "Train Epoch: 2 [130/997 (13%)]\tLoss: 0.093940\n",
      "Train Epoch: 2 [140/997 (14%)]\tLoss: 0.311855\n",
      "Train Epoch: 2 [150/997 (15%)]\tLoss: 0.057570\n",
      "Train Epoch: 2 [160/997 (16%)]\tLoss: 0.249835\n",
      "Train Epoch: 2 [170/997 (17%)]\tLoss: 0.352981\n",
      "Train Epoch: 2 [180/997 (18%)]\tLoss: 0.202833\n",
      "Train Epoch: 2 [190/997 (19%)]\tLoss: 0.077381\n",
      "Train Epoch: 2 [200/997 (20%)]\tLoss: 0.064421\n",
      "Train Epoch: 2 [210/997 (21%)]\tLoss: 0.080428\n",
      "Train Epoch: 2 [220/997 (22%)]\tLoss: 0.155860\n",
      "Train Epoch: 2 [230/997 (23%)]\tLoss: 0.279472\n",
      "Train Epoch: 2 [240/997 (24%)]\tLoss: 0.094303\n",
      "Train Epoch: 2 [250/997 (25%)]\tLoss: 0.185883\n",
      "Train Epoch: 2 [260/997 (26%)]\tLoss: 0.272420\n",
      "Train Epoch: 2 [270/997 (27%)]\tLoss: 0.108766\n",
      "Train Epoch: 2 [280/997 (28%)]\tLoss: 0.107831\n",
      "Train Epoch: 2 [290/997 (29%)]\tLoss: 0.195566\n",
      "Train Epoch: 2 [300/997 (30%)]\tLoss: 0.120163\n",
      "Train Epoch: 2 [310/997 (31%)]\tLoss: 0.062307\n",
      "Train Epoch: 2 [320/997 (32%)]\tLoss: 0.085363\n",
      "Train Epoch: 2 [330/997 (33%)]\tLoss: 0.085294\n",
      "Train Epoch: 2 [340/997 (34%)]\tLoss: 0.152597\n",
      "Train Epoch: 2 [350/997 (35%)]\tLoss: 0.171219\n",
      "Train Epoch: 2 [360/997 (36%)]\tLoss: 0.093763\n",
      "Train Epoch: 2 [370/997 (37%)]\tLoss: 0.105283\n",
      "Train Epoch: 2 [380/997 (38%)]\tLoss: 0.063925\n",
      "Train Epoch: 2 [390/997 (39%)]\tLoss: 0.073903\n",
      "Train Epoch: 2 [400/997 (40%)]\tLoss: 0.143814\n",
      "Train Epoch: 2 [410/997 (41%)]\tLoss: 0.138065\n",
      "Train Epoch: 2 [420/997 (42%)]\tLoss: 0.092889\n",
      "Train Epoch: 2 [430/997 (43%)]\tLoss: 0.173662\n",
      "Train Epoch: 2 [440/997 (44%)]\tLoss: 0.200724\n",
      "Train Epoch: 2 [450/997 (45%)]\tLoss: 0.131193\n",
      "Train Epoch: 2 [460/997 (46%)]\tLoss: 0.123390\n",
      "Train Epoch: 2 [470/997 (47%)]\tLoss: 0.080033\n",
      "Train Epoch: 2 [480/997 (48%)]\tLoss: 0.127560\n",
      "Train Epoch: 2 [490/997 (49%)]\tLoss: 0.083054\n",
      "Train Epoch: 2 [500/997 (50%)]\tLoss: 0.146854\n",
      "Train Epoch: 2 [510/997 (51%)]\tLoss: 0.101993\n",
      "Train Epoch: 2 [520/997 (52%)]\tLoss: 0.082132\n",
      "Train Epoch: 2 [530/997 (53%)]\tLoss: 0.127839\n",
      "Train Epoch: 2 [540/997 (54%)]\tLoss: 0.132615\n",
      "Train Epoch: 2 [550/997 (55%)]\tLoss: 0.076345\n",
      "Train Epoch: 2 [560/997 (56%)]\tLoss: 0.072053\n",
      "Train Epoch: 2 [570/997 (57%)]\tLoss: 0.103800\n",
      "Train Epoch: 2 [580/997 (58%)]\tLoss: 0.118331\n",
      "Train Epoch: 2 [590/997 (59%)]\tLoss: 0.125248\n",
      "Train Epoch: 2 [600/997 (60%)]\tLoss: 0.096809\n",
      "Train Epoch: 2 [610/997 (61%)]\tLoss: 0.086563\n",
      "Train Epoch: 2 [620/997 (62%)]\tLoss: 0.158875\n",
      "Train Epoch: 2 [630/997 (63%)]\tLoss: 0.149462\n",
      "Train Epoch: 2 [640/997 (64%)]\tLoss: 0.125639\n",
      "Train Epoch: 2 [650/997 (65%)]\tLoss: 0.107869\n",
      "Train Epoch: 2 [660/997 (66%)]\tLoss: 0.078952\n",
      "Train Epoch: 2 [670/997 (67%)]\tLoss: 0.058394\n",
      "Train Epoch: 2 [680/997 (68%)]\tLoss: 0.076377\n",
      "Train Epoch: 2 [690/997 (69%)]\tLoss: 0.192092\n",
      "Train Epoch: 2 [700/997 (70%)]\tLoss: 0.159946\n",
      "Train Epoch: 2 [710/997 (71%)]\tLoss: 0.177422\n",
      "Train Epoch: 2 [720/997 (72%)]\tLoss: 0.245453\n",
      "Train Epoch: 2 [730/997 (73%)]\tLoss: 0.132230\n",
      "Train Epoch: 2 [740/997 (74%)]\tLoss: 0.264405\n",
      "Train Epoch: 2 [750/997 (75%)]\tLoss: 0.245831\n",
      "Train Epoch: 2 [760/997 (76%)]\tLoss: 0.240119\n",
      "Train Epoch: 2 [770/997 (77%)]\tLoss: 0.226179\n",
      "Train Epoch: 2 [780/997 (78%)]\tLoss: 0.160328\n",
      "Train Epoch: 2 [790/997 (79%)]\tLoss: 0.168489\n",
      "Train Epoch: 2 [800/997 (80%)]\tLoss: 0.190456\n",
      "Train Epoch: 2 [810/997 (81%)]\tLoss: 0.188767\n",
      "Train Epoch: 2 [820/997 (82%)]\tLoss: 0.188376\n",
      "Train Epoch: 2 [830/997 (83%)]\tLoss: 0.140310\n",
      "Train Epoch: 2 [840/997 (84%)]\tLoss: 0.115196\n",
      "Train Epoch: 2 [850/997 (85%)]\tLoss: 0.153160\n",
      "Train Epoch: 2 [860/997 (86%)]\tLoss: 0.155340\n",
      "Train Epoch: 2 [870/997 (87%)]\tLoss: 0.105440\n",
      "Train Epoch: 2 [880/997 (88%)]\tLoss: 0.131224\n",
      "Train Epoch: 2 [890/997 (89%)]\tLoss: 0.082599\n",
      "Train Epoch: 2 [900/997 (90%)]\tLoss: 0.095103\n",
      "Train Epoch: 2 [910/997 (91%)]\tLoss: 0.113005\n",
      "Train Epoch: 2 [920/997 (92%)]\tLoss: 0.068053\n",
      "Train Epoch: 2 [930/997 (93%)]\tLoss: 0.115648\n",
      "Train Epoch: 2 [940/997 (94%)]\tLoss: 0.062181\n",
      "Train Epoch: 2 [950/997 (95%)]\tLoss: 0.065186\n",
      "Train Epoch: 2 [960/997 (96%)]\tLoss: 0.054259\n",
      "Train Epoch: 2 [970/997 (97%)]\tLoss: 0.065095\n",
      "Train Epoch: 2 [980/997 (98%)]\tLoss: 0.087214\n",
      "Train Epoch: 2 [990/997 (99%)]\tLoss: 0.057010\n",
      "input and target sent to CUDA\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1804, 0.1615, 0.1396,  ..., 0.1961, 0.2310, 0.1989], device='cuda:0')\n",
      "t tensor([0.0047, 0.0047, 0.0047,  ..., 0.3258, 0.3257, 0.3256], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1716, 0.1564, 0.1851,  ..., 0.2782, 0.2787, 0.2907], device='cuda:0')\n",
      "t tensor([0.0247, 0.0247, 0.0247,  ..., 0.0017, 0.0020, 0.0021], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1759, 0.1572, 0.1508,  ..., 0.2101, 0.2676, 0.2431], device='cuda:0')\n",
      "t tensor([0.0348, 0.0348, 0.0348,  ..., 0.4665, 0.4665, 0.4665], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1648, 0.1568, 0.1840,  ..., 0.2768, 0.2717, 0.2862], device='cuda:0')\n",
      "t tensor([0.6048, 0.6048, 0.6047,  ..., 0.9539, 0.9540, 0.9540], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1772, 0.1604, 0.1271,  ..., 0.1886, 0.2545, 0.1949], device='cuda:0')\n",
      "t tensor([0.7523, 0.7524, 0.7524,  ..., 0.9628, 0.9628, 0.9628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1749, 0.1603, 0.1261,  ..., 0.1881, 0.2385, 0.1899], device='cuda:0')\n",
      "t tensor([0.5879, 0.5898, 0.5951,  ..., 0.9336, 0.9336, 0.9336], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1814, 0.1608, 0.1264,  ..., 0.1887, 0.2487, 0.1944], device='cuda:0')\n",
      "t tensor([0.3946, 0.3929, 0.3882,  ..., 0.9903, 0.9904, 0.9904], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1783, 0.1588, 0.1607,  ..., 0.2780, 0.2878, 0.2981], device='cuda:0')\n",
      "t tensor([0.0886, 0.0886, 0.0887,  ..., 0.8846, 0.8844, 0.8844], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1786, 0.1600, 0.1280,  ..., 0.1900, 0.2620, 0.2064], device='cuda:0')\n",
      "t tensor([0.7348, 0.7348, 0.7347,  ..., 0.5635, 0.5635, 0.5635], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1737, 0.1605, 0.1264,  ..., 0.1887, 0.2617, 0.1986], device='cuda:0')\n",
      "t tensor([0.5335, 0.5334, 0.5330,  ..., 0.6007, 0.6014, 0.6016], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1816, 0.1614, 0.1271,  ..., 0.1874, 0.2176, 0.1828], device='cuda:0')\n",
      "t tensor([0.4988, 0.4988, 0.4991,  ..., 0.9337, 0.9338, 0.9338], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1803, 0.1607, 0.1263,  ..., 0.1889, 0.2506, 0.1952], device='cuda:0')\n",
      "t tensor([0.0616, 0.0617, 0.0620,  ..., 0.6313, 0.6312, 0.6312], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1733, 0.1610, 0.1251,  ..., 0.1886, 0.2504, 0.1953], device='cuda:0')\n",
      "t tensor([0.2780, 0.2779, 0.2775,  ..., 0.3864, 0.3865, 0.3865], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1777, 0.1606, 0.1260,  ..., 0.1888, 0.2560, 0.1974], device='cuda:0')\n",
      "t tensor([0.2567, 0.2565, 0.2558,  ..., 0.2739, 0.2738, 0.2738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1815, 0.1615, 0.1275,  ..., 0.1875, 0.2168, 0.1872], device='cuda:0')\n",
      "t tensor([0.7539, 0.7537, 0.7530,  ..., 0.9571, 0.9571, 0.9571], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1726, 0.1603, 0.1263,  ..., 0.1891, 0.2643, 0.1998], device='cuda:0')\n",
      "t tensor([0.2040, 0.2035, 0.2020,  ..., 0.4414, 0.4413, 0.4413], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o tensor([0.1739, 0.1600, 0.1272,  ..., 0.1896, 0.2651, 0.2016], device='cuda:0')\n",
      "t tensor([0.2856, 0.2856, 0.2854,  ..., 0.8735, 0.8735, 0.8735], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1724, 0.1603, 0.1262,  ..., 0.1891, 0.2643, 0.1998], device='cuda:0')\n",
      "t tensor([0.1827, 0.1823, 0.1809,  ..., 0.9637, 0.9637, 0.9637], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1786, 0.1604, 0.1267,  ..., 0.1889, 0.2592, 0.1971], device='cuda:0')\n",
      "t tensor([0.3747, 0.3743, 0.3730,  ..., 0.6949, 0.6949, 0.6949], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1744, 0.1601, 0.1264,  ..., 0.1891, 0.2660, 0.1992], device='cuda:0')\n",
      "t tensor([0.2302, 0.2302, 0.2301,  ..., 0.6374, 0.6371, 0.6370], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1678, 0.1607, 0.1254,  ..., 0.1892, 0.2613, 0.1982], device='cuda:0')\n",
      "t tensor([0.2914, 0.2912, 0.2906,  ..., 0.3812, 0.3812, 0.3811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1795, 0.1602, 0.1273,  ..., 0.1894, 0.2620, 0.2024], device='cuda:0')\n",
      "t tensor([0.8507, 0.8507, 0.8507,  ..., 0.1821, 0.1822, 0.1823], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1783, 0.1603, 0.1267,  ..., 0.1891, 0.2615, 0.1981], device='cuda:0')\n",
      "t tensor([0.9335, 0.9334, 0.9333,  ..., 0.0684, 0.0683, 0.0683], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1822, 0.1613, 0.1271,  ..., 0.1885, 0.2354, 0.1916], device='cuda:0')\n",
      "t tensor([0.9413, 0.9413, 0.9414,  ..., 0.7688, 0.7688, 0.7688], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1791, 0.1603, 0.1270,  ..., 0.1893, 0.2607, 0.2007], device='cuda:0')\n",
      "t tensor([0.6306, 0.6306, 0.6305,  ..., 0.6907, 0.6909, 0.6909], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1791, 0.1608, 0.1283,  ..., 0.1906, 0.2643, 0.2049], device='cuda:0')\n",
      "t tensor([0.0256, 0.0256, 0.0255,  ..., 0.9322, 0.9322, 0.9322], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1559, 0.1613, 0.1242,  ..., 0.1871, 0.2125, 0.1843], device='cuda:0')\n",
      "t tensor([0.1775, 0.1775, 0.1775,  ..., 0.9676, 0.9676, 0.9676], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1829, 0.1598, 0.1305,  ..., 0.1903, 0.2565, 0.2116], device='cuda:0')\n",
      "t tensor([0.5727, 0.5722, 0.5708,  ..., 0.3124, 0.3121, 0.3120], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1768, 0.1607, 0.1254,  ..., 0.1889, 0.2558, 0.1975], device='cuda:0')\n",
      "t tensor([0.2348, 0.2342, 0.2325,  ..., 0.4525, 0.4524, 0.4524], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1783, 0.1604, 0.1270,  ..., 0.1893, 0.2601, 0.2018], device='cuda:0')\n",
      "t tensor([0.7909, 0.7908, 0.7906,  ..., 0.8627, 0.8628, 0.8628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1780, 0.1603, 0.1266,  ..., 0.1891, 0.2614, 0.1981], device='cuda:0')\n",
      "t tensor([0.4285, 0.4283, 0.4279,  ..., 0.8922, 0.8919, 0.8919], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1756, 0.1603, 0.1264,  ..., 0.1891, 0.2647, 0.2018], device='cuda:0')\n",
      "t tensor([0.1388, 0.1376, 0.1339,  ..., 0.4811, 0.4811, 0.4811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1777, 0.1602, 0.1270,  ..., 0.1889, 0.2577, 0.1965], device='cuda:0')\n",
      "t tensor([0.1970, 0.1972, 0.1978,  ..., 0.3019, 0.3019, 0.3019], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1792, 0.1607, 0.1257,  ..., 0.1891, 0.2534, 0.1960], device='cuda:0')\n",
      "t tensor([0.4834, 0.4836, 0.4842,  ..., 0.2392, 0.2392, 0.2392], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1874, 0.1576, 0.1521,  ..., 0.2025, 0.2807, 0.2477], device='cuda:0')\n",
      "t tensor([0.2179, 0.2179, 0.2179,  ..., 0.2706, 0.2705, 0.2703], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1822, 0.1572, 0.1632,  ..., 0.2632, 0.2875, 0.2908], device='cuda:0')\n",
      "t tensor([0.0409, 0.0409, 0.0409,  ..., 0.7987, 0.7987, 0.7987], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1666, 0.1608, 0.1248,  ..., 0.1886, 0.2406, 0.1944], device='cuda:0')\n",
      "t tensor([0.0342, 0.0342, 0.0342,  ..., 0.9659, 0.9659, 0.9659], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1770, 0.1609, 0.1248,  ..., 0.1881, 0.2417, 0.1918], device='cuda:0')\n",
      "t tensor([0.3493, 0.3492, 0.3487,  ..., 0.2131, 0.2133, 0.2134], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1693, 0.1606, 0.1254,  ..., 0.1889, 0.2567, 0.1975], device='cuda:0')\n",
      "t tensor([0.5021, 0.5020, 0.5020,  ..., 0.3519, 0.3519, 0.3519], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1812, 0.1605, 0.1264,  ..., 0.1891, 0.2529, 0.1961], device='cuda:0')\n",
      "t tensor([0.5981, 0.5980, 0.5979,  ..., 0.7961, 0.7961, 0.7961], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1812, 0.1605, 0.1265,  ..., 0.1891, 0.2529, 0.1961], device='cuda:0')\n",
      "t tensor([0.7488, 0.7488, 0.7488,  ..., 0.8285, 0.8285, 0.8285], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1753, 0.1603, 0.1252,  ..., 0.1876, 0.2536, 0.1960], device='cuda:0')\n",
      "t tensor([0.0456, 0.0458, 0.0463,  ..., 0.0027, 0.0027, 0.0027], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1781, 0.1616, 0.1304,  ..., 0.1894, 0.2320, 0.1983], device='cuda:0')\n",
      "t tensor([0.5312, 0.5311, 0.5311,  ..., 0.1408, 0.1408, 0.1408], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1560, 0.1562, 0.1903,  ..., 0.2928, 0.2898, 0.3213], device='cuda:0')\n",
      "t tensor([0.2914, 0.2914, 0.2913,  ..., 0.9984, 0.9984, 0.9984], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1593, 0.1561, 0.1932,  ..., 0.2924, 0.2899, 0.3211], device='cuda:0')\n",
      "t tensor([0.5180, 0.5180, 0.5180,  ..., 0.9702, 0.9702, 0.9702], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1584, 0.1558, 0.1929,  ..., 0.2928, 0.2898, 0.3198], device='cuda:0')\n",
      "t tensor([0.1826, 0.1826, 0.1827,  ..., 0.9062, 0.9062, 0.9063], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1515, 0.1567, 0.1691,  ..., 0.2824, 0.2891, 0.3126], device='cuda:0')\n",
      "t tensor([0.1136, 0.1137, 0.1137,  ..., 0.9989, 0.9989, 0.9989], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1737, 0.1612, 0.1240,  ..., 0.1875, 0.2270, 0.1873], device='cuda:0')\n",
      "t tensor([0.4704, 0.4702, 0.4699,  ..., 0.0199, 0.0199, 0.0199], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1758, 0.1602, 0.1265,  ..., 0.1891, 0.2655, 0.2002], device='cuda:0')\n",
      "t tensor([0.9487, 0.9486, 0.9482,  ..., 0.5739, 0.5738, 0.5738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1743, 0.1603, 0.1264,  ..., 0.1891, 0.2640, 0.2014], device='cuda:0')\n",
      "t tensor([0.2798, 0.2796, 0.2791,  ..., 0.7839, 0.7840, 0.7840], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1811, 0.1606, 0.1263,  ..., 0.1889, 0.2530, 0.1957], device='cuda:0')\n",
      "t tensor([0.1696, 0.1689, 0.1668,  ..., 0.8651, 0.8650, 0.8650], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1800, 0.1607, 0.1262,  ..., 0.1888, 0.2505, 0.1948], device='cuda:0')\n",
      "t tensor([0.7236, 0.7236, 0.7235,  ..., 0.6560, 0.6561, 0.6562], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1822, 0.1613, 0.1272,  ..., 0.1884, 0.2343, 0.1910], device='cuda:0')\n",
      "t tensor([0.6936, 0.6936, 0.6935,  ..., 0.7810, 0.7810, 0.7810], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1550, 0.1557, 0.1917,  ..., 0.2926, 0.2899, 0.3212], device='cuda:0')\n",
      "t tensor([0.0778, 0.0778, 0.0777,  ..., 0.9969, 0.9969, 0.9969], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1804, 0.1604, 0.1266,  ..., 0.1890, 0.2556, 0.1961], device='cuda:0')\n",
      "t tensor([0.9165, 0.9165, 0.9165,  ..., 0.3030, 0.3032, 0.3032], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1744, 0.1607, 0.1259,  ..., 0.1887, 0.2495, 0.1951], device='cuda:0')\n",
      "t tensor([0.4204, 0.4204, 0.4205,  ..., 0.3603, 0.3601, 0.3601], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o tensor([0.1796, 0.1602, 0.1274,  ..., 0.1896, 0.2608, 0.2021], device='cuda:0')\n",
      "t tensor([0.6500, 0.6501, 0.6502,  ..., 0.7238, 0.7240, 0.7240], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1520, 0.1557, 0.1898,  ..., 0.2928, 0.2899, 0.3208], device='cuda:0')\n",
      "t tensor([0.2068, 0.2069, 0.2069,  ..., 0.8895, 0.8895, 0.8894], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1718, 0.1602, 0.1271,  ..., 0.1903, 0.2561, 0.2024], device='cuda:0')\n",
      "t tensor([0.0011, 0.0011, 0.0011,  ..., 0.9777, 0.9777, 0.9777], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1667, 0.1605, 0.1253,  ..., 0.1886, 0.2406, 0.1936], device='cuda:0')\n",
      "t tensor([0.0587, 0.0587, 0.0587,  ..., 0.9461, 0.9463, 0.9464], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1733, 0.1610, 0.1246,  ..., 0.1882, 0.2418, 0.1913], device='cuda:0')\n",
      "t tensor([0.1505, 0.1516, 0.1547,  ..., 0.3629, 0.3629, 0.3630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1812, 0.1605, 0.1264,  ..., 0.1891, 0.2529, 0.1961], device='cuda:0')\n",
      "t tensor([0.2263, 0.2268, 0.2284,  ..., 0.6039, 0.6040, 0.6041], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1801, 0.1604, 0.1266,  ..., 0.1891, 0.2572, 0.1974], device='cuda:0')\n",
      "t tensor([0.6393, 0.6394, 0.6397,  ..., 0.9386, 0.9385, 0.9385], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1794, 0.1605, 0.1263,  ..., 0.1888, 0.2565, 0.1990], device='cuda:0')\n",
      "t tensor([0.6337, 0.6337, 0.6334,  ..., 0.2633, 0.2631, 0.2630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1809, 0.1609, 0.1275,  ..., 0.1884, 0.2401, 0.1901], device='cuda:0')\n",
      "t tensor([0.7495, 0.7496, 0.7497,  ..., 0.1181, 0.1182, 0.1182], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1801, 0.1615, 0.1252,  ..., 0.1871, 0.2147, 0.1824], device='cuda:0')\n",
      "t tensor([0.8907, 0.8907, 0.8908,  ..., 0.0620, 0.0618, 0.0618], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1745, 0.1603, 0.1265,  ..., 0.1890, 0.2643, 0.2007], device='cuda:0')\n",
      "t tensor([0.2725, 0.2721, 0.2709,  ..., 0.5479, 0.5479, 0.5479], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1821, 0.1619, 0.1255,  ..., 0.1869, 0.2043, 0.1802], device='cuda:0')\n",
      "t tensor([0.8225, 0.8225, 0.8223,  ..., 0.2745, 0.2745, 0.2745], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1768, 0.1611, 0.1245,  ..., 0.1877, 0.2407, 0.1894], device='cuda:0')\n",
      "t tensor([0.4347, 0.4347, 0.4347,  ..., 0.5438, 0.5438, 0.5439], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1764, 0.1603, 0.1312,  ..., 0.1911, 0.2599, 0.2100], device='cuda:0')\n",
      "t tensor([0.1683, 0.1683, 0.1683,  ..., 0.0104, 0.0104, 0.0104], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1823, 0.1572, 0.1536,  ..., 0.2138, 0.2771, 0.2457], device='cuda:0')\n",
      "t tensor([0.0155, 0.0155, 0.0155,  ..., 0.2109, 0.2109, 0.2109], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1815, 0.1611, 0.1267,  ..., 0.1877, 0.2224, 0.1838], device='cuda:0')\n",
      "t tensor([0.0041, 0.0041, 0.0041,  ..., 0.1236, 0.1236, 0.1236], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1819, 0.1606, 0.1268,  ..., 0.1881, 0.2373, 0.1990], device='cuda:0')\n",
      "t tensor([0.2529, 0.2529, 0.2529,  ..., 0.0449, 0.0448, 0.0447], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1657, 0.1593, 0.1414,  ..., 0.2000, 0.2382, 0.2216], device='cuda:0')\n",
      "t tensor([7.9046e-05, 7.8999e-05, 7.8867e-05,  ..., 4.1099e-01, 4.1101e-01,\n",
      "        4.1101e-01], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1734, 0.1565, 0.1657,  ..., 0.2439, 0.2687, 0.2663], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1827, 0.1602, 0.1284,  ..., 0.1895, 0.2478, 0.2045], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1804, 0.1603, 0.1273,  ..., 0.1890, 0.2515, 0.1942], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1782, 0.1609, 0.1267,  ..., 0.1886, 0.2439, 0.1928], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1770, 0.1604, 0.1270,  ..., 0.1885, 0.2551, 0.1951], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1781, 0.1609, 0.1248,  ..., 0.1875, 0.2275, 0.1861], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1821, 0.1599, 0.1314,  ..., 0.1909, 0.2565, 0.2112], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1792, 0.1561, 0.1751,  ..., 0.2568, 0.2829, 0.2806], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1765, 0.1557, 0.1782,  ..., 0.2699, 0.2836, 0.2853], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1799, 0.1604, 0.1466,  ..., 0.2011, 0.2454, 0.2175], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1427, 0.1618, 0.1491,  ..., 0.2120, 0.1926, 0.1926], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1596, 0.1572, 0.1906,  ..., 0.2837, 0.2623, 0.2862], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1782, 0.1561, 0.1734,  ..., 0.2511, 0.2788, 0.2723], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1421, 0.1617, 0.1611,  ..., 0.2342, 0.1939, 0.2016], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1716, 0.1563, 0.1759,  ..., 0.2551, 0.2689, 0.2755], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1542, 0.1596, 0.1510,  ..., 0.2177, 0.2226, 0.2222], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1399, 0.1616, 0.1477,  ..., 0.2137, 0.1945, 0.1966], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1702, 0.1563, 0.1758,  ..., 0.2620, 0.2790, 0.2777], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1647, 0.1620, 0.1589,  ..., 0.2190, 0.1971, 0.1981], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1693, 0.1561, 0.1871,  ..., 0.2806, 0.2792, 0.2936], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1527, 0.1622, 0.1371,  ..., 0.1919, 0.1918, 0.1804], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1811, 0.1573, 0.1628,  ..., 0.2196, 0.2673, 0.2513], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1695, 0.1614, 0.1602,  ..., 0.2263, 0.2245, 0.2190], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1737, 0.1589, 0.1499,  ..., 0.2146, 0.2590, 0.2364], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1617, 0.1601, 0.1791,  ..., 0.2724, 0.2397, 0.2545], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1594, 0.1585, 0.1422,  ..., 0.2071, 0.2458, 0.2253], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "[0.3525697973107502, 0.20350569114462663, 0.19294637319264762, tensor(0.1915, device='cuda:0'), tensor(0.1936, device='cuda:0'), tensor(0.1925, device='cuda:0'), tensor(0.1946, device='cuda:0'), tensor(0.1940, device='cuda:0')]\n",
      "\n",
      "Test set: Avg. loss: 0.1940, Accuracy: 0/997 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input and target sent to CUDA\n",
      "Train Epoch: 3 [0/997 (0%)]\tLoss: 0.047355\n",
      "Train Epoch: 3 [10/997 (1%)]\tLoss: 0.042477\n",
      "Train Epoch: 3 [20/997 (2%)]\tLoss: 0.111148\n",
      "Train Epoch: 3 [30/997 (3%)]\tLoss: 0.411402\n",
      "Train Epoch: 3 [40/997 (4%)]\tLoss: 0.524188\n",
      "Train Epoch: 3 [50/997 (5%)]\tLoss: 0.476661\n",
      "Train Epoch: 3 [60/997 (6%)]\tLoss: 0.484674\n",
      "Train Epoch: 3 [70/997 (7%)]\tLoss: 0.326203\n",
      "Train Epoch: 3 [80/997 (8%)]\tLoss: 0.288811\n",
      "Train Epoch: 3 [90/997 (9%)]\tLoss: 0.310285\n",
      "Train Epoch: 3 [100/997 (10%)]\tLoss: 0.226459\n",
      "Train Epoch: 3 [110/997 (11%)]\tLoss: 0.097029\n",
      "Train Epoch: 3 [120/997 (12%)]\tLoss: 0.051276\n",
      "Train Epoch: 3 [130/997 (13%)]\tLoss: 0.091516\n",
      "Train Epoch: 3 [140/997 (14%)]\tLoss: 0.384715\n",
      "Train Epoch: 3 [150/997 (15%)]\tLoss: 0.056904\n",
      "Train Epoch: 3 [160/997 (16%)]\tLoss: 0.221418\n",
      "Train Epoch: 3 [170/997 (17%)]\tLoss: 0.375565\n",
      "Train Epoch: 3 [180/997 (18%)]\tLoss: 0.229129\n",
      "Train Epoch: 3 [190/997 (19%)]\tLoss: 0.078448\n",
      "Train Epoch: 3 [200/997 (20%)]\tLoss: 0.064010\n",
      "Train Epoch: 3 [210/997 (21%)]\tLoss: 0.080273\n",
      "Train Epoch: 3 [220/997 (22%)]\tLoss: 0.150115\n",
      "Train Epoch: 3 [230/997 (23%)]\tLoss: 0.266971\n",
      "Train Epoch: 3 [240/997 (24%)]\tLoss: 0.091117\n",
      "Train Epoch: 3 [250/997 (25%)]\tLoss: 0.179694\n",
      "Train Epoch: 3 [260/997 (26%)]\tLoss: 0.264185\n",
      "Train Epoch: 3 [270/997 (27%)]\tLoss: 0.105108\n",
      "Train Epoch: 3 [280/997 (28%)]\tLoss: 0.107310\n",
      "Train Epoch: 3 [290/997 (29%)]\tLoss: 0.196027\n",
      "Train Epoch: 3 [300/997 (30%)]\tLoss: 0.116847\n",
      "Train Epoch: 3 [310/997 (31%)]\tLoss: 0.063425\n",
      "Train Epoch: 3 [320/997 (32%)]\tLoss: 0.085705\n",
      "Train Epoch: 3 [330/997 (33%)]\tLoss: 0.079943\n",
      "Train Epoch: 3 [340/997 (34%)]\tLoss: 0.145974\n",
      "Train Epoch: 3 [350/997 (35%)]\tLoss: 0.173093\n",
      "Train Epoch: 3 [360/997 (36%)]\tLoss: 0.089820\n",
      "Train Epoch: 3 [370/997 (37%)]\tLoss: 0.115649\n",
      "Train Epoch: 3 [380/997 (38%)]\tLoss: 0.070034\n",
      "Train Epoch: 3 [390/997 (39%)]\tLoss: 0.087233\n",
      "Train Epoch: 3 [400/997 (40%)]\tLoss: 0.147356\n",
      "Train Epoch: 3 [410/997 (41%)]\tLoss: 0.136253\n",
      "Train Epoch: 3 [420/997 (42%)]\tLoss: 0.089493\n",
      "Train Epoch: 3 [430/997 (43%)]\tLoss: 0.172123\n",
      "Train Epoch: 3 [440/997 (44%)]\tLoss: 0.197620\n",
      "Train Epoch: 3 [450/997 (45%)]\tLoss: 0.173717\n",
      "Train Epoch: 3 [460/997 (46%)]\tLoss: 0.123255\n",
      "Train Epoch: 3 [470/997 (47%)]\tLoss: 0.077884\n",
      "Train Epoch: 3 [480/997 (48%)]\tLoss: 0.137285\n",
      "Train Epoch: 3 [490/997 (49%)]\tLoss: 0.082376\n",
      "Train Epoch: 3 [500/997 (50%)]\tLoss: 0.129526\n",
      "Train Epoch: 3 [510/997 (51%)]\tLoss: 0.148620\n",
      "Train Epoch: 3 [520/997 (52%)]\tLoss: 0.123648\n",
      "Train Epoch: 3 [530/997 (53%)]\tLoss: 0.113179\n",
      "Train Epoch: 3 [540/997 (54%)]\tLoss: 0.129406\n",
      "Train Epoch: 3 [550/997 (55%)]\tLoss: 0.080163\n",
      "Train Epoch: 3 [560/997 (56%)]\tLoss: 0.075565\n",
      "Train Epoch: 3 [570/997 (57%)]\tLoss: 0.104871\n",
      "Train Epoch: 3 [580/997 (58%)]\tLoss: 0.120709\n",
      "Train Epoch: 3 [590/997 (59%)]\tLoss: 0.123572\n",
      "Train Epoch: 3 [600/997 (60%)]\tLoss: 0.089123\n",
      "Train Epoch: 3 [610/997 (61%)]\tLoss: 0.081432\n",
      "Train Epoch: 3 [620/997 (62%)]\tLoss: 0.160568\n",
      "Train Epoch: 3 [630/997 (63%)]\tLoss: 0.147054\n",
      "Train Epoch: 3 [640/997 (64%)]\tLoss: 0.138273\n",
      "Train Epoch: 3 [650/997 (65%)]\tLoss: 0.092975\n",
      "Train Epoch: 3 [660/997 (66%)]\tLoss: 0.078818\n",
      "Train Epoch: 3 [670/997 (67%)]\tLoss: 0.062018\n",
      "Train Epoch: 3 [680/997 (68%)]\tLoss: 0.077384\n",
      "Train Epoch: 3 [690/997 (69%)]\tLoss: 0.208893\n",
      "Train Epoch: 3 [700/997 (70%)]\tLoss: 0.147575\n",
      "Train Epoch: 3 [710/997 (71%)]\tLoss: 0.186039\n",
      "Train Epoch: 3 [720/997 (72%)]\tLoss: 0.226827\n",
      "Train Epoch: 3 [730/997 (73%)]\tLoss: 0.133024\n",
      "Train Epoch: 3 [740/997 (74%)]\tLoss: 0.239752\n",
      "Train Epoch: 3 [750/997 (75%)]\tLoss: 0.211842\n",
      "Train Epoch: 3 [760/997 (76%)]\tLoss: 0.253518\n",
      "Train Epoch: 3 [770/997 (77%)]\tLoss: 0.249829\n",
      "Train Epoch: 3 [780/997 (78%)]\tLoss: 0.173575\n",
      "Train Epoch: 3 [790/997 (79%)]\tLoss: 0.158556\n",
      "Train Epoch: 3 [800/997 (80%)]\tLoss: 0.176614\n",
      "Train Epoch: 3 [810/997 (81%)]\tLoss: 0.179801\n",
      "Train Epoch: 3 [820/997 (82%)]\tLoss: 0.182855\n",
      "Train Epoch: 3 [830/997 (83%)]\tLoss: 0.139566\n",
      "Train Epoch: 3 [840/997 (84%)]\tLoss: 0.113204\n",
      "Train Epoch: 3 [850/997 (85%)]\tLoss: 0.156762\n",
      "Train Epoch: 3 [860/997 (86%)]\tLoss: 0.143933\n",
      "Train Epoch: 3 [870/997 (87%)]\tLoss: 0.100020\n",
      "Train Epoch: 3 [880/997 (88%)]\tLoss: 0.102925\n",
      "Train Epoch: 3 [890/997 (89%)]\tLoss: 0.074129\n",
      "Train Epoch: 3 [900/997 (90%)]\tLoss: 0.091610\n",
      "Train Epoch: 3 [910/997 (91%)]\tLoss: 0.103760\n",
      "Train Epoch: 3 [920/997 (92%)]\tLoss: 0.064999\n",
      "Train Epoch: 3 [930/997 (93%)]\tLoss: 0.123410\n",
      "Train Epoch: 3 [940/997 (94%)]\tLoss: 0.063907\n",
      "Train Epoch: 3 [950/997 (95%)]\tLoss: 0.056518\n",
      "Train Epoch: 3 [960/997 (96%)]\tLoss: 0.061838\n",
      "Train Epoch: 3 [970/997 (97%)]\tLoss: 0.068456\n",
      "Train Epoch: 3 [980/997 (98%)]\tLoss: 0.098407\n",
      "Train Epoch: 3 [990/997 (99%)]\tLoss: 0.053178\n",
      "input and target sent to CUDA\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1737, 0.1450, 0.1502,  ..., 0.1994, 0.2100, 0.2041], device='cuda:0')\n",
      "t tensor([0.0047, 0.0047, 0.0047,  ..., 0.3258, 0.3257, 0.3256], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1835, 0.1821, 0.1716,  ..., 0.2931, 0.2783, 0.2905], device='cuda:0')\n",
      "t tensor([0.0247, 0.0247, 0.0247,  ..., 0.0017, 0.0020, 0.0021], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1589, 0.1713, 0.1470,  ..., 0.2176, 0.2512, 0.2214], device='cuda:0')\n",
      "t tensor([0.0348, 0.0348, 0.0348,  ..., 0.4665, 0.4665, 0.4665], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1780, 0.1817, 0.1722,  ..., 0.2901, 0.2757, 0.2871], device='cuda:0')\n",
      "t tensor([0.6048, 0.6048, 0.6047,  ..., 0.9539, 0.9540, 0.9540], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1407, 0.1451, 0.1411,  ..., 0.1871, 0.2010, 0.1904], device='cuda:0')\n",
      "t tensor([0.7523, 0.7524, 0.7524,  ..., 0.9628, 0.9628, 0.9628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1413, 0.1443, 0.1414,  ..., 0.1870, 0.2000, 0.1905], device='cuda:0')\n",
      "t tensor([0.5879, 0.5898, 0.5951,  ..., 0.9336, 0.9336, 0.9336], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1557, 0.1443, 0.1421,  ..., 0.1879, 0.2010, 0.1920], device='cuda:0')\n",
      "t tensor([0.3946, 0.3929, 0.3882,  ..., 0.9903, 0.9904, 0.9904], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1772, 0.1548, 0.1557,  ..., 0.2772, 0.2747, 0.2859], device='cuda:0')\n",
      "t tensor([0.0886, 0.0886, 0.0887,  ..., 0.8846, 0.8844, 0.8844], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1598, 0.1462, 0.1419,  ..., 0.1904, 0.2078, 0.2006], device='cuda:0')\n",
      "t tensor([0.7348, 0.7348, 0.7347,  ..., 0.5635, 0.5635, 0.5635], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1568, 0.1448, 0.1417,  ..., 0.1884, 0.2015, 0.1929], device='cuda:0')\n",
      "t tensor([0.5335, 0.5334, 0.5330,  ..., 0.6007, 0.6014, 0.6016], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1581, 0.1462, 0.1424,  ..., 0.1895, 0.2046, 0.1957], device='cuda:0')\n",
      "t tensor([0.4988, 0.4988, 0.4991,  ..., 0.9337, 0.9338, 0.9338], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1606, 0.1477, 0.1422,  ..., 0.1915, 0.2057, 0.1990], device='cuda:0')\n",
      "t tensor([0.0616, 0.0617, 0.0620,  ..., 0.6313, 0.6312, 0.6312], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1551, 0.1445, 0.1421,  ..., 0.1877, 0.2014, 0.1916], device='cuda:0')\n",
      "t tensor([0.2780, 0.2779, 0.2775,  ..., 0.3864, 0.3865, 0.3865], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1590, 0.1488, 0.1420,  ..., 0.1927, 0.2095, 0.2005], device='cuda:0')\n",
      "t tensor([0.2567, 0.2565, 0.2558,  ..., 0.2739, 0.2738, 0.2738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1670, 0.1443, 0.1430,  ..., 0.1899, 0.2036, 0.1961], device='cuda:0')\n",
      "t tensor([0.7539, 0.7537, 0.7530,  ..., 0.9571, 0.9571, 0.9571], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1593, 0.1474, 0.1420,  ..., 0.1910, 0.2058, 0.1982], device='cuda:0')\n",
      "t tensor([0.2040, 0.2035, 0.2020,  ..., 0.4414, 0.4413, 0.4413], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1513, 0.1500, 0.1411,  ..., 0.1929, 0.2094, 0.1992], device='cuda:0')\n",
      "t tensor([0.2856, 0.2856, 0.2854,  ..., 0.8735, 0.8735, 0.8735], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1579, 0.1470, 0.1419,  ..., 0.1904, 0.2049, 0.1973], device='cuda:0')\n",
      "t tensor([0.1827, 0.1823, 0.1809,  ..., 0.9637, 0.9637, 0.9637], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o tensor([0.1603, 0.1481, 0.1420,  ..., 0.1913, 0.2060, 0.1986], device='cuda:0')\n",
      "t tensor([0.3747, 0.3743, 0.3730,  ..., 0.6949, 0.6949, 0.6949], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1596, 0.1474, 0.1421,  ..., 0.1911, 0.2058, 0.1984], device='cuda:0')\n",
      "t tensor([0.2302, 0.2302, 0.2301,  ..., 0.6374, 0.6371, 0.6370], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1518, 0.1443, 0.1415,  ..., 0.1886, 0.2027, 0.1936], device='cuda:0')\n",
      "t tensor([0.2914, 0.2912, 0.2906,  ..., 0.3812, 0.3812, 0.3811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1608, 0.1477, 0.1422,  ..., 0.1915, 0.2057, 0.1990], device='cuda:0')\n",
      "t tensor([0.8507, 0.8507, 0.8507,  ..., 0.1821, 0.1822, 0.1823], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1590, 0.1488, 0.1420,  ..., 0.1927, 0.2095, 0.2005], device='cuda:0')\n",
      "t tensor([0.9335, 0.9334, 0.9333,  ..., 0.0684, 0.0683, 0.0683], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1638, 0.1445, 0.1448,  ..., 0.1903, 0.2037, 0.1949], device='cuda:0')\n",
      "t tensor([0.9413, 0.9413, 0.9414,  ..., 0.7688, 0.7688, 0.7688], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1599, 0.1472, 0.1421,  ..., 0.1910, 0.2055, 0.1982], device='cuda:0')\n",
      "t tensor([0.6306, 0.6306, 0.6305,  ..., 0.6907, 0.6909, 0.6909], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1563, 0.1458, 0.1427,  ..., 0.1918, 0.2113, 0.2044], device='cuda:0')\n",
      "t tensor([0.0256, 0.0256, 0.0255,  ..., 0.9322, 0.9322, 0.9322], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1304, 0.1415, 0.1404,  ..., 0.1860, 0.1982, 0.1873], device='cuda:0')\n",
      "t tensor([0.1775, 0.1775, 0.1775,  ..., 0.9676, 0.9676, 0.9676], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1632, 0.1494, 0.1425,  ..., 0.1931, 0.2082, 0.2007], device='cuda:0')\n",
      "t tensor([0.5727, 0.5722, 0.5708,  ..., 0.3124, 0.3121, 0.3120], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1596, 0.1464, 0.1420,  ..., 0.1896, 0.2031, 0.1957], device='cuda:0')\n",
      "t tensor([0.2348, 0.2342, 0.2325,  ..., 0.4525, 0.4524, 0.4524], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1606, 0.1478, 0.1422,  ..., 0.1915, 0.2058, 0.1990], device='cuda:0')\n",
      "t tensor([0.7909, 0.7908, 0.7906,  ..., 0.8627, 0.8628, 0.8628], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1603, 0.1476, 0.1421,  ..., 0.1914, 0.2058, 0.1988], device='cuda:0')\n",
      "t tensor([0.4285, 0.4283, 0.4279,  ..., 0.8922, 0.8919, 0.8919], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1606, 0.1477, 0.1422,  ..., 0.1915, 0.2057, 0.1990], device='cuda:0')\n",
      "t tensor([0.1388, 0.1376, 0.1339,  ..., 0.4811, 0.4811, 0.4811], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1548, 0.1457, 0.1422,  ..., 0.1893, 0.2052, 0.1954], device='cuda:0')\n",
      "t tensor([0.1970, 0.1972, 0.1978,  ..., 0.3019, 0.3019, 0.3019], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1596, 0.1474, 0.1421,  ..., 0.1911, 0.2058, 0.1984], device='cuda:0')\n",
      "t tensor([0.4834, 0.4836, 0.4842,  ..., 0.2392, 0.2392, 0.2392], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1705, 0.1724, 0.1438,  ..., 0.2265, 0.2618, 0.2270], device='cuda:0')\n",
      "t tensor([0.2179, 0.2179, 0.2179,  ..., 0.2706, 0.2705, 0.2703], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1778, 0.1686, 0.1508,  ..., 0.2661, 0.2717, 0.2737], device='cuda:0')\n",
      "t tensor([0.0409, 0.0409, 0.0409,  ..., 0.7987, 0.7987, 0.7987], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1438, 0.1443, 0.1419,  ..., 0.1883, 0.2039, 0.1960], device='cuda:0')\n",
      "t tensor([0.0342, 0.0342, 0.0342,  ..., 0.9659, 0.9659, 0.9659], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1586, 0.1453, 0.1420,  ..., 0.1891, 0.2026, 0.1946], device='cuda:0')\n",
      "t tensor([0.3493, 0.3492, 0.3487,  ..., 0.2131, 0.2133, 0.2134], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1575, 0.1461, 0.1419,  ..., 0.1888, 0.2026, 0.1939], device='cuda:0')\n",
      "t tensor([0.5021, 0.5020, 0.5020,  ..., 0.3519, 0.3519, 0.3519], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1606, 0.1477, 0.1422,  ..., 0.1915, 0.2057, 0.1989], device='cuda:0')\n",
      "t tensor([0.5981, 0.5980, 0.5979,  ..., 0.7961, 0.7961, 0.7961], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1585, 0.1473, 0.1425,  ..., 0.1911, 0.2073, 0.1985], device='cuda:0')\n",
      "t tensor([0.7488, 0.7488, 0.7488,  ..., 0.8285, 0.8285, 0.8285], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1536, 0.1453, 0.1413,  ..., 0.1887, 0.2061, 0.1960], device='cuda:0')\n",
      "t tensor([0.0456, 0.0458, 0.0463,  ..., 0.0027, 0.0027, 0.0027], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1383, 0.1431, 0.1423,  ..., 0.1869, 0.2007, 0.1888], device='cuda:0')\n",
      "t tensor([0.5312, 0.5311, 0.5311,  ..., 0.1408, 0.1408, 0.1408], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1835, 0.1871, 0.1746,  ..., 0.3036, 0.2863, 0.3136], device='cuda:0')\n",
      "t tensor([0.2914, 0.2914, 0.2913,  ..., 0.9984, 0.9984, 0.9984], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1830, 0.1851, 0.1747,  ..., 0.3037, 0.2863, 0.3131], device='cuda:0')\n",
      "t tensor([0.5180, 0.5180, 0.5180,  ..., 0.9702, 0.9702, 0.9702], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1766, 0.1849, 0.1732,  ..., 0.3038, 0.2863, 0.3134], device='cuda:0')\n",
      "t tensor([0.1826, 0.1826, 0.1827,  ..., 0.9062, 0.9062, 0.9063], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1752, 0.1569, 0.1527,  ..., 0.2414, 0.2579, 0.2605], device='cuda:0')\n",
      "t tensor([0.1136, 0.1137, 0.1137,  ..., 0.9989, 0.9989, 0.9989], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1497, 0.1431, 0.1417,  ..., 0.1871, 0.2004, 0.1897], device='cuda:0')\n",
      "t tensor([0.4704, 0.4702, 0.4699,  ..., 0.0199, 0.0199, 0.0199], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1596, 0.1474, 0.1421,  ..., 0.1911, 0.2058, 0.1984], device='cuda:0')\n",
      "t tensor([0.9487, 0.9486, 0.9482,  ..., 0.5739, 0.5738, 0.5738], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1558, 0.1467, 0.1419,  ..., 0.1894, 0.2047, 0.1963], device='cuda:0')\n",
      "t tensor([0.2798, 0.2796, 0.2791,  ..., 0.7839, 0.7840, 0.7840], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1593, 0.1464, 0.1421,  ..., 0.1901, 0.2051, 0.1968], device='cuda:0')\n",
      "t tensor([0.1696, 0.1689, 0.1668,  ..., 0.8651, 0.8650, 0.8650], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1599, 0.1493, 0.1421,  ..., 0.1933, 0.2095, 0.2013], device='cuda:0')\n",
      "t tensor([0.7236, 0.7236, 0.7235,  ..., 0.6560, 0.6561, 0.6562], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1647, 0.1464, 0.1425,  ..., 0.1911, 0.2039, 0.1982], device='cuda:0')\n",
      "t tensor([0.6936, 0.6936, 0.6935,  ..., 0.7810, 0.7810, 0.7810], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1776, 0.1884, 0.1753,  ..., 0.3036, 0.2865, 0.3132], device='cuda:0')\n",
      "t tensor([0.0778, 0.0778, 0.0777,  ..., 0.9969, 0.9969, 0.9969], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1594, 0.1472, 0.1422,  ..., 0.1906, 0.2057, 0.1975], device='cuda:0')\n",
      "t tensor([0.9165, 0.9165, 0.9165,  ..., 0.3030, 0.3032, 0.3032], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1549, 0.1446, 0.1420,  ..., 0.1877, 0.2015, 0.1914], device='cuda:0')\n",
      "t tensor([0.4204, 0.4204, 0.4205,  ..., 0.3603, 0.3601, 0.3601], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1616, 0.1489, 0.1421,  ..., 0.1931, 0.2078, 0.2010], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t tensor([0.6500, 0.6501, 0.6502,  ..., 0.7238, 0.7240, 0.7240], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1803, 0.1877, 0.1708,  ..., 0.3037, 0.2865, 0.3132], device='cuda:0')\n",
      "t tensor([0.2068, 0.2069, 0.2069,  ..., 0.8895, 0.8895, 0.8894], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1578, 0.1449, 0.1425,  ..., 0.1885, 0.2022, 0.1939], device='cuda:0')\n",
      "t tensor([0.0011, 0.0011, 0.0011,  ..., 0.9777, 0.9777, 0.9777], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1413, 0.1443, 0.1414,  ..., 0.1870, 0.2000, 0.1905], device='cuda:0')\n",
      "t tensor([0.0587, 0.0587, 0.0587,  ..., 0.9461, 0.9463, 0.9464], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1493, 0.1428, 0.1416,  ..., 0.1871, 0.2000, 0.1898], device='cuda:0')\n",
      "t tensor([0.1505, 0.1516, 0.1547,  ..., 0.3629, 0.3629, 0.3630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1591, 0.1478, 0.1423,  ..., 0.1916, 0.2080, 0.1992], device='cuda:0')\n",
      "t tensor([0.2263, 0.2268, 0.2284,  ..., 0.6039, 0.6040, 0.6041], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1606, 0.1478, 0.1422,  ..., 0.1915, 0.2058, 0.1990], device='cuda:0')\n",
      "t tensor([0.6393, 0.6394, 0.6397,  ..., 0.9386, 0.9385, 0.9385], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1574, 0.1461, 0.1418,  ..., 0.1897, 0.2052, 0.1987], device='cuda:0')\n",
      "t tensor([0.6337, 0.6337, 0.6334,  ..., 0.2633, 0.2631, 0.2630], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1589, 0.1472, 0.1420,  ..., 0.1903, 0.2055, 0.1971], device='cuda:0')\n",
      "t tensor([0.7495, 0.7496, 0.7497,  ..., 0.1181, 0.1182, 0.1182], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1557, 0.1443, 0.1421,  ..., 0.1879, 0.2010, 0.1920], device='cuda:0')\n",
      "t tensor([0.8907, 0.8907, 0.8908,  ..., 0.0620, 0.0618, 0.0618], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1591, 0.1468, 0.1419,  ..., 0.1899, 0.2044, 0.1965], device='cuda:0')\n",
      "t tensor([0.2725, 0.2721, 0.2709,  ..., 0.5479, 0.5479, 0.5479], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1637, 0.1446, 0.1436,  ..., 0.1896, 0.2030, 0.1951], device='cuda:0')\n",
      "t tensor([0.8225, 0.8225, 0.8223,  ..., 0.2745, 0.2745, 0.2745], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1603, 0.1449, 0.1437,  ..., 0.1893, 0.2026, 0.1956], device='cuda:0')\n",
      "t tensor([0.4347, 0.4347, 0.4347,  ..., 0.5438, 0.5438, 0.5439], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1543, 0.1443, 0.1426,  ..., 0.1878, 0.2027, 0.1945], device='cuda:0')\n",
      "t tensor([0.1683, 0.1683, 0.1683,  ..., 0.0104, 0.0104, 0.0104], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1717, 0.1745, 0.1476,  ..., 0.2493, 0.2644, 0.2397], device='cuda:0')\n",
      "t tensor([0.0155, 0.0155, 0.0155,  ..., 0.2109, 0.2109, 0.2109], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1604, 0.1434, 0.1449,  ..., 0.1888, 0.2016, 0.1923], device='cuda:0')\n",
      "t tensor([0.0041, 0.0041, 0.0041,  ..., 0.1236, 0.1236, 0.1236], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1665, 0.1437, 0.1428,  ..., 0.1893, 0.2034, 0.1954], device='cuda:0')\n",
      "t tensor([0.2529, 0.2529, 0.2529,  ..., 0.0449, 0.0448, 0.0447], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1511, 0.1563, 0.1466,  ..., 0.1996, 0.2212, 0.2069], device='cuda:0')\n",
      "t tensor([7.9046e-05, 7.8999e-05, 7.8867e-05,  ..., 4.1099e-01, 4.1101e-01,\n",
      "        4.1101e-01], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1683, 0.1766, 0.1546,  ..., 0.2496, 0.2513, 0.2435], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1649, 0.1504, 0.1422,  ..., 0.1951, 0.2110, 0.2032], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1553, 0.1463, 0.1424,  ..., 0.1901, 0.2062, 0.1975], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1522, 0.1458, 0.1421,  ..., 0.1884, 0.2044, 0.1938], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1434, 0.1438, 0.1415,  ..., 0.1871, 0.2004, 0.1905], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1419, 0.1436, 0.1410,  ..., 0.1866, 0.1991, 0.1891], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1622, 0.1505, 0.1423,  ..., 0.1915, 0.2104, 0.1998], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1756, 0.1813, 0.1590,  ..., 0.2753, 0.2774, 0.2695], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1658, 0.1850, 0.1594,  ..., 0.2821, 0.2814, 0.2710], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1737, 0.1530, 0.1510,  ..., 0.2121, 0.2279, 0.2187], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1411, 0.1425, 0.1605,  ..., 0.1913, 0.1991, 0.1954], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1814, 0.1822, 0.1772,  ..., 0.2981, 0.2779, 0.2971], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1647, 0.1822, 0.1571,  ..., 0.2652, 0.2765, 0.2570], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1466, 0.1440, 0.1693,  ..., 0.2013, 0.2015, 0.2058], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1654, 0.1805, 0.1620,  ..., 0.2647, 0.2686, 0.2553], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1486, 0.1546, 0.1534,  ..., 0.2059, 0.2166, 0.2105], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1398, 0.1458, 0.1618,  ..., 0.1978, 0.2037, 0.2035], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1693, 0.1818, 0.1634,  ..., 0.2807, 0.2768, 0.2730], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1641, 0.1421, 0.1644,  ..., 0.1964, 0.2004, 0.2037], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1797, 0.1841, 0.1721,  ..., 0.2952, 0.2791, 0.2917], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1461, 0.1405, 0.1525,  ..., 0.1875, 0.1978, 0.1907], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1713, 0.1714, 0.1517,  ..., 0.2370, 0.2557, 0.2352], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1766, 0.1481, 0.1661,  ..., 0.2287, 0.2263, 0.2358], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1730, 0.1631, 0.1529,  ..., 0.2352, 0.2447, 0.2368], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1756, 0.1563, 0.1737,  ..., 0.2665, 0.2435, 0.2637], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "correct 0\n",
      "--------------------------\n",
      "o tensor([0.1506, 0.1601, 0.1469,  ..., 0.2037, 0.2226, 0.2089], device='cuda:0')\n",
      "t tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "-----------------------\n",
      "[0.3525697973107502, 0.20350569114462663, 0.19294637319264762, tensor(0.1915, device='cuda:0'), tensor(0.1936, device='cuda:0'), tensor(0.1925, device='cuda:0'), tensor(0.1946, device='cuda:0'), tensor(0.1940, device='cuda:0'), tensor(0.1942, device='cuda:0')]\n",
      "\n",
      "Test set: Avg. loss: 0.1942, Accuracy: 0/997 (0%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# CE E IN JOS DE AICI ERA TESTARE MAI VECHE, O PASTREZ JUST IN CASE\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    mask = train(epoch)\n",
    "    test()  \n",
    "#     split_audios_epoch(epoch, mask)\n",
    "    \n",
    "    plt.plot(train_losses)\n",
    "    plt.title('TRAIN losses')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(test_losses)\n",
    "    plt.title('TEST losses')\n",
    "    plt.show()\n",
    "\n",
    "print(\"DONE\")\n",
    "# print(len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    mask = []\n",
    "    network.train()\n",
    "    \n",
    "    # input is an AF, target is the mask for the PF of the current AF\n",
    "    for index, (input, target) in enumerate(train_set.items()):\n",
    "        \n",
    "        assert(input.shape == (4, 1, 513, 11))\n",
    "        assert(target.shape == (513, 11))\n",
    "\n",
    "        target_view = target.view(-1, target.shape[0] * target.shape[1])\n",
    "        \n",
    "        # if cuda is available, send (input, target) to gpu\n",
    "        if torch.cuda.is_available():\n",
    "            input, target_view = input.cuda(), target_view.cuda()\n",
    "            if index == 0:\n",
    "                print(\"input and target sent to CUDA\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. forward propagation\n",
    "        output = network(input)\n",
    "        \n",
    "        # 2. loss calculation\n",
    "        loss = loss_function(output[len(output)-1], target_view[0])       \n",
    "        \n",
    "        # 3. backward propagation\n",
    "        loss.backward() \n",
    "        \n",
    "        # 4. weight optimization\n",
    "        optimizer.step()\n",
    "            \n",
    "        \n",
    "        current_mask = output[len(output)-1].view(target.shape[0], target.shape[1])\n",
    "        mask.append(output[len(output)-1])\n",
    "\n",
    "        if index % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, index, len(train_set),\n",
    "            100. * index / len(train_set), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "            (index) + ((epoch-1)*len(train_set.items())))\n",
    "#             torch.save(network.state_dict(), './results/model.pth')\n",
    "#             torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for index, (input, target) in enumerate(test_set.items()):\n",
    "            \n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            target_view = target.view(-1, target.shape[0] * target.shape[1])\n",
    "            if torch.cuda.is_available():\n",
    "                input, target_view = input.cuda(), target_view.cuda()\n",
    "                if index == 0:\n",
    "                    print(\"input and target sent to CUDA\")\n",
    "            \n",
    "            output = network(input)\n",
    "            \n",
    "            test_loss += loss_function(output[len(output)-1], target_view[0])\n",
    "            \n",
    "            correct += (int)(torch.eq(output[len(output)-1], target_view[0]).sum())\n",
    "            \n",
    "#             print(\"test loss\",test_loss)\n",
    "            if index % 100 == 0:\n",
    "                print(\"correct\",correct)\n",
    "                print(\"--------------------------\")\n",
    "                print(\"o\",output[len(output)-1])\n",
    "                print(\"t\",target_view[0])\n",
    "                print(\"-----------------------\")\n",
    "\n",
    "#             break\n",
    "            \n",
    "    test_loss /= len(test_set)\n",
    "    test_losses.append(test_loss)\n",
    "    print(test_losses)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_set),\n",
    "    100. * correct / len(test_set)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
