{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import my_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_entire_audio(female, male, mix):\n",
    "    \n",
    "    n_fft = 2048\n",
    "    len_hop = (int)(n_fft / 4)\n",
    "    # compute stft for both audio files -> works better when calling librosa.mono -> forces the audio signal to go down to mono\n",
    "    # stft_1 = librosa.stft(female, n_fft=80) \n",
    "    # stft_2 = librosa.stft(male, n_fft=80) \n",
    "    # stft_mix = librosa.stft(mix, n_fft=80)\n",
    "    stft_1 = librosa.stft(librosa.to_mono(female), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_1_mag, stft_1_phase = librosa.magphase(stft_1)\n",
    "    s1  = librosa.core.fft_frequencies(sr=16000, n_fft=20)\n",
    "    \n",
    "    stft_2 = librosa.stft(librosa.to_mono(male), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_2_mag, stft_2_phase = librosa.magphase(stft_2)\n",
    "    \n",
    "    stft_mix = librosa.stft(librosa.to_mono(mix), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_mix_mag, stft_mix_phase = librosa.magphase(stft_mix)\n",
    "\n",
    "    print(stft_1.shape, stft_1_mag.shape, stft_1_phase.shape, s1.shape)\n",
    "    print(librosa.get_duration(y=female, sr=16000))\n",
    "\n",
    "    # get mask for entire audio\n",
    "    mask_1 = my_utils.compute_mask(stft_1, stft_2)\n",
    "    mask_2 = my_utils.compute_mask(stft_2, stft_1)\n",
    "#     print(stft_1.shape, stft_2.shape, stft_mix.shape, mask_1.shape)\n",
    "\n",
    "    first_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_1, stft_mix)\n",
    "    # print(first_sound_stft.shape)\n",
    "\n",
    "    second_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_2, stft_mix)\n",
    "    # print(second_sound_stft.shape)\n",
    "\n",
    "    my_utils.write_new_audio_file(first_sound_stft, '../../recordings/recover-female.wav')\n",
    "    my_utils.write_new_audio_file(second_sound_stft, '../../recordings/recover-male.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_final_zeros_for_silence(sound):\n",
    "    # Create an array that is 1 where a is 0, and pad each end with an extra 0.\n",
    "    iszero = np.concatenate(([0], np.equal(sound, 0).view(np.int8), [0]))\n",
    "    absdiff = np.abs(np.diff(iszero))\n",
    "    # Runs start and end where absdiff is 1.\n",
    "    ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n",
    "\n",
    "    if ranges.size == 0:\n",
    "        return sound\n",
    "       \n",
    "    start = ranges[len(ranges)-1][0]\n",
    "    stop = ranges[len(ranges)-1][1]\n",
    "    if stop == sound.shape[0]:\n",
    "        sound = sound[:start]\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_audio_using_small_segments(female_filename, male_filename):    \n",
    "    \n",
    "    n_fft = 2048\n",
    "    len_hop = (int)(n_fft / 4)\n",
    "    mix_filename= my_utils.mix_audios(male_filename, female_filename)\n",
    "    \n",
    "    male = AudioSegment.from_wav(male_filename)\n",
    "    female = AudioSegment.from_wav(female_filename)\n",
    "    mix = AudioSegment.from_wav(mix_filename)\n",
    "#     print(\"total seconds: \",female.__len__(), male.__len__(), mix.__len__())\n",
    "    \n",
    "#     female, male = make_wav_files_same_size(female, male)\n",
    "    \n",
    "    # the recover matrix must be the size of the mix, since the mix has the biggest size between the 2 audio files\n",
    "    # we only need the lines number, since we split the matrix of the sound in a vertically manner, we add new columns \n",
    "    # in time for the result matrix\n",
    "    mix_ndarray, r = my_utils.audiosegment_to_ndarray(mix)\n",
    "#     print(\"mix ndarray: \", mix_ndarray.shape)\n",
    "    fem, r = my_utils.audiosegment_to_ndarray(female)\n",
    "#     print(\"short ndarray: \", fem.shape)\n",
    "#     print(\"duration: \",librosa.get_duration(y=mix_ndarray, sr=16000))\n",
    "\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "    \n",
    "    total_ms = female.__len__()\n",
    "    frame_size_ms = 20\n",
    "    i = 0\n",
    "    \n",
    "    while i * frame_size_ms < total_ms:\n",
    "        start = i * frame_size_ms\n",
    "        stop = i * frame_size_ms + frame_size_ms\n",
    "        \n",
    "        # in case the frame size goes above mix length\n",
    "        if stop > total_ms:\n",
    "            fs = total_ms - start\n",
    "            stop = i * frame_size_ms + fs\n",
    "            \n",
    "#         print(total_ms, start, stop)\n",
    "        # get frames from all audio signals, type = audiosegment\n",
    "        frame_1 = my_utils.get_specific_frame_in_ms(female, start, stop)\n",
    "        frame_2 = my_utils.get_specific_frame_in_ms(male, start, stop)\n",
    "        frame_mix = my_utils.get_specific_frame_in_ms(mix,start, stop)\n",
    "        \n",
    "#         print(\"length in ms of frame \",len(frame_1), \" adica ia audio segments de cate 20 ms, mai apoi -> ndarray\")\n",
    "        # use the hop size at 50% of the frame size: for fs = 500, 0->500; 250->750; 500->1000...\n",
    "#         start = i * (frame_size_ms / 2)\n",
    "#         stop = i * (frame_size_ms / 2) + frame_size_ms\n",
    "#         frame_1 = get_specific_frame_in_ms(female_filename, start, stop)\n",
    "#         frame_2 = get_specific_frame_in_ms(male_filename, start, stop)\n",
    "#         frame_mix = get_specific_frame_in_ms(mix_filename,start, stop)\n",
    "\n",
    "        # from audio segment convert to ndarray how librosa uses\n",
    "        frame_1, r = my_utils.audiosegment_to_ndarray(frame_1)\n",
    "        frame_2, r = my_utils.audiosegment_to_ndarray(frame_2)\n",
    "        frame_mix, r = my_utils.audiosegment_to_ndarray(frame_mix)\n",
    "        \n",
    "#         print(\"length of ndarray of frame \",frame_1.shape)\n",
    "\n",
    "        frame_1, frame_mix = my_utils.make_wav_files_same_size(frame_1, frame_mix)\n",
    "        frame_2, frame_mix = my_utils.make_wav_files_same_size(frame_2, frame_mix)\n",
    "#         print(\"duration window: \",librosa.get_duration(y=frame_1, sr=16000))\n",
    "          \n",
    "        n_fft = 1024\n",
    "        hop_length = int(0.001 * 8000)\n",
    "        # compute the stft for each of them\n",
    "#         frame_1_stft = librosa.stft(librosa.to_mono(frame_1), window='hann', n_fft=1024)\n",
    "#         frame_2_stft = librosa.stft(librosa.to_mono(frame_2), window='hann', n_fft=1024)\n",
    "#         frame_mix_stft = librosa.stft(librosa.to_mono(frame_mix), window='hann', n_fft=1024)\n",
    "        frame_1_stft = librosa.stft(librosa.to_mono(frame_1), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        frame_2_stft = librosa.stft(librosa.to_mono(frame_2), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        frame_mix_stft = librosa.stft(librosa.to_mono(frame_mix), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        # compute masks for current frame\n",
    "        mask_1 = my_utils.compute_mask(frame_1_stft, frame_2_stft)\n",
    "        mask_2 = my_utils.compute_mask(frame_2_stft, frame_1_stft)\n",
    "\n",
    "        # get sound for each source of i-th frame\n",
    "        y_frame_1_stft = my_utils.get_stft_matrix_from_mixture(mask_1, frame_mix_stft)\n",
    "        y_frame_2_stft = my_utils.get_stft_matrix_from_mixture(mask_2, frame_mix_stft)\n",
    "        \n",
    "        inverse_sound1_stft = librosa.istft(y_frame_1_stft ,hop_length=hop_length, window='hann')\n",
    "        inverse_sound2_stft = librosa.istft(y_frame_2_stft, hop_length=hop_length, window='hann')\n",
    "        \n",
    "#         print(sound1.shape)\n",
    "#         print(inverse_sound1_stft.shape)\n",
    "        \n",
    "        sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "        sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "        \n",
    "        i += 1\n",
    "#         print(\"sound1 shape: \", sound1.shape)\n",
    "#         print(\"--------------------------------------------------------\")\n",
    "\n",
    "#     print(\"i: \", i)\n",
    "#     print(\"len final: \", sound_1_stft.shape)\n",
    "#     print(\"sound len final: \", sound1.shape)\n",
    "    sound1_start, sound1_end = mix_filename.index('arctic'), mix_filename.index('.wav')\n",
    "    name = \"../../recordings/rec_\" + mix_filename[sound1_start:sound1_end]\n",
    "    \n",
    "#     my_utils.write_new_audio_file(sound_1_stft, name + '_female.wav')\n",
    "#     my_utils.write_new_audio_file(sound_2_stft, name + '_male.wav')\n",
    "    sound1 = delete_final_zeros_for_silence(sound1)\n",
    "    sound2 = delete_final_zeros_for_silence(sound2)\n",
    "        \n",
    "    librosa.output.write_wav(name + '_female.wav', librosa.to_mono(sound1), sr = 16000)\n",
    "    librosa.output.write_wav(name + '_male.wav', sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_filename = '../../recordings/male1/arctic_a0451.wav'\n",
    "female_filename = '../../recordings/female1/arctic_a0327.wav'\n",
    "\n",
    "# for entire audio\n",
    "# female, male, mix = my_utils.load_and_mix_files(female_filename, male_filename)\n",
    "# split_entire_audio(female, male, mix)\n",
    "\n",
    "#---------------------------------------\n",
    "# split audio in segments\n",
    "# mix is created inside function\n",
    "split_audio_using_small_segments(female_filename, male_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
