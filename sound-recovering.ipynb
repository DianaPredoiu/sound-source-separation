{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\envs\\machine-learning\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import my_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_entire_audio(female, male, mix):\n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 256#8\n",
    "    sr = 16000\n",
    "    \n",
    "    # compute stft for both audio files -> works better when calling librosa.mono -> forces the audio signal to go down to mono\n",
    "    stft_1 = librosa.stft(librosa.to_mono(female), window='hann', n_fft=n_fft, hop_length=hop_length)    \n",
    "    stft_2 = librosa.stft(librosa.to_mono(male), window='hann', n_fft=n_fft, hop_length=hop_length)    \n",
    "    stft_mix = librosa.stft(librosa.to_mono(mix), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    \n",
    "    # get mask for entire audio\n",
    "    mask_1 = my_utils.compute_mask(stft_1, stft_2)\n",
    "    mask_2 = my_utils.compute_mask(stft_2, stft_1)\n",
    "    print(mask_1)\n",
    "\n",
    "#     mask_1 = librosa.util.softmask(np.abs(stft_1), np.abs(stft_2))\n",
    "#     mask_2 = librosa.util.softmask(np.abs(stft_2), np.abs(stft_1))\n",
    "    \n",
    "    first_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_1, stft_mix)\n",
    "    second_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_2, stft_mix)\n",
    "\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     plt.subplot(3, 1, 1)\n",
    "#     librosa.display.specshow(librosa.amplitude_to_db(np.abs(stft_mix[:2]), ref=np.max),\n",
    "#                              y_axis='log', sr=sr)\n",
    "#     plt.title('stft_mix')\n",
    "#     plt.colorbar()\n",
    "\n",
    "#     plt.subplot(3, 1, 2)\n",
    "#     librosa.display.specshow(librosa.amplitude_to_db(np.abs(stft_1[:2]), ref=np.max),\n",
    "#                              y_axis='log', sr=sr)\n",
    "#     plt.title('first_sound_stft')\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(3, 1, 3)\n",
    "#     librosa.display.specshow(librosa.amplitude_to_db(np.abs(first_sound_stft[:2]), ref=np.max),\n",
    "#                              y_axis='log', x_axis='time', sr=sr)\n",
    "#     plt.title('first_sound_stft after masking')\n",
    "#     plt.colorbar()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    inverse_sound1_stft = librosa.istft(first_sound_stft, hop_length=hop_length, window='hann')\n",
    "    inverse_sound2_stft = librosa.istft(second_sound_stft, hop_length=hop_length, window='hann')\n",
    "#     print(inverse_sound1_stft[:10])\n",
    "    \n",
    "    librosa.output.write_wav(\"../recordings/recover-full-female-2.wav\", inverse_sound1_stft, sr = 16000)\n",
    "    librosa.output.write_wav(\"../recordings/recover-full-male-2.wav\", inverse_sound2_stft, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_audio_using_small_segments(female_filename, male_filename):    \n",
    "    \n",
    "    n_fft = 1024\n",
    "    hop_length = 8\n",
    "    mix_filename= my_utils.mix_audios(male_filename, female_filename)\n",
    "    \n",
    "    male = AudioSegment.from_wav(male_filename)\n",
    "    female = AudioSegment.from_wav(female_filename)\n",
    "    mix = AudioSegment.from_wav(mix_filename)\n",
    "\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "    sound = np.empty([0,])\n",
    "    \n",
    "    total_ms = mix.__len__()\n",
    "    frame_size_ms = 20\n",
    "    i = 0\n",
    "    \n",
    "    while i * frame_size_ms < total_ms:\n",
    "        start = i * frame_size_ms\n",
    "        stop = i * frame_size_ms + frame_size_ms\n",
    "        \n",
    "        # use the hop size at 50% of the frame size: for fs = 500, 0->500; 250->750; 500->1000...\n",
    "#         start = i * (frame_size_ms / 2)\n",
    "#         stop = i * (frame_size_ms / 2) + frame_size_ms\n",
    "        \n",
    "        # in case the frame size goes above mix length\n",
    "        if stop > total_ms:\n",
    "            fs = total_ms - start\n",
    "            stop = i * frame_size_ms + fs\n",
    "            \n",
    "        # get frames from all audio signals, type = audiosegment\n",
    "        frame_1 = my_utils.get_specific_frame_in_ms(female, start, stop)\n",
    "        frame_2 = my_utils.get_specific_frame_in_ms(male, start, stop)\n",
    "        frame_mix = my_utils.get_specific_frame_in_ms(mix,start, stop)\n",
    "\n",
    "\n",
    "        # from audio segment convert to ndarray how librosa uses\n",
    "        frame_1, r = my_utils.audiosegment_to_ndarray(frame_1)\n",
    "        frame_2, r = my_utils.audiosegment_to_ndarray(frame_2)\n",
    "        frame_mix, r = my_utils.audiosegment_to_ndarray(frame_mix)\n",
    "        \n",
    "#         print(\"length of ndarray of frame \",frame_1.shape)\n",
    "\n",
    "        frame_1, frame_mix = my_utils.make_wav_files_same_size(frame_1, frame_mix)\n",
    "        frame_2, frame_mix = my_utils.make_wav_files_same_size(frame_2, frame_mix)\n",
    "#         print(\"duration window: \",librosa.get_duration(y=frame_1, sr=16000))\n",
    "          \n",
    "        # compute the stft for each of them\n",
    "        frame_1_stft = librosa.stft(librosa.to_mono(frame_1), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        frame_2_stft = librosa.stft(librosa.to_mono(frame_2), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        frame_mix_stft = librosa.stft(librosa.to_mono(frame_mix), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "#         inverse_sound1_stft = librosa.istft(frame_1_stft, hop_length=hop_length, window='hann')\n",
    "#         inverse_sound2_stft = librosa.istft(frame_2_stft, hop_length=hop_length, window='hann')\n",
    "        \n",
    "        # compute masks for current frame\n",
    "        mask_1 = my_utils.compute_mask(frame_1_stft, frame_2_stft)\n",
    "        mask_2 = my_utils.compute_mask(frame_2_stft, frame_1_stft)\n",
    "        \n",
    "#         mask_1 = librosa.util.softmask(np.abs(frame_1_stft), np.abs(frame_2_stft), power=1000)\n",
    "#         mask_2 = librosa.util.softmask(np.abs(frame_2_stft), np.abs(frame_1_stft), power=1000)\n",
    "\n",
    "        # get sound for each source of i-th frame\n",
    "        y_frame_1_stft_with_mask = mask_1 * frame_mix_stft\n",
    "        y_frame_2_stft_with_mask = mask_2 * frame_mix_stft\n",
    "        \n",
    "        inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "        inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "#         inverse_sound_mix_stft = librosa.istft(inv, hop_length=hop_length, window='hann')\n",
    "\n",
    "        sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "        sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "\n",
    "        if i == 0:\n",
    "            sr = 16000\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.subplot(3, 1, 1)\n",
    "            librosa.display.specshow(librosa.amplitude_to_db(np.abs(frame_1_stft.transpose()), ref=np.max),\n",
    "                                     y_axis='log', sr=sr)\n",
    "            plt.title('female - original segment STFT')\n",
    "            plt.colorbar()\n",
    "\n",
    "            plt.subplot(3, 1, 2)\n",
    "            librosa.display.specshow(librosa.amplitude_to_db(np.abs(frame_mix_stft.transpose()), ref=np.max),\n",
    "                                     y_axis='log', sr=sr)\n",
    "            plt.title('mix - segment STFT')\n",
    "            plt.colorbar()\n",
    "            plt.subplot(3, 1, 3)\n",
    "            librosa.display.specshow(librosa.amplitude_to_db(np.abs(y_frame_1_stft_with_mask.transpose()), ref=np.max),\n",
    "                                     y_axis='log', x_axis='time', sr=sr)\n",
    "            plt.title('female - segment with mask STFT')\n",
    "            plt.colorbar()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        i += 1\n",
    "\n",
    "\n",
    "    sound1_start, sound1_end = mix_filename.index('arctic'), mix_filename.index('.wav')\n",
    "    name = \"../recordings/rec_\" + mix_filename[sound1_start:sound1_end]\n",
    "\n",
    "    \n",
    "#     sound1 = my_utils.delete_final_zeros_for_silence(sound1)\n",
    "#     sound2 = my_utils.delete_final_zeros_for_silence(sound2)\n",
    "#     print(\"sound final: \", sound1[315:321], sep='\\n')\n",
    "        \n",
    "    librosa.output.write_wav(name + '_female.wav', sound1, sr = 16000)\n",
    "    librosa.output.write_wav(name + '_male2.wav', sound2, sr = 16000)\n",
    "#     librosa.output.write_wav(name + '_MIX-seg.wav', sound, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../recordings/male1/arctic_a0271.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0c6b326e41b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# split audio in segments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# mix is created inside function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msplit_audio_using_small_segments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfemale_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmale_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-44d9df0fa140>\u001b[0m in \u001b[0;36msplit_audio_using_small_segments\u001b[1;34m(female_filename, male_filename)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_fft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mhop_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmix_filename\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmy_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmix_audios\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmale_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfemale_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmale_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\sound-source-separation\\my_utils.py\u001b[0m in \u001b[0;36mmix_audios\u001b[1;34m(filename1, filename2)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmix_audios\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0msound1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0msound2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine-learning\\lib\\site-packages\\pydub\\audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\machine-learning\\lib\\site-packages\\pydub\\utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[1;34m(fd, mode, tempfile)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../recordings/male1/arctic_a0271.wav'"
     ]
    }
   ],
   "source": [
    "male_filename = '../recordings/male1/arctic_a0271.wav'\n",
    "female_filename = '../recordings/female1/arctic_a0161.wav'\n",
    "\n",
    "# for entire audio\n",
    "# female, male, mix = my_utils.load_and_mix_files(female_filename, male_filename)\n",
    "# split_entire_audio(female, male, mix)\n",
    "\n",
    "#---------------------------------------\n",
    "# split audio in segments\n",
    "# mix is created inside function\n",
    "split_audio_using_small_segments(female_filename, male_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
