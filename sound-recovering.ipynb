{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import my_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_entire_audio(female, male, mix):\n",
    "    \n",
    "    n_fft = 1024\n",
    "    len_hop = (int)(n_fft / 4)\n",
    "    # compute stft for both audio files -> works better when calling librosa.mono -> forces the audio signal to go down to mono\n",
    "    # stft_1 = librosa.stft(female, n_fft=80) \n",
    "    # stft_2 = librosa.stft(male, n_fft=80) \n",
    "    # stft_mix = librosa.stft(mix, n_fft=80)\n",
    "    stft_1 = librosa.stft(librosa.to_mono(female), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_1_mag, stft_1_phase = librosa.magphase(stft_1)\n",
    "    \n",
    "    stft_2 = librosa.stft(librosa.to_mono(male), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_2_mag, stft_2_phase = librosa.magphase(stft_2)\n",
    "    \n",
    "    stft_mix = librosa.stft(librosa.to_mono(mix), window='hann', n_fft=n_fft, hop_length=len_hop)\n",
    "    stft_mix_mag, stft_mix_phase = librosa.magphase(stft_mix)\n",
    "\n",
    "    print(stft_1.shape, stft_1_mag.shape, stft_1_phase.shape)\n",
    "\n",
    "    # get mask for entire audio\n",
    "    mask_1 = my_utils.compute_mask(stft_1, stft_2)\n",
    "    mask_2 = my_utils.compute_mask(stft_2, stft_1)\n",
    "    print(stft_1.shape, stft_2.shape, stft_mix.shape, mask_1.shape)\n",
    "\n",
    "    first_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_1, stft_mix)\n",
    "    # print(first_sound_stft.shape)\n",
    "\n",
    "    second_sound_stft = my_utils.get_stft_matrix_from_mixture(mask_2, stft_mix)\n",
    "    # print(second_sound_stft.shape)\n",
    "\n",
    "    my_utils.write_new_audio_file(first_sound_stft, '../recordings/recover-female.wav')\n",
    "    my_utils.write_new_audio_file(second_sound_stft, '../recordings/recover-male.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_audio_using_small_segments(female_filename, male_filename):    \n",
    "    \n",
    "    n_fft = 2048\n",
    "    len_hop = (int)(n_fft / 4)\n",
    "    mix_filename= my_utils.mix_audios(male_filename, female_filename)\n",
    "    \n",
    "    male = AudioSegment.from_wav(male_filename)\n",
    "    female = AudioSegment.from_wav(female_filename)\n",
    "    mix = AudioSegment.from_wav(mix_filename)\n",
    "    print(\"total seconds: \",female.__len__(), male.__len__(), mix.__len__())\n",
    "    \n",
    "#     female, male = make_wav_files_same_size(female, male)\n",
    "    \n",
    "    # the recover matrix must be the size of the mix, since the mix has the biggest size between the 2 audio files\n",
    "    # we only need the lines number, since we split the matrix of the sound in a vertically manner, we add new columns \n",
    "    # in time for the result matrix\n",
    "    mix_ndarray, r = my_utils.audiosegment_to_ndarray(mix)\n",
    "    lines, cols = librosa.stft(librosa.to_mono(mix_ndarray)).shape\n",
    "    sound_1_stft = np.empty([lines,0], dtype=np.float32)\n",
    "    sound_2_stft = np.empty([lines,0], dtype=np.float32)\n",
    "    \n",
    "    print(lines, cols)\n",
    "    \n",
    "    total_ms = mix.__len__()\n",
    "    frame_size_ms = 1000\n",
    "    i = 0\n",
    "    \n",
    "    while i * frame_size_ms < total_ms:\n",
    "        start = i * frame_size_ms\n",
    "        stop = i * frame_size_ms + frame_size_ms\n",
    "        \n",
    "        # in case the frame size goes above mix length\n",
    "        if stop > total_ms:\n",
    "            fs = total_ms - start\n",
    "            stop = i * frame_size_ms + fs\n",
    "            \n",
    "#         print(total_ms, start, stop)\n",
    "        # get frames from all audio signals, type = audiosegment\n",
    "        frame_1 = my_utils.get_specific_frame_in_ms(female, start, stop)\n",
    "        frame_2 = my_utils.get_specific_frame_in_ms(male, start, stop)\n",
    "        frame_mix = my_utils.get_specific_frame_in_ms(mix,start, stop)\n",
    "        \n",
    "        print(\"length in seconds of frame \",len(frame_1))\n",
    "        # use the hop size at 50% of the frame size: for fs = 500, 0->500; 250->750; 500->1000...\n",
    "#         start = i * (frame_size_ms / 2)\n",
    "#         stop = i * (frame_size_ms / 2) + frame_size_ms\n",
    "#         frame_1 = get_specific_frame_in_ms(female_filename, start, stop)\n",
    "#         frame_2 = get_specific_frame_in_ms(male_filename, start, stop)\n",
    "#         frame_mix = get_specific_frame_in_ms(mix_filename,start, stop)\n",
    "\n",
    "        # from audio segment convert to ndarray how librosa uses\n",
    "        frame_1, r = my_utils.audiosegment_to_ndarray(frame_1)\n",
    "        frame_2, r = my_utils.audiosegment_to_ndarray(frame_2)\n",
    "        frame_mix, r = my_utils.audiosegment_to_ndarray(frame_mix)\n",
    "        \n",
    "        print(\"length in array of frame \",len(frame_1), len(female))\n",
    "\n",
    "        frame_1, frame_mix = my_utils.make_wav_files_same_size(frame_1, frame_mix)\n",
    "        frame_2, frame_mix = my_utils.make_wav_files_same_size(frame_2, frame_mix)\n",
    "            \n",
    "        # compute the stft for each of them\n",
    "        frame_1_stft = librosa.stft(librosa.to_mono(frame_1), window='hann', hop_length=512)\n",
    "        frame_2_stft = librosa.stft(librosa.to_mono(frame_2), window='hann', hop_length=512)\n",
    "        frame_mix_stft = librosa.stft(librosa.to_mono(frame_mix), window='hann', hop_length=512)\n",
    "        \n",
    "        print(\"stft: \",frame_1_stft.shape, frame_2_stft.shape, frame_mix_stft.shape)\n",
    "        \n",
    "        # compute masks for current frame\n",
    "        mask_1 = my_utils.compute_mask(frame_1_stft, frame_2_stft)\n",
    "        mask_2 = my_utils.compute_mask(frame_2_stft, frame_1_stft)\n",
    "\n",
    "        # get sound for each source of i-th frame\n",
    "        y_frame_1_stft = my_utils.get_stft_matrix_from_mixture(mask_1, frame_mix_stft)\n",
    "        y_frame_2_stft = my_utils.get_stft_matrix_from_mixture(mask_2, frame_mix_stft)\n",
    "\n",
    "#         write_new_audio_file(y_frame_1_stft, '../recordings/recover-' + str(i) + '.wav')\n",
    "\n",
    "        sound_1_stft = np.hstack((sound_1_stft,y_frame_1_stft))\n",
    "        sound_2_stft = np.hstack((sound_2_stft,y_frame_2_stft))\n",
    "        i += 1\n",
    "\n",
    "    print(\"i: \", i)\n",
    "    print(\"len final: \", sound_1_stft.shape)\n",
    "    sound1_start, sound1_end = mix_filename.index('arctic'), mix_filename.index('.wav')\n",
    "    name = \"../recordings/RECOVER_\" + mix_filename[sound1_start:sound1_end]\n",
    "    \n",
    "    my_utils.write_new_audio_file(sound_1_stft, name + '_female.wav')\n",
    "    my_utils.write_new_audio_file(sound_2_stft, name + '_male.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total seconds:  6255 7000 7000\n",
      "1025 219\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  1000\n",
      "length in array of frame  16000 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "length in seconds of frame  255\n",
      "length in array of frame  4080 6255\n",
      "stft:  (1025, 32) (1025, 32) (1025, 32)\n",
      "i:  7\n",
      "len final:  (1025, 224)\n"
     ]
    }
   ],
   "source": [
    "male_filename = '../recordings/male1/arctic_a0023.wav'\n",
    "female_filename = '../recordings/female1/arctic_a0407.wav'\n",
    "\n",
    "# for entire audio\n",
    "# female, male, mix = my_utils.load_and_mix_files(female_filename, male_filename)\n",
    "# split_entire_audio(female, male, mix)\n",
    "\n",
    "#---------------------------------------\n",
    "# split audio in segments\n",
    "# mix is created inside function\n",
    "split_audio_using_small_segments(female_filename, male_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
