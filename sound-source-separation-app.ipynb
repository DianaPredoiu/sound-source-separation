{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 8\n",
    "sr = 16000\n",
    "\n",
    "# cate bucati PF iau in considerare pentru AF -> cu overlapping => 15 frame-uri \n",
    "# ultimul frame din AF fiind PF-ul curent\n",
    "nb_of_frames_in_AF = 4\n",
    "# exp_w_avg_beta = 0.98\n",
    "marja_eroare = 1e-2\n",
    "\n",
    "# frame_length_ms = 5\n",
    "# total_length_ms = 5000.0\n",
    "# nb_of_samples = 80000\n",
    "samples_per_frame_10ms = 160 #(int)(160000 * 10 / 10000.0)\n",
    "samples_per_frame_5ms = 80 #(int)(80000 * 5 / 5000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliz(mix):\n",
    "    mu = np.mean(mix, axis=0)\n",
    "    var = np.var(mix, axis=0)\n",
    "\n",
    "    mix_norm = (mix - mu) / np.sqrt(var + 1e-8)\n",
    "    \n",
    "    return mix_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(stft_1, stft_2):\n",
    "    # small epsilon to avoid dividing by zero\n",
    "    eps = np.finfo(np.float).eps\n",
    "\n",
    "    # compute model as the sum of spectrograms\n",
    "    mix = eps + np.abs(stft_1) + np.abs(stft_2)    \n",
    "    mask = np.divide(np.abs(stft_1), mix)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT_AF_frames(AF_array, PF_size):\n",
    "    frames = []\n",
    "    half = (int)(PF_size/2)\n",
    "    frames_added = 0\n",
    "    \n",
    "    i = AF_array.shape[0]-1\n",
    "    \n",
    "    # use AF as 4 times bigger than PF's size -> PF = 10 ms => AF = 40 ms\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 1. add PF[i]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 2. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 3. add PF[i - 1]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i - 1]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 4. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "        \n",
    "    \n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set_for_mix(mix, voice_1, voice_2, samples_per_frame):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_1_frames = np.array([voice_1[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_2_frames = np.array([voice_2[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    \n",
    "    for index in range(mix_frames.shape[0]):\n",
    "        \n",
    "        if index < 2:\n",
    "            continue\n",
    "        \n",
    "        # 1. create train set input for AF with current PF and previous frames\n",
    "        AF_frames = np.array([mix_frames[i] for i in range(index - 2, index)])      \n",
    "        AF_STFT_frames = get_STFT_AF_frames(AF_array=AF_frames, PF_size= samples_per_frame)\n",
    "        inputs.append(AF_STFT_frames)\n",
    "        \n",
    "        # 2. create train set target for that AF, containing the mask for the current PF\n",
    "        stft_voice_1 = librosa.stft(librosa.to_mono(voice_1_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        stft_voice_2 = librosa.stft(librosa.to_mono(voice_2_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        mask = compute_mask(stft_voice_1, stft_voice_2)\n",
    "        \n",
    "        targets.append(mask)\n",
    "    \n",
    "    # train set for only one audio\n",
    "    train_set_input = torch.from_numpy(np.array(inputs))\n",
    "    \n",
    "    # target contains the calculated masks for each PF from mix\n",
    "    train_set_target = torch.from_numpy(np.array(targets))\n",
    "    return np.array(inputs), np.array(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(Network, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(1 * height * width, 300)\n",
    "        self.fc_batch = nn.BatchNorm1d(300)\n",
    "        \n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        \n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(300, height * width)\n",
    "        self.fc3_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # layer 1\n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        x = x.view(-1, self.height * self.width)        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_batch(x)\n",
    "        x = torch.relu(x)\n",
    "#         x = self.drop(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc_batch(x)\n",
    "        x = torch.relu(x)\n",
    "#         x = self.drop(x)\n",
    "        \n",
    "#          # layer 2\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc_batch(x)\n",
    "#         x = torch.relu(x)\n",
    "# #         x = self.drop(x)\n",
    "        \n",
    "#                  # layer 2\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc_batch(x)\n",
    "#         x = torch.relu(x)\n",
    "# #         x = self.drop(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConv(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(NetworkConv, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, padding=2)\n",
    "        self.conv1_batch = nn.BatchNorm2d(20)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, padding=1)\n",
    "        \n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(20, 20, kernel_size=5, padding=2)\n",
    "        self.conv2_batch = nn.BatchNorm2d(20)\n",
    "    \n",
    "        # layer 3\n",
    "        self.fc1 = nn.Linear(20 * 129 * 6, 400)\n",
    "        self.fc1_batch = nn.BatchNorm1d(400)\n",
    "        \n",
    "        # layer 4\n",
    "        self.fc2 = nn.Linear(400, 400)\n",
    "        \n",
    "        # layer 5\n",
    "        self.fc3 = nn.Linear(400, height * width)\n",
    "        self.fc3_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        \n",
    "        \n",
    "        # layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = x.view(-1, self.height * self.width * 20) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 4\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_10_seconds(voice):\n",
    "    nb_sample_for_10_seconds = 160000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_10_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_10_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_10_seconds:\n",
    "        voice = voice[0:nb_sample_for_10_seconds]\n",
    "    \n",
    "    return voice        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_5_seconds(voice):\n",
    "    nb_sample_for_5_seconds = 80000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_5_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_5_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_5_seconds:\n",
    "        voice = voice[0:nb_sample_for_5_seconds]\n",
    "    \n",
    "    return voice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_interchanged(voice, is_valid):\n",
    "    voices = []\n",
    "    pos_half = (int)(len(voice) / 2)\n",
    "    pos_1quart = (int)(pos_half / 2)\n",
    "    pos_3quart = (int)(pos_half + (pos_half / 2))\n",
    "    pos_1third = 26000\n",
    "    \n",
    "    if is_valid == True:\n",
    "        voice_perm = voice[pos_1third * 2 :len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1third])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1third:pos_1third * 2])\n",
    "        voices.append(voice_perm)\n",
    "    else:\n",
    "        voices.append(voice)\n",
    "\n",
    "        voice_perm = voice[pos_3quart:len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_half])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voices.append(voice_perm)\n",
    "        \n",
    "        voice_perm = voice[pos_half:pos_3quart]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_3quart:len(voice)])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_half])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voices.append(voice_perm)\n",
    "        \n",
    "        voice_perm = voice[pos_1quart:pos_half]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_3quart:len(voice)])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voices.append(voice_perm)\n",
    "        \n",
    "        voice_perm = voice[pos_3quart:len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_half])\n",
    "        voices.append(voice_perm)\n",
    "\n",
    "\n",
    "        voice_perm = voice[pos_1quart:pos_half]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:len(voice)])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voices.append(voice_perm)\n",
    "    \n",
    "    return np.array(voices)\n",
    "    \n",
    "    # split voice into smaller batches/chunks\n",
    "    # np.array_split takes as args the data input and the number of batches!!! not the number of elems in a batch\n",
    "#     if is_valid == False:\n",
    "#         voice_batches = np.array_split(np.array(voice),5)\n",
    "#     else:\n",
    "#         voice_batches = np.array_split(np.array(voice),6)\n",
    "        \n",
    "#     np.random.shuffle(voice_batches)\n",
    "\n",
    "#     voice_perm = []\n",
    "#     for v in voice_batches:\n",
    "#         voice_perm.extend(v)\n",
    "    \n",
    "#     return np.array(voice_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                 samples_per_frame, mix_5_seconds):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix = voice1 + voice2\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "    mix = np.array(mix)\n",
    "\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_set_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interchanged_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                 samples_per_frame, mix_5_seconds, nb_of_permutations, is_validation):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    noise_filename = 'recordings/noises/piano5sec.wav'\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    noise, sr = librosa.load(noise_filename, sr=16000)\n",
    "    noise = np.append(noise, noise)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "\n",
    "    voices1 = get_voice_interchanged(voice1, is_validation)\n",
    "    voices2 = get_voice_interchanged(voice2, is_validation)\n",
    "        \n",
    "    for i in range(len(voices1)):\n",
    "            mix = voices1[i] + voices2[i]\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voices1[i], voices2[i], samples_per_frame)\n",
    "            print(inputs.shape)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    # add combinations : voice1+noise and voice2+noise only for TRAIN SET\n",
    "#     if is_validation == False:\n",
    "#         noise = noise / 5\n",
    "#         mix = voice1 + noise\n",
    "#         mix = np.array(mix)\n",
    "\n",
    "#         inputs, targets = get_train_set_for_mix(mix, voice1, noise, samples_per_frame)\n",
    "#         print(inputs.shape)\n",
    "#         inputs_list.extend(inputs)\n",
    "#         targets_list.extend(targets)\n",
    "\n",
    "#         mix = voice2 + noise\n",
    "#         mix = np.array(mix)\n",
    "\n",
    "#         inputs, targets = get_train_set_for_mix(mix, voice2, noise, samples_per_frame)\n",
    "#         print(inputs.shape)\n",
    "#         inputs_list.extend(inputs)\n",
    "#         targets_list.extend(targets)\n",
    "    #------------------------------------------------------------\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_interchanged_set_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_with_noise_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                            samples_per_frame, mix_5_seconds, noise_filename):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    noise, sr = librosa.load(noise_filename, sr=16000) \n",
    "    noise = np.append(noise, noise)\n",
    "    noise = noise / 5\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix = voice1 + voice2 + noise\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "    noise = np.array(noise)\n",
    "    mix = np.array(mix)\n",
    "\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_set_with_noise_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices_80_10_10(voice1_file_name, voice2_file_name, \n",
    "                                          samples_per_frame, mix_5_seconds):\n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000) \n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "    train_len = (int)(80/100 * len(voice1))\n",
    "    diff = (int)( (len(voice1) - train_len) / 2)\n",
    "    \n",
    "    # --------------------------------------split voices into train/valid/test sets\n",
    "    voice1_train = voice1[:train_len]\n",
    "    voice2_train = voice2[:train_len]\n",
    "    print(len(voice1_train))\n",
    "    \n",
    "    voice1_valid = voice1[train_len:(train_len + diff)]\n",
    "    voice2_valid = voice2[train_len:(train_len + diff)]\n",
    "    print(len(voice1_valid))\n",
    "    \n",
    "    voice1_test = voice1[(train_len + diff):len(voice1)]\n",
    "    voice2_test = voice2[(train_len + diff):len(voice2)]\n",
    "    print(len(voice1_test))\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "\n",
    "    # -------------------------------------compute train set [with permutations or without]\n",
    "    inputs_list, targets_list = [], []\n",
    "        \n",
    "#     mix = voice1_train + voice2_train\n",
    "#     mix = np.array(mix)\n",
    "\n",
    "#     inputs, targets = get_train_set_for_mix(mix, voice1_train, voice2_train, samples_per_frame)\n",
    "#     inputs_list.extend(inputs)\n",
    "#     targets_list.extend(targets)\n",
    "    \n",
    "            \n",
    "    voices1 = get_voice_interchanged(voice1_train, False)\n",
    "    voices2 = get_voice_interchanged(voice2_train, False)\n",
    "        \n",
    "    for i in range(len(voices1)):\n",
    "            mix = voices1[i] + voices2[i]\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voices1[i], voices2[i], samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "\n",
    "#   for i in range(nb_of_permutations):\n",
    "\n",
    "#       voice1_perm = get_voice_interchanged(voice1_train)\n",
    "#       voice2_perm = get_voice_interchanged(voice2_train)\n",
    "\n",
    "#       mix = voice1_perm + voice2_perm\n",
    "#       mix = np.array(mix)\n",
    "\n",
    "#       inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "#       inputs_list.extend(inputs)\n",
    "#       targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    train_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    # ------------------------------------------------------compute valid set\n",
    "    inputs_list, targets_list = [], []\n",
    "    \n",
    "    mix = voice1_valid + voice2_valid\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1_valid, voice2_valid, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    valid_set = dict(zip(inputs_list, targets_list))\n",
    "\n",
    "    # ---------------------------------------------------------compute test set\n",
    "    inputs_list, targets_list = [], []\n",
    "    \n",
    "    mix = voice1_test + voice2_test\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1_test, voice2_test, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    test_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    print(\"create_set_from_voices_80_10_10 sets dim:\", len(train_set), len(valid_set), len(test_set))\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n",
      "8000\n",
      "8000\n",
      "create_set_from_voices_80_10_10 sets dim: 2388 48 48\n",
      "create_set_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "(498, 4, 1, 513, 21)\n",
      "(498, 4, 1, 513, 21)\n",
      "(498, 4, 1, 513, 21)\n",
      "(498, 4, 1, 513, 21)\n",
      "(498, 4, 1, 513, 21)\n",
      "(498, 4, 1, 513, 21)\n",
      "create_interchanged_set_from_voices dims:  torch.Size([2988, 4, 1, 513, 21]) torch.Size([2988, 513, 21])\n",
      "(498, 4, 1, 513, 21)\n",
      "create_interchanged_set_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "create_set_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "create_set_with_noise_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n"
     ]
    }
   ],
   "source": [
    "noise_filename = 'recordings/noises/piano5sec.wav'\n",
    "noise2_filename = 'recordings/noises/engine.wav'\n",
    "noise3_filename = 'recordings/noises/beeps.wav'\n",
    "\n",
    "voice1_file_name = 'recordings/voice1/arctic_a0007.wav'\n",
    "voice2_file_name = 'recordings/voice2/arctic_a0032.wav'\n",
    "\n",
    "voice1_file_names_list2 = ['recordings/voice1/arctic_a0407.wav']\n",
    "voice2_file_names_list2 = ['recordings/voice2/arctic_a0032.wav']\n",
    "\n",
    "noises_list = ['recordings/noises/engine.wav', 'recordings/noises/applauses.wav', 'recordings/noises/beeps.wav']\n",
    "\n",
    "\n",
    "train_set_80, valid_set_10, test_set_10 = create_set_from_voices_80_10_10(voice1_file_name, voice2_file_name,\n",
    "                                                                        samples_per_frame=samples_per_frame_10ms,\n",
    "                                                                        mix_5_seconds=True)\n",
    "# un singur mix, intreg, simplu\n",
    "train_set = create_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                         samples_per_frame = samples_per_frame_10ms,\n",
    "                                        mix_5_seconds= True)\n",
    "\n",
    "# un singur mix, intreg, 3 inregistrari, din care 2 permutate\n",
    "train_set_interchanged = create_interchanged_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                         samples_per_frame = samples_per_frame_10ms,\n",
    "                                        mix_5_seconds= True, nb_of_permutations = 3, is_validation=False)\n",
    "\n",
    "# un singur mix, intreg, permutat in alt mod fata de permutarile din train\n",
    "# are si un noise de applause in functie, doar trebuie comentat / decomentat cand e adaugat in mix\n",
    "valid_set = create_interchanged_set_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame = samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, nb_of_permutations = 1, is_validation=True)\n",
    "\n",
    "# un singur mix, intreg, contine doar cele doua voci pentru care s-a facut trainul\n",
    "test_set = create_set_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True)\n",
    "\n",
    "# un singur mix, intreg, cele doua voci + zgomot de pian\n",
    "test_set_with_noise = create_set_with_noise_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, \n",
    "                                                    noise_filename=noise_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(nr_epochs, train_set, valid_set, test_set, model_name, optimizer, network):\n",
    "\n",
    "    # plot train/valid loss contains losses on each epoch, so we can see after each epoch what happens with the error\n",
    "    plot_train_losses = []\n",
    "    plot_valid_losses = []\n",
    "    plot_train_accuracy = []\n",
    "    plot_valid_accuracy = []\n",
    "\n",
    "\n",
    "    epoch = 1\n",
    "    while epoch <= nr_epochs:\n",
    "        \n",
    "        correct_train = 0\n",
    "        correct_test = 0\n",
    "        train_losses, valid_losses = [], []\n",
    "        loss = 0\n",
    "\n",
    "        # training part \n",
    "        network.train()\n",
    "        for index, (input, target) in enumerate(train_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network(input)\n",
    "\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1])  \n",
    "\n",
    "\n",
    "            # 3. backward propagation\n",
    "            loss.backward() \n",
    "\n",
    "\n",
    "            # 4. weight optimization\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # 5. save the loss for this PF\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            \n",
    "            # 6. check how many items where predicted correctly\n",
    "            correct_train += 1 if loss.item() <= marja_eroare else 0 \n",
    "            \n",
    "\n",
    "        # add the mean loss for this training epoch for ploting\n",
    "        train_mean_loss_for_epoch = np.mean(train_losses)\n",
    "        plot_train_losses.append(train_mean_loss_for_epoch)\n",
    "        \n",
    "        current_accuracy = (int)(100. * correct_train / len(train_set))\n",
    "        plot_train_accuracy.append(current_accuracy)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "            print(\"Train set -> \", \"loss: \", loss.item(), \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                  str(correct_train) + \"/\" + str(len(train_set)) + \"]\")\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # evaluation part \n",
    "#         network.eval()\n",
    "        if epoch % 1 == 0:\n",
    "#             \n",
    "            with torch.no_grad():\n",
    "                for index, (input, target) in enumerate(valid_set.items()):\n",
    "\n",
    "                    # if cuda is available, send (input, target) to gpu\n",
    "                    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "                    # 1. forward propagation\n",
    "                    output = network.forward(input)\n",
    "\n",
    "                    # 2. loss calculation\n",
    "                    loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "                    \n",
    "                    # 3. save loss for current PF\n",
    "                    valid_losses.append(loss)\n",
    "\n",
    "                    # 4. check how many items where predicted correctly\n",
    "                    correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "                 # add the mean loss for this training epoch for ploting\n",
    "                valid_mean_loss_for_epoch = np.mean(valid_losses)\n",
    "                plot_valid_losses.append(valid_mean_loss_for_epoch)\n",
    "                \n",
    "                current_accuracy = (int)(100. * correct_test / len(valid_set))\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == 1 :\n",
    "                    print(\"Valid set -> \", \"loss: \", loss, \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(valid_set)) + \"]\")\n",
    "                \n",
    "                if len(plot_valid_accuracy) >= 1:\n",
    "                    if current_accuracy > max(plot_valid_accuracy):\n",
    "                        print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "                        torch.save(network, str(current_accuracy) + \"-valid-\"+ model_name)\n",
    "                        network_test = torch.load(str(current_accuracy) + \"-valid-\" + model_name)\n",
    "                        eval(network=network_test, test_set=test_set)\n",
    "            \n",
    "            plot_valid_accuracy.append(current_accuracy)\n",
    "            \n",
    "            if len(plot_valid_losses) >= 5:\n",
    "                valid_l = plot_valid_losses[len(plot_valid_losses) - 5 : len(plot_valid_losses)]\n",
    "                train_l = plot_train_losses[len(plot_train_losses) - 5 : len(plot_train_losses)]\n",
    "                if valid_l == sorted(valid_l) and train_l == sorted(train_l, reverse=True):\n",
    "                    \n",
    "                    print(\"Stop training due to validation loss increasing [training loss decreasing] for 5 consecutive epochs.\")\n",
    "                    break\n",
    "                if all(x >= 98 for x in plot_valid_accuracy[len(plot_valid_accuracy) - 10: len(plot_valid_accuracy)]):\n",
    "                    print(\"Stop training due to validation accuracy greater than 98% for 10 epochs.\")\n",
    "                    break\n",
    "                    \n",
    "        epoch += 1\n",
    "\n",
    "    torch.save(network, model_name)\n",
    "    \n",
    "    plt.plot(plot_train_losses, label='Training loss')\n",
    "    plt.plot(plot_valid_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(plot_train_accuracy, label='Training accuracy')\n",
    "    plt.plot(plot_valid_accuracy, label='Validation accuracy')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONSTRUIRE SUNET PE FRAME-URI, FOLOSIND TARGETURILE GENERATE PT SETUL DE ANTRENARE\n",
    "def split_audios_epoch(name, mask, mix, samples_per_frame):\n",
    "    \n",
    "    frame_pos = (int)(nb_of_frames_in_AF/2)\n",
    "\n",
    "    mask_stack = torch.stack(mask)\n",
    "    cpu_mask = mask_stack.cpu()\n",
    "    n_mask = cpu_mask.detach().numpy()\n",
    "\n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "\n",
    "\n",
    "    for i in range (0, len(mix_frames)):\n",
    "        stft_mix = librosa.stft(librosa.to_mono(mix_frames[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        # reteaua nu a invatat mastile pentru primele frame_pos bucati [PF] din mix\n",
    "        # deci las matricea STFT asa cum e in mix\n",
    "        if i < frame_pos :\n",
    "            y_frame_1_stft_with_mask = stft_mix\n",
    "            y_frame_2_stft_with_mask = stft_mix\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "            \n",
    "        else:\n",
    "            # n_mask[i-7] pentru ca reteaua invata pt AF-uri facute pe cate 8 PF-uri -> 15 items pt AF\n",
    "            # abia de cand ajunge la primul AF care s a putut compune, folosesc masca invata de retea\n",
    "            \n",
    "            y_frame_1_stft_with_mask = np.multiply(n_mask[i-frame_pos], stft_mix)\n",
    "            y_frame_2_stft_with_mask = np.multiply((1 -  n_mask[i-frame_pos]), stft_mix)\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "\n",
    "\n",
    "    librosa.output.write_wav(\"recordings/voice1-\"+ str(name) + \".wav\", sound1, sr = 16000)\n",
    "    librosa.output.write_wav(\"recordings/voice2-\"+ str(name) + \".wav\", sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, test_set):\n",
    "\n",
    "#     network.eval()\n",
    "                \n",
    "    test_loss, test_mask, test_accuracy = [], [], []\n",
    "    correct_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (input, target) in enumerate(test_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network.forward(input)\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "\n",
    "            # 3. save the mask for the current PF, meaning the last entry in the output\n",
    "            current_mask = output[len(output)-1]\n",
    "            test_mask.append(current_mask)\n",
    "\n",
    "            test_loss.append(loss)\n",
    "\n",
    "            # 4. check how many items where predicted correctly\n",
    "            correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "\n",
    "        current_accuracy = 100. * correct_test / len(test_set)\n",
    "        print(\"Test set -> \", \"test loss: \", np.mean(test_loss), \"accuracy: \", (int)(current_accuracy), \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(test_set)) + \"]\")\n",
    "\n",
    "        return test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdam(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "\n",
    "    print(\"__________________________________________ADAM FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    network = Network()\n",
    "    \n",
    "    print(\"network sent to CUDA\")\n",
    "    network.cuda()\n",
    "    \n",
    "    # set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(network.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set = test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=network)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdamConv(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "    \n",
    "    print(\"__________________________________________ADAM CONV + FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    networkConv = NetworkConv()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"networkConv sent to CUDA\")\n",
    "        networkConv.cuda()\n",
    "        \n",
    "    # set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(networkConv.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set=test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=networkConv)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices(voice1_filename, voice2_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        \n",
    "    mix = voice1 + voice2\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-withOUT-noise.wav\", mix, 16000)\n",
    "    \n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices_with_noise(voice1_filename, voice2_filename, noise_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    noise, sr = librosa.load(noise_filename, sr=16000)\n",
    "    noise = np.append(noise, noise)\n",
    "    noise = noise / 5\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "    \n",
    "    mix = voice1 + voice2 + noise\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-with-noise.wav\", mix, 16000)\n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ADAM FC_________________________________\n",
      "network sent to CUDA\n",
      "--------------------------------------Epoch 1 ------------------------------\n",
      "Train set ->  loss:  0.11829706281423569 accuracy:  0 % [10/2988]\n",
      "Valid set ->  loss:  0.11680864542722702 accuracy:  0 % [1/498]\n",
      "--------------------------------------Epoch 2 ------------------------------\n",
      "Test set ->  test loss:  0.09541109730732668 accuracy:  0 % [1/498]\n",
      "--------------------------------------Epoch 4 ------------------------------\n",
      "Test set ->  test loss:  0.08017326193935534 accuracy:  0 % [4/498]\n",
      "--------------------------------------Epoch 5 ------------------------------\n",
      "Test set ->  test loss:  0.0726564155880317 accuracy:  1 % [6/498]\n",
      "--------------------------------------Epoch 7 ------------------------------\n",
      "Test set ->  test loss:  0.06581813788479082 accuracy:  1 % [9/498]\n",
      "--------------------------------------Epoch 8 ------------------------------\n",
      "Test set ->  test loss:  0.06375207533605441 accuracy:  3 % [17/498]\n",
      "--------------------------------------Epoch 9 ------------------------------\n",
      "Test set ->  test loss:  0.061928362853967224 accuracy:  4 % [20/498]\n",
      "--------------------------------------Epoch 10 ------------------------------\n",
      "Train set ->  loss:  0.009300487115979195 accuracy:  16 % [500/2988]\n",
      "Valid set ->  loss:  0.006015125196427107 accuracy:  23 % [119/498]\n",
      "--------------------------------------Epoch 10 ------------------------------\n",
      "Test set ->  test loss:  0.05966634122583731 accuracy:  5 % [25/498]\n",
      "--------------------------------------Epoch 11 ------------------------------\n",
      "Test set ->  test loss:  0.060813756918171834 accuracy:  7 % [38/498]\n",
      "--------------------------------------Epoch 12 ------------------------------\n",
      "Test set ->  test loss:  0.0594567576372794 accuracy:  9 % [47/498]\n",
      "--------------------------------------Epoch 13 ------------------------------\n",
      "Test set ->  test loss:  0.05865606637559382 accuracy:  14 % [73/498]\n",
      "--------------------------------------Epoch 14 ------------------------------\n",
      "Test set ->  test loss:  0.0586869299713799 accuracy:  16 % [81/498]\n",
      "--------------------------------------Epoch 15 ------------------------------\n",
      "Test set ->  test loss:  0.05939852015136827 accuracy:  17 % [88/498]\n",
      "--------------------------------------Epoch 16 ------------------------------\n",
      "Test set ->  test loss:  0.05891868525351132 accuracy:  16 % [84/498]\n",
      "--------------------------------------Epoch 17 ------------------------------\n",
      "Test set ->  test loss:  0.058622513542393125 accuracy:  21 % [106/498]\n",
      "--------------------------------------Epoch 18 ------------------------------\n",
      "Test set ->  test loss:  0.059093756446695275 accuracy:  22 % [114/498]\n",
      "--------------------------------------Epoch 19 ------------------------------\n",
      "Test set ->  test loss:  0.05871625626403614 accuracy:  24 % [124/498]\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "Train set ->  loss:  0.0038147715386003256 accuracy:  95 % [2853/2988]\n",
      "Valid set ->  loss:  0.0033530944492667913 accuracy:  93 % [466/498]\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "Test set ->  test loss:  0.05850525933082204 accuracy:  27 % [136/498]\n",
      "--------------------------------------Epoch 21 ------------------------------\n",
      "Test set ->  test loss:  0.057304790948310036 accuracy:  27 % [139/498]\n",
      "--------------------------------------Epoch 22 ------------------------------\n",
      "Test set ->  test loss:  0.057948682716922335 accuracy:  28 % [144/498]\n",
      "--------------------------------------Epoch 29 ------------------------------\n",
      "Test set ->  test loss:  0.05829073661278155 accuracy:  30 % [151/498]\n",
      "--------------------------------------Epoch 30 ------------------------------\n",
      "Train set ->  loss:  0.002508819103240967 accuracy:  99 % [2961/2988]\n",
      "Valid set ->  loss:  0.0023875574115663767 accuracy:  98 % [493/498]\n",
      "Stop training due to validation accuracy greater than 98% for 10 epochs.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 200epoci-FC-mix-intreg-permutat-v1(7)-v2(32).pth : 00:24:13.65\n",
      "Test set ->  test loss:  0.0030180932380058935 accuracy:  98 % [493/498]\n",
      "Test set ->  test loss:  0.05884460239469197 accuracy:  30 % [152/498]\n"
     ]
    }
   ],
   "source": [
    "import winsound\n",
    "import os\n",
    "\n",
    "voice1 = 'recordings/voice1/arctic_a0007.wav'\n",
    "voice2 = 'recordings/voice2/arctic_a0032.wav'\n",
    "    \n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(300, train_set, valid_set, test_set_with_noise, \"FC-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set, valid_set, test_set_with_noise, \"CONV-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_80, valid_set_10, test_set_10, \"FC-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set_80, valid_set_10, test_set_10, \"CONV-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_name = runAdam(200, train_set_interchanged, valid_set, test_set_with_noise, \"FC-mix-intreg-permutat-v1(7)-v2(32)\")\n",
    "\n",
    "# test first what it learned from train\n",
    "mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set)\n",
    "split_audios_epoch(\"FC-mix-intreg-permutat-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# test with noise\n",
    "mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "split_audios_epoch(\"FC-mix-intreg-permutat-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "# mai trebuie convolutionala aici\n",
    "# ------------------------------------------------------------------------------------\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_interchanged_and_noisy, valid_set, test_set_with_noise, \"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_80, valid_set_10, test_set_10, \"FC-mix-80-10-10-permutat-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-permutat-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-permutat-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
