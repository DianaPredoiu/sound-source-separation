{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 8\n",
    "sr = 16000\n",
    "\n",
    "# cate bucati PF iau in considerare pentru AF -> cu overlapping => 15 frame-uri \n",
    "# ultimul frame din AF fiind PF-ul curent\n",
    "nb_of_frames_in_AF = 4\n",
    "# exp_w_avg_beta = 0.98\n",
    "marja_eroare = 1e-2\n",
    "\n",
    "# frame_length_ms = 5\n",
    "# total_length_ms = 5000.0\n",
    "# nb_of_samples = 80000\n",
    "samples_per_frame_10ms = 160 #(int)(160000 * 10 / 10000.0)\n",
    "samples_per_frame_5ms = 80 #(int)(80000 * 5 / 5000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliz(mix):\n",
    "    mu = np.mean(mix, axis=0)\n",
    "    var = np.var(mix, axis=0)\n",
    "\n",
    "    mix_norm = (mix - mu) / np.sqrt(var + 1e-8)\n",
    "    \n",
    "    return mix_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(stft_1, stft_2):\n",
    "    # small epsilon to avoid dividing by zero\n",
    "    eps = np.finfo(np.float).eps\n",
    "\n",
    "    # compute model as the sum of spectrograms\n",
    "    mix = eps + np.abs(stft_1) + np.abs(stft_2)    \n",
    "    mask = np.divide(np.abs(stft_1), mix)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT_AF_frames(AF_array, PF_size):\n",
    "    frames = []\n",
    "    half = (int)(PF_size/2)\n",
    "    frames_added = 0\n",
    "    \n",
    "    i = AF_array.shape[0]-1\n",
    "    \n",
    "    # use AF as 4 times bigger than PF's size -> PF = 10 ms => AF = 40 ms\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 1. add PF[i]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 2. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 3. add PF[i - 1]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i - 1]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 4. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "        \n",
    "    \n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set_for_mix(mix, voice_1, voice_2, samples_per_frame):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_1_frames = np.array([voice_1[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_2_frames = np.array([voice_2[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    \n",
    "    for index in range(mix_frames.shape[0]):\n",
    "        \n",
    "        if index < 2:\n",
    "            continue\n",
    "        \n",
    "        # 1. create train set input for AF with current PF and previous frames\n",
    "        AF_frames = np.array([mix_frames[i] for i in range(index - 2, index)])      \n",
    "        AF_STFT_frames = get_STFT_AF_frames(AF_array=AF_frames, PF_size= samples_per_frame)\n",
    "        inputs.append(AF_STFT_frames)\n",
    "        \n",
    "        # 2. create train set target for that AF, containing the mask for the current PF\n",
    "        stft_voice_1 = librosa.stft(librosa.to_mono(voice_1_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        stft_voice_2 = librosa.stft(librosa.to_mono(voice_2_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        mask = compute_mask(stft_voice_1, stft_voice_2)\n",
    "        \n",
    "        targets.append(mask)\n",
    "    \n",
    "    # train set for only one audio\n",
    "    train_set_input = torch.from_numpy(np.array(inputs))\n",
    "    \n",
    "    # target contains the calculated masks for each PF from mix\n",
    "    train_set_target = torch.from_numpy(np.array(targets))\n",
    "    return np.array(inputs), np.array(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(Network, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(1 * height * width, 250)\n",
    "        self.fc1_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(250, 250)\n",
    "        self.fc2_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(250, height * width)\n",
    "        self.fc3_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # layer 1\n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        x = x.view(-1, self.height * self.width)        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConv(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(NetworkConv, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, padding=2)\n",
    "        self.conv1_batch = nn.BatchNorm2d(20)\n",
    "        \n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(20, 20, kernel_size=5, padding=2)\n",
    "        self.conv2_batch = nn.BatchNorm2d(20)\n",
    "    \n",
    "        # layer 3\n",
    "        self.fc1 = nn.Linear(20 * height * width, 250)\n",
    "        self.fc1_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 4\n",
    "        self.fc2 = nn.Linear(250, height * width)\n",
    "        self.fc2_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        \n",
    "        \n",
    "        # layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = x.view(-1, self.height * self.width * 20) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 4\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_10_seconds(voice):\n",
    "    nb_sample_for_10_seconds = 160000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_10_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_10_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_10_seconds:\n",
    "        voice = voice[0:nb_sample_for_10_seconds]\n",
    "    \n",
    "    return voice        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_5_seconds(voice):\n",
    "    nb_sample_for_5_seconds = 80000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_5_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_5_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_5_seconds:\n",
    "        voice = voice[0:nb_sample_for_5_seconds]\n",
    "    \n",
    "    return voice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_interchanged(voice, is_valid):\n",
    "    voices = []\n",
    "    pos_half = (int)(len(voice) / 2)\n",
    "    pos_1quart = (int)(pos_half / 2)\n",
    "    pos_3quart = (int)(pos_half + (pos_half / 2))\n",
    "    pos_1eight = pos_1quart + (int)(pos_1quart / 2)\n",
    "    \n",
    "    if is_valid == True:\n",
    "        voice_perm = voice[pos_3quart:len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_half])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voices.append(voice_perm)\n",
    "    else:\n",
    "        voices.append(voice)\n",
    "    #     voice_perm = voice[pos_3quart:len(voice)]\n",
    "    #     voice_perm = np.append(voice_perm, voice[0:pos_half])\n",
    "    #     voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "    #     voices.append(voice_perm)\n",
    "\n",
    "    #     voice_perm = voice[pos_3quart:len(voice)]\n",
    "    #     voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "    #     voice_perm = np.append(voice_perm, voice[pos_1quart:pos_half])\n",
    "    #     voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "    #     voices.append(voice_perm)\n",
    "\n",
    "        voice_perm = voice[pos_3quart:len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_1eight])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1eight:pos_half])\n",
    "        voices.append(voice_perm)\n",
    "\n",
    "        voice_perm = voice[pos_1eight:pos_half]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_3quart:len(voice)])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_1eight])\n",
    "        voices.append(voice_perm)\n",
    "\n",
    "        voice_perm = voice[pos_3quart:len(voice)]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_1eight])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_half:pos_3quart])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1eight:pos_half])\n",
    "        voices.append(voice_perm)\n",
    "\n",
    "        voice_perm = voice[pos_half:pos_3quart]\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1eight:pos_half])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_1quart:pos_1eight])\n",
    "        voice_perm = np.append(voice_perm, voice[pos_3quart:len(voice)])\n",
    "        voice_perm = np.append(voice_perm, voice[0:pos_1quart])\n",
    "        voices.append(voice_perm)\n",
    "    \n",
    "    return np.array(voices)\n",
    "    \n",
    "    # split voice into smaller batches/chunks\n",
    "    # np.array_split takes as args the data input and the number of batches!!! not the number of elems in a batch\n",
    "#     if is_valid == False:\n",
    "#         voice_batches = np.array_split(np.array(voice),5)\n",
    "#     else:\n",
    "#         voice_batches = np.array_split(np.array(voice),6)\n",
    "        \n",
    "#     np.random.shuffle(voice_batches)\n",
    "\n",
    "#     voice_perm = []\n",
    "#     for v in voice_batches:\n",
    "#         voice_perm.extend(v)\n",
    "    \n",
    "#     return np.array(voice_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                 samples_per_frame, mix_5_seconds):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix = voice1 + voice2\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "    mix = np.array(mix)\n",
    "\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_set_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interchanged_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                 samples_per_frame, mix_5_seconds, nb_of_permutations, is_validation):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "    \n",
    "#     mix = voice1 + voice2\n",
    "#     inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "#     inputs_list.extend(inputs)\n",
    "#     targets_list.extend(targets)\n",
    "        \n",
    "#     for i in range(nb_of_permutations):\n",
    "\n",
    "#         voice1_perm = get_voice_interchanged(voice1, is_validation)\n",
    "#         voice2_perm = get_voice_interchanged(voice2, is_validation)\n",
    "\n",
    "#         mix = voice1_perm + voice2_perm\n",
    "\n",
    "#         inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "#         inputs_list.extend(inputs)\n",
    "#         targets_list.extend(targets)\n",
    "\n",
    "    voices1 = get_voice_interchanged(voice1, False)\n",
    "    voices2 = get_voice_interchanged(voice2, False)\n",
    "        \n",
    "    for i in range(len(voices1)):\n",
    "            mix = voices1[i] + voices2[i]\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voices1[i], voices2[i], samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_interchanged_set_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_with_noise_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                            samples_per_frame, mix_5_seconds, noise_filename):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    noise, sr = librosa.load(noise_filename, sr=16000) \n",
    "    noise = np.append(noise, noise)\n",
    "    noise = noise / 5\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "\n",
    "    # load the mixed audio \n",
    "    mix = voice1 + voice2 + noise\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "    noise = np.array(noise)\n",
    "    mix = np.array(mix)\n",
    "\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"create_set_with_noise_from_voices dims: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices_80_10_10(voice1_file_name, voice2_file_name, \n",
    "                                          samples_per_frame, mix_5_seconds):\n",
    "            \n",
    "    voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_file_name, sr=16000) \n",
    "    voice2 = np.append(voice2, voice2)\n",
    "\n",
    "    # pad smaller array with zeros if it's the case or delete last entries\n",
    "    if mix_5_seconds == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "    train_len = (int)(80/100 * len(voice1))\n",
    "    diff = (int)( (len(voice1) - train_len) / 2)\n",
    "    \n",
    "    # --------------------------------------split voices into train/valid/test sets\n",
    "    voice1_train = voice1[:train_len]\n",
    "    voice2_train = voice2[:train_len]\n",
    "    print(len(voice1_train))\n",
    "    \n",
    "    voice1_valid = voice1[train_len:(train_len + diff)]\n",
    "    voice2_valid = voice2[train_len:(train_len + diff)]\n",
    "    print(len(voice1_valid))\n",
    "    \n",
    "    voice1_test = voice1[(train_len + diff):len(voice1)]\n",
    "    voice2_test = voice2[(train_len + diff):len(voice2)]\n",
    "    print(len(voice1_test))\n",
    "\n",
    "    voice1 = np.array(voice1)\n",
    "    voice2 = np.array(voice2)\n",
    "\n",
    "    # -------------------------------------compute train set [with permutations or without]\n",
    "    inputs_list, targets_list = [], []\n",
    "        \n",
    "#     mix = voice1_train + voice2_train\n",
    "#     mix = np.array(mix)\n",
    "\n",
    "#     inputs, targets = get_train_set_for_mix(mix, voice1_train, voice2_train, samples_per_frame)\n",
    "#     inputs_list.extend(inputs)\n",
    "#     targets_list.extend(targets)\n",
    "    \n",
    "            \n",
    "    voices1 = get_voice_interchanged(voice1_train, False)\n",
    "    voices2 = get_voice_interchanged(voice2_train, False)\n",
    "        \n",
    "    for i in range(len(voices1)):\n",
    "            mix = voices1[i] + voices2[i]\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voices1[i], voices2[i], samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "\n",
    "#   for i in range(nb_of_permutations):\n",
    "\n",
    "#       voice1_perm = get_voice_interchanged(voice1_train)\n",
    "#       voice2_perm = get_voice_interchanged(voice2_train)\n",
    "\n",
    "#       mix = voice1_perm + voice2_perm\n",
    "#       mix = np.array(mix)\n",
    "\n",
    "#       inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "#       inputs_list.extend(inputs)\n",
    "#       targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    train_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    # ------------------------------------------------------compute valid set\n",
    "    inputs_list, targets_list = [], []\n",
    "    \n",
    "    mix = voice1_valid + voice2_valid\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1_valid, voice2_valid, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    valid_set = dict(zip(inputs_list, targets_list))\n",
    "\n",
    "    # ---------------------------------------------------------compute test set\n",
    "    inputs_list, targets_list = [], []\n",
    "    \n",
    "    mix = voice1_test + voice2_test\n",
    "    inputs, targets = get_train_set_for_mix(mix, voice1_test, voice2_test, samples_per_frame)\n",
    "    inputs_list.extend(inputs)\n",
    "    targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    test_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    print(\"create_set_from_voices_80_10_10 sets dim:\", len(train_set), len(valid_set), len(test_set))\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000\n",
      "8000\n",
      "8000\n",
      "create_set_from_voices_80_10_10 sets dim: 1990 48 48\n",
      "create_set_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "create_interchanged_set_from_voices dims:  torch.Size([2490, 4, 1, 513, 21]) torch.Size([2490, 513, 21])\n",
      "create_interchanged_set_from_voices dims:  torch.Size([2490, 4, 1, 513, 21]) torch.Size([2490, 513, 21])\n",
      "create_set_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "create_set_with_noise_from_voices dims:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n"
     ]
    }
   ],
   "source": [
    "noise_filename = 'recordings/noises/piano5sec.wav'\n",
    "noise2_filename = 'recordings/noises/engine.wav'\n",
    "noise3_filename = 'recordings/noises/beeps.wav'\n",
    "\n",
    "voice1_file_name = 'recordings/voice1/arctic_a0007.wav'\n",
    "voice2_file_name = 'recordings/voice2/arctic_a0032.wav'\n",
    "\n",
    "voice1_file_names_list2 = ['recordings/voice1/arctic_a0407.wav']\n",
    "voice2_file_names_list2 = ['recordings/voice2/arctic_a0032.wav']\n",
    "\n",
    "noises_list = ['recordings/noises/engine.wav', 'recordings/noises/applauses.wav', 'recordings/noises/beeps.wav']\n",
    "\n",
    "\n",
    "train_set_80, valid_set_10, test_set_10 = create_set_from_voices_80_10_10(voice1_file_name, voice2_file_name,\n",
    "                                                                        samples_per_frame=samples_per_frame_10ms,\n",
    "                                                                        mix_5_seconds=True)\n",
    "# un singur mix, intreg, simplu\n",
    "train_set = create_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                         samples_per_frame = samples_per_frame_10ms,\n",
    "                                        mix_5_seconds= True)\n",
    "\n",
    "# un singur mix, intreg, 3 inregistrari, din care 2 permutate\n",
    "train_set_interchanged = create_interchanged_set_from_voices(voice1_file_name, voice2_file_name, \n",
    "                                         samples_per_frame = samples_per_frame_10ms,\n",
    "                                        mix_5_seconds= True, nb_of_permutations = 3, is_validation=False)\n",
    "\n",
    "# un singur mix, intreg, permutat in alt mod fata de permutarile din train\n",
    "# are si un noise de applause in functie, doar trebuie comentat / decomentat cand e adaugat in mix\n",
    "valid_set = create_interchanged_set_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame = samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, nb_of_permutations = 1, is_validation=True)\n",
    "\n",
    "# un singur mix, intreg, contine doar cele doua voci pentru care s-a facut trainul\n",
    "test_set = create_set_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True)\n",
    "\n",
    "# un singur mix, intreg, cele doua voci + zgomot de pian\n",
    "test_set_with_noise = create_set_with_noise_from_voices(voice1_file_name, voice2_file_name,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, \n",
    "                                                    noise_filename=noise_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(nr_epochs, train_set, valid_set, test_set, model_name, optimizer, network):\n",
    "\n",
    "    # plot train/valid loss contains losses on each epoch, so we can see after each epoch what happens with the error\n",
    "    plot_train_losses = []\n",
    "    plot_valid_losses = []\n",
    "    plot_train_accuracy = []\n",
    "    plot_valid_accuracy = []\n",
    "\n",
    "\n",
    "    epoch = 1\n",
    "    while epoch <= nr_epochs:\n",
    "        \n",
    "        correct_train = 0\n",
    "        correct_test = 0\n",
    "        train_losses, valid_losses = [], []\n",
    "        loss = 0\n",
    "\n",
    "        # training part \n",
    "        network.train()\n",
    "        for index, (input, target) in enumerate(train_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network(input)\n",
    "\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1])  \n",
    "\n",
    "\n",
    "            # 3. backward propagation\n",
    "            loss.backward() \n",
    "\n",
    "\n",
    "            # 4. weight optimization\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # 5. save the loss for this PF\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            \n",
    "            # 6. check how many items where predicted correctly\n",
    "            correct_train += 1 if loss.item() <= marja_eroare else 0 \n",
    "            \n",
    "\n",
    "        # add the mean loss for this training epoch for ploting\n",
    "        train_mean_loss_for_epoch = np.mean(train_losses)\n",
    "        plot_train_losses.append(train_mean_loss_for_epoch)\n",
    "        \n",
    "        current_accuracy = (int)(100. * correct_train / len(train_set))\n",
    "        plot_train_accuracy.append(current_accuracy)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "            print(\"Train set -> \", \"loss: \", loss.item(), \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                  str(correct_train) + \"/\" + str(len(train_set)) + \"]\")\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # evaluation part \n",
    "#         network.eval()\n",
    "        if epoch % 1 == 0:\n",
    "#             \n",
    "            with torch.no_grad():\n",
    "                for index, (input, target) in enumerate(valid_set.items()):\n",
    "\n",
    "                    # if cuda is available, send (input, target) to gpu\n",
    "                    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "                    # 1. forward propagation\n",
    "                    output = network.forward(input)\n",
    "\n",
    "                    # 2. loss calculation\n",
    "                    loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "                    \n",
    "                    # 3. save loss for current PF\n",
    "                    valid_losses.append(loss)\n",
    "\n",
    "                    # 4. check how many items where predicted correctly\n",
    "                    correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "                 # add the mean loss for this training epoch for ploting\n",
    "                valid_mean_loss_for_epoch = np.mean(valid_losses)\n",
    "                plot_valid_losses.append(valid_mean_loss_for_epoch)\n",
    "                \n",
    "                current_accuracy = (int)(100. * correct_test / len(valid_set))\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == 1 :\n",
    "                    print(\"Valid set -> \", \"loss: \", loss, \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(valid_set)) + \"]\")\n",
    "                \n",
    "                if len(plot_valid_accuracy) >= 1:\n",
    "                    if current_accuracy > max(plot_valid_accuracy) or current_accuracy > 90:\n",
    "                        print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "#                         print(current_accuracy, max(plot_valid_accuracy))\n",
    "#                         torch.save(network, str(epoch) + \"valid\"+ str(current_accuracy) + model_name)\n",
    "                        torch.save(network, \"valid-\"+ model_name)\n",
    "#                         network_test = torch.load(str(epoch) + \"valid\"+ str(current_accuracy) + model_name)\n",
    "                        network_test = torch.load(\"valid-\"+ model_name)\n",
    "                        eval(network=network_test, test_set=test_set)\n",
    "                \n",
    "                plot_valid_accuracy.append(current_accuracy)\n",
    "                \n",
    "                if current_accuracy > 95:\n",
    "                    break\n",
    "                    \n",
    "        epoch += 1\n",
    "\n",
    "    torch.save(network, model_name)\n",
    "    \n",
    "    plt.plot(plot_train_losses, label='Training loss')\n",
    "    plt.plot(plot_valid_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(plot_train_accuracy, label='Training accuracy')\n",
    "    plt.plot(plot_valid_accuracy, label='Validation accuracy')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONSTRUIRE SUNET PE FRAME-URI, FOLOSIND TARGETURILE GENERATE PT SETUL DE ANTRENARE\n",
    "def split_audios_epoch(name, mask, mix, samples_per_frame):\n",
    "    \n",
    "    frame_pos = (int)(nb_of_frames_in_AF/2)\n",
    "\n",
    "    mask_stack = torch.stack(mask)\n",
    "    cpu_mask = mask_stack.cpu()\n",
    "    n_mask = cpu_mask.detach().numpy()\n",
    "\n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "\n",
    "\n",
    "    for i in range (0, len(mix_frames)):\n",
    "        stft_mix = librosa.stft(librosa.to_mono(mix_frames[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        # reteaua nu a invatat mastile pentru primele frame_pos bucati [PF] din mix\n",
    "        # deci las matricea STFT asa cum e in mix\n",
    "        if i < frame_pos :\n",
    "            y_frame_1_stft_with_mask = stft_mix\n",
    "            y_frame_2_stft_with_mask = stft_mix\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "            \n",
    "        else:\n",
    "            # n_mask[i-7] pentru ca reteaua invata pt AF-uri facute pe cate 8 PF-uri -> 15 items pt AF\n",
    "            # abia de cand ajunge la primul AF care s a putut compune, folosesc masca invata de retea\n",
    "            \n",
    "            y_frame_1_stft_with_mask = np.multiply(n_mask[i-frame_pos], stft_mix)\n",
    "            y_frame_2_stft_with_mask = np.multiply((1 -  n_mask[i-frame_pos]), stft_mix)\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "\n",
    "\n",
    "    librosa.output.write_wav(\"recordings/voice1-\"+ str(name) + \".wav\", sound1, sr = 16000)\n",
    "    librosa.output.write_wav(\"recordings/voice2-\"+ str(name) + \".wav\", sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, test_set):\n",
    "\n",
    "#     network.eval()\n",
    "                \n",
    "    test_loss, test_mask, test_accuracy = [], [], []\n",
    "    correct_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (input, target) in enumerate(test_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network.forward(input)\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "\n",
    "            # 3. save the mask for the current PF, meaning the last entry in the output\n",
    "            current_mask = output[len(output)-1]\n",
    "            test_mask.append(current_mask)\n",
    "\n",
    "            test_loss.append(loss)\n",
    "\n",
    "            # 4. check how many items where predicted correctly\n",
    "            correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "\n",
    "        current_accuracy = 100. * correct_test / len(test_set)\n",
    "        print(\"Test set -> \", \"test loss: \", np.mean(test_loss), \"accuracy: \", (int)(current_accuracy), \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(test_set)) + \"]\")\n",
    "\n",
    "        return test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdam(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "\n",
    "    print(\"__________________________________________ADAM FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    network = Network()\n",
    "    \n",
    "    print(\"network sent to CUDA\")\n",
    "    network.cuda()\n",
    "    \n",
    "    # set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(network.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set = test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=network)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdamConv(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "    \n",
    "    print(\"__________________________________________ADAM CONV + FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    networkConv = NetworkConv()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"networkConv sent to CUDA\")\n",
    "        networkConv.cuda()\n",
    "        \n",
    "    # set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(networkConv.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set=test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=networkConv)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices(voice1_filename, voice2_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        \n",
    "    mix = voice1 + voice2\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-withOUT-noise.wav\", mix, 16000)\n",
    "    \n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices_with_noise(voice1_filename, voice2_filename, noise_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    noise, sr = librosa.load(noise_filename, sr=16000)\n",
    "    noise = np.append(noise, noise)\n",
    "    noise = noise / 5\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "    \n",
    "    mix = voice1 + voice2 + noise\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-with-noise.wav\", mix, 16000)\n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ADAM FC_________________________________\n",
      "network sent to CUDA\n",
      "--------------------------------------Epoch 1 ------------------------------\n",
      "Train set ->  loss:  0.16330279409885406 accuracy:  0 % [3/2490]\n",
      "Valid set ->  loss:  0.15334303677082062 accuracy:  0 % [0/2490]\n",
      "--------------------------------------Epoch 7 ------------------------------\n",
      "Test set ->  test loss:  0.0864519329814532 accuracy:  0 % [2/498]\n",
      "--------------------------------------Epoch 9 ------------------------------\n",
      "Test set ->  test loss:  0.08291525340192095 accuracy:  0 % [4/498]\n",
      "--------------------------------------Epoch 10 ------------------------------\n",
      "Train set ->  loss:  0.050030458718538284 accuracy:  2 % [60/2490]\n",
      "Valid set ->  loss:  0.04394029453396797 accuracy:  1 % [45/2490]\n",
      "--------------------------------------Epoch 12 ------------------------------\n",
      "Test set ->  test loss:  0.07450028959555124 accuracy:  0 % [4/498]\n",
      "--------------------------------------Epoch 18 ------------------------------\n",
      "Test set ->  test loss:  0.07117389448769727 accuracy:  1 % [5/498]\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "Train set ->  loss:  0.02109679952263832 accuracy:  4 % [122/2490]\n",
      "Valid set ->  loss:  0.020366504788398743 accuracy:  5 % [131/2490]\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "Test set ->  test loss:  0.07147102281694341 accuracy:  1 % [6/498]\n",
      "--------------------------------------Epoch 21 ------------------------------\n",
      "Test set ->  test loss:  0.07013110991335478 accuracy:  1 % [6/498]\n",
      "--------------------------------------Epoch 24 ------------------------------\n",
      "Test set ->  test loss:  0.06755556146488956 accuracy:  2 % [10/498]\n",
      "--------------------------------------Epoch 26 ------------------------------\n",
      "Test set ->  test loss:  0.06965437799834283 accuracy:  1 % [9/498]\n",
      "--------------------------------------Epoch 29 ------------------------------\n",
      "Test set ->  test loss:  0.0687057253461421 accuracy:  2 % [11/498]\n",
      "--------------------------------------Epoch 30 ------------------------------\n",
      "Train set ->  loss:  0.014367861673235893 accuracy:  10 % [268/2490]\n",
      "Valid set ->  loss:  0.012790488079190254 accuracy:  11 % [292/2490]\n",
      "--------------------------------------Epoch 31 ------------------------------\n",
      "Test set ->  test loss:  0.06752528766792897 accuracy:  2 % [14/498]\n",
      "--------------------------------------Epoch 34 ------------------------------\n",
      "Test set ->  test loss:  0.06669750047008877 accuracy:  3 % [15/498]\n",
      "--------------------------------------Epoch 37 ------------------------------\n",
      "Test set ->  test loss:  0.06771077736361274 accuracy:  4 % [20/498]\n",
      "--------------------------------------Epoch 38 ------------------------------\n",
      "Test set ->  test loss:  0.06670737757542017 accuracy:  3 % [17/498]\n",
      "--------------------------------------Epoch 40 ------------------------------\n",
      "Train set ->  loss:  0.01239367201924324 accuracy:  19 % [476/2490]\n",
      "Valid set ->  loss:  0.01121613197028637 accuracy:  18 % [453/2490]\n",
      "--------------------------------------Epoch 40 ------------------------------\n",
      "Test set ->  test loss:  0.06811120070822829 accuracy:  3 % [18/498]\n",
      "--------------------------------------Epoch 41 ------------------------------\n",
      "Test set ->  test loss:  0.06779905261348439 accuracy:  3 % [18/498]\n",
      "--------------------------------------Epoch 43 ------------------------------\n",
      "Test set ->  test loss:  0.06748381038392748 accuracy:  4 % [22/498]\n",
      "--------------------------------------Epoch 45 ------------------------------\n",
      "Test set ->  test loss:  0.06673446021170867 accuracy:  3 % [18/498]\n",
      "--------------------------------------Epoch 47 ------------------------------\n",
      "Test set ->  test loss:  0.06755468991106324 accuracy:  4 % [22/498]\n",
      "--------------------------------------Epoch 49 ------------------------------\n",
      "Test set ->  test loss:  0.06777295905883503 accuracy:  3 % [19/498]\n",
      "--------------------------------------Epoch 50 ------------------------------\n",
      "Train set ->  loss:  0.0109581109136343 accuracy:  26 % [670/2490]\n",
      "Valid set ->  loss:  0.009738525375723839 accuracy:  25 % [634/2490]\n",
      "--------------------------------------Epoch 52 ------------------------------\n",
      "Test set ->  test loss:  0.07052223686171867 accuracy:  4 % [23/498]\n",
      "--------------------------------------Epoch 55 ------------------------------\n",
      "Test set ->  test loss:  0.06882780166829087 accuracy:  4 % [21/498]\n",
      "--------------------------------------Epoch 57 ------------------------------\n",
      "Test set ->  test loss:  0.06873534817760997 accuracy:  4 % [22/498]\n",
      "--------------------------------------Epoch 59 ------------------------------\n",
      "Test set ->  test loss:  0.06995460269392943 accuracy:  4 % [21/498]\n",
      "--------------------------------------Epoch 60 ------------------------------\n",
      "Train set ->  loss:  0.008565044030547142 accuracy:  34 % [871/2490]\n",
      "Valid set ->  loss:  0.007066630758345127 accuracy:  33 % [833/2490]\n",
      "--------------------------------------Epoch 60 ------------------------------\n",
      "Test set ->  test loss:  0.07012944912746451 accuracy:  4 % [24/498]\n",
      "--------------------------------------Epoch 61 ------------------------------\n",
      "Test set ->  test loss:  0.07013166529392023 accuracy:  4 % [21/498]\n",
      "--------------------------------------Epoch 62 ------------------------------\n",
      "Test set ->  test loss:  0.06964747777655646 accuracy:  4 % [22/498]\n",
      "--------------------------------------Epoch 63 ------------------------------\n",
      "Test set ->  test loss:  0.07023070367094295 accuracy:  5 % [25/498]\n",
      "--------------------------------------Epoch 65 ------------------------------\n",
      "Test set ->  test loss:  0.0710854881618875 accuracy:  6 % [34/498]\n",
      "--------------------------------------Epoch 67 ------------------------------\n",
      "Test set ->  test loss:  0.07051816431012559 accuracy:  6 % [33/498]\n",
      "--------------------------------------Epoch 70 ------------------------------\n",
      "Train set ->  loss:  0.010582946240901947 accuracy:  41 % [1039/2490]\n",
      "Valid set ->  loss:  0.008870430290699005 accuracy:  41 % [1044/2490]\n",
      "--------------------------------------Epoch 71 ------------------------------\n",
      "Test set ->  test loss:  0.07063879822189154 accuracy:  5 % [29/498]\n",
      "--------------------------------------Epoch 72 ------------------------------\n",
      "Test set ->  test loss:  0.07065541823894855 accuracy:  6 % [30/498]\n",
      "--------------------------------------Epoch 73 ------------------------------\n",
      "Test set ->  test loss:  0.07106508263788863 accuracy:  7 % [35/498]\n",
      "--------------------------------------Epoch 75 ------------------------------\n",
      "Test set ->  test loss:  0.07101888651305054 accuracy:  6 % [34/498]\n",
      "--------------------------------------Epoch 77 ------------------------------\n",
      "Test set ->  test loss:  0.07087492297102424 accuracy:  6 % [30/498]\n",
      "--------------------------------------Epoch 79 ------------------------------\n",
      "Test set ->  test loss:  0.0715482563795391 accuracy:  6 % [30/498]\n",
      "--------------------------------------Epoch 80 ------------------------------\n",
      "Train set ->  loss:  0.00577923096716404 accuracy:  51 % [1277/2490]\n",
      "Valid set ->  loss:  0.005147701594978571 accuracy:  48 % [1215/2490]\n",
      "--------------------------------------Epoch 81 ------------------------------\n",
      "Test set ->  test loss:  0.07134041159570846 accuracy:  7 % [37/498]\n",
      "--------------------------------------Epoch 84 ------------------------------\n",
      "Test set ->  test loss:  0.0714721102279192 accuracy:  8 % [42/498]\n",
      "--------------------------------------Epoch 85 ------------------------------\n",
      "Test set ->  test loss:  0.07183645296389289 accuracy:  7 % [37/498]\n",
      "--------------------------------------Epoch 89 ------------------------------\n",
      "Test set ->  test loss:  0.07169418666188242 accuracy:  6 % [32/498]\n",
      "--------------------------------------Epoch 90 ------------------------------\n",
      "Train set ->  loss:  0.005075511988252401 accuracy:  58 % [1454/2490]\n",
      "Valid set ->  loss:  0.004766668658703566 accuracy:  55 % [1374/2490]\n",
      "--------------------------------------Epoch 90 ------------------------------\n",
      "Test set ->  test loss:  0.07213005390117341 accuracy:  8 % [40/498]\n",
      "--------------------------------------Epoch 92 ------------------------------\n",
      "Test set ->  test loss:  0.07289206326974698 accuracy:  8 % [41/498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Epoch 97 ------------------------------\n",
      "Test set ->  test loss:  0.0718998100798405 accuracy:  7 % [38/498]\n",
      "--------------------------------------Epoch 99 ------------------------------\n",
      "Test set ->  test loss:  0.07221033441344178 accuracy:  7 % [37/498]\n",
      "--------------------------------------Epoch 100 ------------------------------\n",
      "Train set ->  loss:  0.00708015589043498 accuracy:  62 % [1556/2490]\n",
      "Valid set ->  loss:  0.005575141403824091 accuracy:  60 % [1507/2490]\n",
      "--------------------------------------Epoch 101 ------------------------------\n",
      "Test set ->  test loss:  0.07302607536076541 accuracy:  7 % [36/498]\n",
      "--------------------------------------Epoch 104 ------------------------------\n",
      "Test set ->  test loss:  0.07398025093840466 accuracy:  7 % [36/498]\n",
      "--------------------------------------Epoch 108 ------------------------------\n",
      "Test set ->  test loss:  0.07315626161862128 accuracy:  7 % [39/498]\n",
      "--------------------------------------Epoch 110 ------------------------------\n",
      "Train set ->  loss:  0.005594662856310606 accuracy:  66 % [1655/2490]\n",
      "Valid set ->  loss:  0.0048265038058161736 accuracy:  67 % [1670/2490]\n",
      "--------------------------------------Epoch 110 ------------------------------\n",
      "Test set ->  test loss:  0.07300370876550166 accuracy:  8 % [42/498]\n",
      "--------------------------------------Epoch 120 ------------------------------\n",
      "Train set ->  loss:  0.005380118731409311 accuracy:  70 % [1750/2490]\n",
      "Valid set ->  loss:  0.004442338366061449 accuracy:  68 % [1716/2490]\n",
      "--------------------------------------Epoch 120 ------------------------------\n",
      "Test set ->  test loss:  0.07448795961658376 accuracy:  7 % [36/498]\n",
      "--------------------------------------Epoch 125 ------------------------------\n",
      "Test set ->  test loss:  0.07479242710387297 accuracy:  7 % [38/498]\n",
      "--------------------------------------Epoch 126 ------------------------------\n",
      "Test set ->  test loss:  0.0742776702054361 accuracy:  8 % [41/498]\n",
      "--------------------------------------Epoch 130 ------------------------------\n",
      "Train set ->  loss:  0.004217843525111675 accuracy:  73 % [1822/2490]\n",
      "Valid set ->  loss:  0.003979040309786797 accuracy:  70 % [1760/2490]\n",
      "--------------------------------------Epoch 133 ------------------------------\n",
      "Test set ->  test loss:  0.0757098867953942 accuracy:  8 % [43/498]\n",
      "--------------------------------------Epoch 140 ------------------------------\n",
      "Train set ->  loss:  0.004519463982433081 accuracy:  73 % [1825/2490]\n",
      "Valid set ->  loss:  0.004289683420211077 accuracy:  73 % [1839/2490]\n",
      "--------------------------------------Epoch 145 ------------------------------\n",
      "Test set ->  test loss:  0.07767297326630153 accuracy:  8 % [41/498]\n",
      "--------------------------------------Epoch 149 ------------------------------\n",
      "Test set ->  test loss:  0.0772040464511388 accuracy:  8 % [41/498]\n",
      "--------------------------------------Epoch 150 ------------------------------\n",
      "Train set ->  loss:  0.004590264987200499 accuracy:  75 % [1881/2490]\n",
      "Valid set ->  loss:  0.004346839617937803 accuracy:  76 % [1903/2490]\n",
      "--------------------------------------Epoch 150 ------------------------------\n",
      "Test set ->  test loss:  0.0771789386378504 accuracy:  7 % [35/498]\n",
      "--------------------------------------Epoch 160 ------------------------------\n",
      "Train set ->  loss:  0.0036366553977131844 accuracy:  79 % [1973/2490]\n",
      "Valid set ->  loss:  0.003447894938290119 accuracy:  77 % [1932/2490]\n",
      "--------------------------------------Epoch 160 ------------------------------\n",
      "Test set ->  test loss:  0.07746718533409117 accuracy:  8 % [43/498]\n",
      "--------------------------------------Epoch 166 ------------------------------\n",
      "Test set ->  test loss:  0.07763188799546777 accuracy:  8 % [44/498]\n",
      "--------------------------------------Epoch 170 ------------------------------\n",
      "Train set ->  loss:  0.004646369256079197 accuracy:  80 % [1995/2490]\n",
      "Valid set ->  loss:  0.0042951107025146484 accuracy:  75 % [1873/2490]\n",
      "--------------------------------------Epoch 171 ------------------------------\n",
      "Test set ->  test loss:  0.07781878990671938 accuracy:  8 % [44/498]\n",
      "--------------------------------------Epoch 178 ------------------------------\n",
      "Test set ->  test loss:  0.07849243376053398 accuracy:  9 % [45/498]\n",
      "--------------------------------------Epoch 180 ------------------------------\n",
      "Train set ->  loss:  0.004126394633203745 accuracy:  80 % [2016/2490]\n",
      "Valid set ->  loss:  0.0036500587593764067 accuracy:  80 % [2003/2490]\n",
      "--------------------------------------Epoch 189 ------------------------------\n",
      "Test set ->  test loss:  0.07867438562240556 accuracy:  8 % [44/498]\n",
      "--------------------------------------Epoch 190 ------------------------------\n",
      "Train set ->  loss:  0.004252147860825062 accuracy:  83 % [2073/2490]\n",
      "Valid set ->  loss:  0.0036519074346870184 accuracy:  80 % [2009/2490]\n",
      "--------------------------------------Epoch 192 ------------------------------\n",
      "Test set ->  test loss:  0.07932987169270969 accuracy:  8 % [42/498]\n",
      "--------------------------------------Epoch 196 ------------------------------\n",
      "Test set ->  test loss:  0.07956977575399303 accuracy:  6 % [34/498]\n",
      "--------------------------------------Epoch 200 ------------------------------\n",
      "Train set ->  loss:  0.00399697944521904 accuracy:  84 % [2113/2490]\n",
      "Valid set ->  loss:  0.003628408070653677 accuracy:  81 % [2034/2490]\n",
      "--------------------------------------Epoch 205 ------------------------------\n",
      "Test set ->  test loss:  0.07825043731734688 accuracy:  8 % [43/498]\n",
      "--------------------------------------Epoch 210 ------------------------------\n",
      "Train set ->  loss:  0.0037537335883826017 accuracy:  85 % [2127/2490]\n",
      "Valid set ->  loss:  0.0034235618077218533 accuracy:  83 % [2070/2490]\n",
      "--------------------------------------Epoch 214 ------------------------------\n",
      "Test set ->  test loss:  0.07995219846830205 accuracy:  7 % [39/498]\n",
      "--------------------------------------Epoch 220 ------------------------------\n",
      "Train set ->  loss:  0.0035997291561216116 accuracy:  86 % [2147/2490]\n",
      "Valid set ->  loss:  0.0033543696627020836 accuracy:  83 % [2075/2490]\n",
      "--------------------------------------Epoch 228 ------------------------------\n",
      "Test set ->  test loss:  0.08048411525120158 accuracy:  8 % [42/498]\n",
      "--------------------------------------Epoch 230 ------------------------------\n",
      "Train set ->  loss:  0.003715578466653824 accuracy:  86 % [2142/2490]\n",
      "Valid set ->  loss:  0.003242960199713707 accuracy:  85 % [2137/2490]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5e414535efa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set_interchanged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_with_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FC-mix-intreg-permutat-v1(7)-v2(32)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# test first what it learned from train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-0af5a93fff1d>\u001b[0m in \u001b[0;36mrunAdam\u001b[1;34m(nr_epochs, train_set, valid_set, test_set, mixnb)\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 network=network)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-905f96669e2b>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(nr_epochs, train_set, valid_set, test_set, model_name, optimizer, network)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;31m# 5. save the loss for this PF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import winsound\n",
    "import os\n",
    "\n",
    "voice1 = 'recordings/voice1/arctic_a0007.wav'\n",
    "voice2 = 'recordings/voice2/arctic_a0032.wav'\n",
    "    \n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(300, train_set, valid_set, test_set_with_noise, \"FC-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set, valid_set, test_set_with_noise, \"CONV-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_80, valid_set_10, test_set_10, \"FC-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set_80, valid_set_10, test_set_10, \"CONV-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_name = runAdam(800, train_set_interchanged, valid_set, test_set_with_noise, \"FC-mix-intreg-permutat-v1(7)-v2(32)\")\n",
    "\n",
    "# test first what it learned from train\n",
    "mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set)\n",
    "split_audios_epoch(\"FC-mix-intreg-permutat-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# test with noise\n",
    "mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "split_audios_epoch(\"FC-mix-intreg-permutat-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "# mai trebuie convolutionala aici\n",
    "# ------------------------------------------------------------------------------------\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_interchanged_and_noisy, valid_set, test_set_with_noise, \"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-intreg-permutat-si2zgomote-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(200, train_set_80, valid_set_10, test_set_10, \"FC-mix-80-10-10-permutat-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-permutat-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-80-10-10-permutat-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
