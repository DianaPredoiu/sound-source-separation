{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "n_fft = 1024\n",
    "hop_length = 8\n",
    "sr = 16000\n",
    "\n",
    "# cate bucati PF iau in considerare pentru AF -> cu overlapping => 15 frame-uri \n",
    "# ultimul frame din AF fiind PF-ul curent\n",
    "nb_of_frames_in_AF = 4\n",
    "# exp_w_avg_beta = 0.98\n",
    "marja_eroare = 1e-2\n",
    "\n",
    "# frame_length_ms = 5\n",
    "# total_length_ms = 5000.0\n",
    "# nb_of_samples = 80000\n",
    "samples_per_frame_10ms = 160 #(int)(160000 * 10 / 10000.0)\n",
    "samples_per_frame_5ms = 80 #(int)(80000 * 5 / 5000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliz(mix):\n",
    "    mu = np.mean(mix, axis=0)\n",
    "    var = np.var(mix, axis=0)\n",
    "\n",
    "    mix_norm = (mix - mu) / np.sqrt(var + 1e-8)\n",
    "    \n",
    "    return mix_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mask(stft_1, stft_2):\n",
    "    # small epsilon to avoid dividing by zero\n",
    "    eps = np.finfo(np.float).eps\n",
    "\n",
    "    # compute model as the sum of spectrograms\n",
    "    mix = eps + np.abs(stft_1) + np.abs(stft_2)    \n",
    "    mask = np.divide(np.abs(stft_1), mix)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_STFT_AF_frames(AF_array, PF_size):\n",
    "    frames = []\n",
    "    half = (int)(PF_size/2)\n",
    "    frames_added = 0\n",
    "    \n",
    "    i = AF_array.shape[0]-1\n",
    "    \n",
    "    # use AF as 4 times bigger than PF's size -> PF = 10 ms => AF = 40 ms\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 1. add PF[i]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 2. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 3. add PF[i - 1]\n",
    "    frame = librosa.stft(librosa.to_mono(AF_array[i - 1]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "    \n",
    "    tensor = []\n",
    "    tensor.append(frame)        \n",
    "    frames.append(tensor)\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # 4. add PF[i-1, i] -> overlap\n",
    "    overlap_frame = AF_array[i-1][half:]\n",
    "    overlap_frame = np.concatenate((overlap_frame, AF_array[i][:half]))\n",
    "    \n",
    "    frame = librosa.stft(librosa.to_mono(overlap_frame), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "    frame = np.abs(frame)\n",
    "    frame = normaliz(frame)\n",
    "\n",
    "    tensor = []\n",
    "    tensor.append(frame)\n",
    "    frames.append(tensor)\n",
    "        \n",
    "    \n",
    "    return np.asarray(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_set_for_mix(mix, voice_1, voice_2, samples_per_frame):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_1_frames = np.array([voice_1[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    voice_2_frames = np.array([voice_2[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    \n",
    "    for index in range(mix_frames.shape[0]):\n",
    "        \n",
    "        if index < 2:\n",
    "            continue\n",
    "        \n",
    "        # 1. create train set input for AF with current PF and previous frames\n",
    "        AF_frames = np.array([mix_frames[i] for i in range(index - 2, index)])      \n",
    "        AF_STFT_frames = get_STFT_AF_frames(AF_array=AF_frames, PF_size= samples_per_frame)\n",
    "        inputs.append(AF_STFT_frames)\n",
    "        \n",
    "        # 2. create train set target for that AF, containing the mask for the current PF\n",
    "        stft_voice_1 = librosa.stft(librosa.to_mono(voice_1_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        stft_voice_2 = librosa.stft(librosa.to_mono(voice_2_frames[index]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        mask = compute_mask(stft_voice_1, stft_voice_2)\n",
    "        \n",
    "        targets.append(mask)\n",
    "    \n",
    "    # train set for only one audio\n",
    "    train_set_input = torch.from_numpy(np.array(inputs))\n",
    "    \n",
    "    # target contains the calculated masks for each PF from mix\n",
    "    train_set_target = torch.from_numpy(np.array(targets))\n",
    "    return np.array(inputs), np.array(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(Network, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.fc1 = nn.Linear(1 * height * width, 250)\n",
    "        self.fc1_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 2\n",
    "        self.fc2 = nn.Linear(250, 250)\n",
    "        self.fc2_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 3\n",
    "        self.fc3 = nn.Linear(250, height * width)\n",
    "        self.fc3_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # layer 1\n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        x = x.view(-1, self.height * self.width)        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkConv(nn.Module):\n",
    "    height = 0\n",
    "    width = 0\n",
    "    \n",
    "    # default values for height and width are given for a processing frame of 10 ms\n",
    "    # 5 ms  = [513, 11]\n",
    "    def __init__(self, height = 513, width = 21):\n",
    "        super(NetworkConv, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        # layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, padding=2)\n",
    "        self.conv1_batch = nn.BatchNorm2d(20)\n",
    "        \n",
    "        # layer 2\n",
    "        self.conv2 = nn.Conv2d(20, 20, kernel_size=5, padding=2)\n",
    "        self.conv2_batch = nn.BatchNorm2d(20)\n",
    "    \n",
    "        # layer 3\n",
    "        self.fc1 = nn.Linear(20 * height * width, 250)\n",
    "        self.fc1_batch = nn.BatchNorm1d(250)\n",
    "        \n",
    "        # layer 4\n",
    "        self.fc2 = nn.Linear(250, height * width)\n",
    "        self.fc2_batch = nn.BatchNorm1d(height * width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # firstly, transform the matrix into an array for the FC\n",
    "        \n",
    "        \n",
    "        # layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 3\n",
    "        x = x.view(-1, self.height * self.width * 20) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # layer 4\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_batch(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = x.view(nb_of_frames_in_AF, self.height, self.width) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_10_seconds(voice):\n",
    "    nb_sample_for_10_seconds = 160000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_10_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_10_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_10_seconds:\n",
    "        voice = voice[0:nb_sample_for_10_seconds]\n",
    "    \n",
    "    return voice        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mix_of_5_seconds(voice):\n",
    "    nb_sample_for_5_seconds = 80000\n",
    "    \n",
    "    if len(voice) < nb_sample_for_5_seconds:\n",
    "        voice = np.pad(voice, (0,(nb_sample_for_5_seconds - len(voice) )), 'constant', constant_values=(0))\n",
    "    elif len(voice) > nb_sample_for_5_seconds:\n",
    "        voice = voice[0:nb_sample_for_5_seconds]\n",
    "    \n",
    "    return voice   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices_lists(voice1_file_names_list, voice2_file_names_list, \n",
    "                                 samples_per_frame, mix_5_seconds):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    for voice1_file_name in voice1_file_names_list:\n",
    "        for voice2_file_name in voice2_file_names_list:\n",
    "            \n",
    "            voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "            voice1 = np.append(voice1, voice1)\n",
    "            \n",
    "            voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "            voice2 = np.append(voice2, voice2)\n",
    "\n",
    "            # pad smaller array with zeros if it's the case or delete last entries\n",
    "            if mix_5_seconds == True:\n",
    "                voice1 = make_mix_of_5_seconds(voice1)\n",
    "                voice2 = make_mix_of_5_seconds(voice2)\n",
    "            else:\n",
    "                voice1 = make_mix_of_10_seconds(voice1)\n",
    "                voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "            # load the mixed audio \n",
    "            mix = voice1 + voice2\n",
    "\n",
    "            voice1 = np.array(voice1)\n",
    "            voice2 = np.array(voice2)\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"dims for set: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_valid_set_from_voices_lists(voice1_file_names_list, voice2_file_names_list, \n",
    "                                 samples_per_frame, mix_5_seconds):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    for voice1_file_name in voice1_file_names_list:\n",
    "        for voice2_file_name in voice2_file_names_list:\n",
    "            \n",
    "            voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "            voice1 = np.append(voice1, voice1)\n",
    "            \n",
    "            voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "            voice2 = np.append(voice2, voice2)\n",
    "\n",
    "            # pad smaller array with zeros if it's the case or delete last entries\n",
    "            if mix_5_seconds == True:\n",
    "                voice1 = make_mix_of_5_seconds(voice1)\n",
    "                voice2 = make_mix_of_5_seconds(voice2)\n",
    "            else:\n",
    "                voice1 = make_mix_of_10_seconds(voice1)\n",
    "                voice2 = make_mix_of_10_seconds(voice2)\n",
    "            \n",
    "            pos_half = (int)(len(voice1) / 2)\n",
    "            pos_3quart = (int)(pos_half + (pos_half / 2))\n",
    "            print(pos_half, pos_3quart, len(voice1))\n",
    "            \n",
    "            voice1_perm = voice1[pos_half:pos_3quart]\n",
    "            print(len(voice1))\n",
    "            voice1_perm = np.append(voice1_perm, voice1[0:pos_half])\n",
    "            print(len(voice1))\n",
    "            voice1_perm = np.append(voice1_perm, voice1[pos_3quart:len(voice1)])\n",
    "            print(len(voice1))\n",
    "\n",
    "            voice2_perm = voice2[pos_half:pos_3quart]\n",
    "            voice2_perm = np.append(voice2_perm, voice2[0:pos_half])\n",
    "            voice2_perm = np.append(voice2_perm, voice2[pos_3quart:len(voice2)])\n",
    "\n",
    "            # load the mixed audio \n",
    "            mix = voice1_perm + voice2_perm\n",
    "\n",
    "            voice1 = np.array(voice1_perm)\n",
    "            voice2 = np.array(voice2_perm)\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"dims for valid set: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_with_noise_from_voices_lists(voice1_file_names_list, voice2_file_names_list, \n",
    "                                            samples_per_frame, mix_5_seconds, noise_filename):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    for voice1_file_name in voice1_file_names_list:\n",
    "        for voice2_file_name in voice2_file_names_list:\n",
    "            \n",
    "            voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "            voice1 = np.append(voice1, voice1)\n",
    "            \n",
    "            voice2, sr = librosa.load(voice2_file_name, sr=16000)\n",
    "            voice2 = np.append(voice2, voice2)\n",
    "\n",
    "            noise, sr = librosa.load(noise_filename, sr=16000) \n",
    "            noise = np.append(noise, noise)\n",
    "            noise = noise / 5\n",
    "\n",
    "            # pad smaller array with zeros if it's the case or delete last entries\n",
    "            if mix_5_seconds == True:\n",
    "                voice1 = make_mix_of_5_seconds(voice1)\n",
    "                voice2 = make_mix_of_5_seconds(voice2)\n",
    "                noise = make_mix_of_5_seconds(noise)\n",
    "            else:\n",
    "                voice1 = make_mix_of_10_seconds(voice1)\n",
    "                voice2 = make_mix_of_10_seconds(voice2)\n",
    "                noise = make_mix_of_10_seconds(noise)\n",
    "\n",
    "            # load the mixed audio \n",
    "            mix = voice1 + voice2 + noise\n",
    "\n",
    "            voice1 = np.array(voice1)\n",
    "            voice2 = np.array(voice2)\n",
    "            noise = np.array(noise)\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "    print(\"dims for noise set: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    network_set = dict(zip(inputs_list, targets_list))\n",
    "    \n",
    "    return network_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_from_voices_lists_80_10_10(voice1_file_names_list, voice2_file_names_list, \n",
    "                                          samples_per_frame, mix_5_seconds):\n",
    "    inputs_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    for voice1_file_name in voice1_file_names_list:\n",
    "        for voice2_file_name in voice2_file_names_list:\n",
    "            \n",
    "            voice1, sr = librosa.load(voice1_file_name, sr=16000) \n",
    "            voice1 = np.append(voice1, voice1)\n",
    "            \n",
    "            voice2, sr = librosa.load(voice2_file_name, sr=16000) \n",
    "            voice2 = np.append(voice2, voice2)\n",
    "\n",
    "            # pad smaller array with zeros if it's the case or delete last entries\n",
    "            if mix_5_seconds == True:\n",
    "                voice1 = make_mix_of_5_seconds(voice1)\n",
    "                voice2 = make_mix_of_5_seconds(voice2)\n",
    "            else:\n",
    "                voice1 = make_mix_of_10_seconds(voice1)\n",
    "                voice2 = make_mix_of_10_seconds(voice2)\n",
    "\n",
    "            # load the mixed audio \n",
    "            mix = voice1 + voice2\n",
    "\n",
    "            voice1 = np.array(voice1)\n",
    "            voice2 = np.array(voice2)\n",
    "            mix = np.array(mix)\n",
    "\n",
    "            inputs, targets = get_train_set_for_mix(mix, voice1, voice2, samples_per_frame)\n",
    "            inputs_list.extend(inputs)\n",
    "            targets_list.extend(targets)\n",
    "    \n",
    "    inputs_list = torch.from_numpy(np.array(inputs_list))\n",
    "    targets_list = torch.from_numpy(np.array(targets_list))\n",
    "    \n",
    "#     print(\"dims for 80-10-10 set: \", inputs_list.shape, targets_list.shape)\n",
    "    \n",
    "    train_len = (int)(80/100 * len(inputs_list))\n",
    "    m = (int)( (len(inputs_list) - train_len) / 2)\n",
    "\n",
    "    train_set = dict(zip(inputs_list[:train_len, :, :], targets_list[:train_len, :, :]))\n",
    "    valid_set = dict(zip(inputs_list[train_len:(train_len + m), :, :], targets_list[train_len:(train_len + m), :, :]))\n",
    "    test_set = dict(zip(inputs_list[(train_len + m):len(inputs_list), :, :], targets_list[(train_len + m):len(inputs_list), :, :]))\n",
    "\n",
    "    print(\"80-10-10 sets dim:\", len(train_set), len(valid_set), len(test_set))\n",
    "    return train_set, valid_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80-10-10 sets dim: 398 50 50\n",
      "dims for set:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "40000 60000 80000\n",
      "80000\n",
      "80000\n",
      "80000\n",
      "dims for valid set:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "dims for set:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "dims for noise set:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n",
      "dims for noise set:  torch.Size([498, 4, 1, 513, 21]) torch.Size([498, 513, 21])\n"
     ]
    }
   ],
   "source": [
    "noise_filename = 'recordings/noises/piano5sec.wav'\n",
    "noise2_filename = 'recordings/noises/engine.wav'\n",
    "noise3_filename = 'recordings/noises/beeps.wav'\n",
    "\n",
    "voice1_file_names_list = ['recordings/voice1/arctic_a0007.wav']\n",
    "voice2_file_names_list = ['recordings/voice2/arctic_a0032.wav']\n",
    "\n",
    "voice1_file_names_list2 = ['recordings/voice1/arctic_a0407.wav']\n",
    "voice2_file_names_list2 = ['recordings/voice2/arctic_a0032.wav']\n",
    "\n",
    "\n",
    "train_set_80, valid_set_10, test_set_10 = create_set_from_voices_lists_80_10_10(voice1_file_names_list, \n",
    "                                                                                      voice2_file_names_list,\n",
    "                                                                                     samples_per_frame=samples_per_frame_10ms,\n",
    "                                                                                     mix_5_seconds=True)\n",
    "\n",
    "# train_set_80_2, valid_set_10_2, test_set_10_2 = create_set_from_voices_lists_80_10_10(voice1_file_names_list2, \n",
    "#                                                                                       voice2_file_names_list2,\n",
    "#                                                                                      samples_per_frame=samples_per_frame_10ms,\n",
    "#                                                                                      mix_5_seconds=True)\n",
    "\n",
    "train_set = create_set_from_voices_lists(voice1_file_names_list, voice2_file_names_list, \n",
    "                                         samples_per_frame=samples_per_frame_10ms,\n",
    "                                        mix_5_seconds= True)\n",
    "\n",
    "valid_set = create_valid_set_from_voices_lists(voice1_file_names_list, voice2_file_names_list,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True)\n",
    "\n",
    "test_set = create_set_from_voices_lists(voice1_file_names_list, voice2_file_names_list,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True)\n",
    "\n",
    "test_set_with_noise = create_set_with_noise_from_voices_lists(voice1_file_names_list, voice2_file_names_list,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, \n",
    "                                                    noise_filename=noise_filename)\n",
    "\n",
    "test_set_with_noise2 = create_set_with_noise_from_voices_lists(voice1_file_names_list, voice2_file_names_list,\n",
    "                                                    samples_per_frame=samples_per_frame_10ms,\n",
    "                                                    mix_5_seconds= True, \n",
    "                                                    noise_filename=noise2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_network(nr_epochs, train_set, valid_set, test_set, model_name, optimizer, network):\n",
    "\n",
    "    # plot train/valid loss contains losses on each epoch, so we can see after each epoch what happens with the error\n",
    "    plot_train_losses = []\n",
    "    plot_valid_losses = []\n",
    "    plot_train_accuracy = []\n",
    "    plot_valid_accuracy = []\n",
    "\n",
    "\n",
    "    epoch = 1\n",
    "    while epoch <= nr_epochs:\n",
    "        \n",
    "        correct_train = 0\n",
    "        correct_test = 0\n",
    "        train_losses, valid_losses = [], []\n",
    "        loss = 0\n",
    "\n",
    "        # training part \n",
    "        network.train()\n",
    "        for index, (input, target) in enumerate(train_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network(input)\n",
    "\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1])  \n",
    "\n",
    "\n",
    "            # 3. backward propagation\n",
    "            loss.backward() \n",
    "\n",
    "\n",
    "            # 4. weight optimization\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # 5. save the loss for this PF\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            \n",
    "            # 6. check how many items where predicted correctly\n",
    "            correct_train += 1 if loss.item() <= marja_eroare else 0 \n",
    "            \n",
    "\n",
    "        # add the mean loss for this training epoch for ploting\n",
    "        train_mean_loss_for_epoch = np.mean(train_losses)\n",
    "        plot_train_losses.append(train_mean_loss_for_epoch)\n",
    "        \n",
    "        current_accuracy = (int)(100. * correct_train / len(train_set))\n",
    "        plot_train_accuracy.append(current_accuracy)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "            print(\"Train set -> \", \"loss: \", loss.item(), \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                  str(correct_train) + \"/\" + str(len(train_set)) + \"]\")\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # evaluation part \n",
    "#         network.eval()\n",
    "        if epoch % 1 == 0:\n",
    "#             \n",
    "            with torch.no_grad():\n",
    "                for index, (input, target) in enumerate(valid_set.items()):\n",
    "\n",
    "                    # if cuda is available, send (input, target) to gpu\n",
    "                    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "                    # 1. forward propagation\n",
    "                    output = network.forward(input)\n",
    "\n",
    "                    # 2. loss calculation\n",
    "                    loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "                    \n",
    "                    # 3. save loss for current PF\n",
    "                    valid_losses.append(loss)\n",
    "\n",
    "                    # 4. check how many items where predicted correctly\n",
    "                    correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "                 # add the mean loss for this training epoch for ploting\n",
    "                valid_mean_loss_for_epoch = np.mean(valid_losses)\n",
    "                plot_valid_losses.append(valid_mean_loss_for_epoch)\n",
    "                \n",
    "                current_accuracy = (int)(100. * correct_test / len(valid_set))\n",
    "\n",
    "                if epoch % 10 == 0 or epoch == 1 :\n",
    "                    print(\"Valid set -> \", \"loss: \", loss, \"accuracy: \", current_accuracy, \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(valid_set)) + \"]\")\n",
    "                \n",
    "                if epoch > 1:\n",
    "                    if current_accuracy > max(plot_valid_accuracy):\n",
    "                        print(\"--------------------------------------Epoch\", str(epoch) ,\"------------------------------\")\n",
    "#                         print(current_accuracy, max(plot_valid_accuracy))\n",
    "                        torch.save(network, str(epoch) + \"valid\"+ str(current_accuracy) + model_name)\n",
    "                        network_test = torch.load(str(epoch) + \"valid\"+ str(current_accuracy) + model_name)\n",
    "                        eval(network=network_test, test_set=test_set)\n",
    "                \n",
    "                plot_valid_accuracy.append(current_accuracy)\n",
    "                    \n",
    "        epoch += 1\n",
    "\n",
    "    torch.save(network, model_name)\n",
    "    \n",
    "    plt.plot(plot_train_losses, label='Training loss')\n",
    "    plt.plot(plot_valid_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(plot_train_accuracy, label='Training accuracy')\n",
    "    plt.plot(plot_valid_accuracy, label='Validation accuracy')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECONSTRUIRE SUNET PE FRAME-URI, FOLOSIND TARGETURILE GENERATE PT SETUL DE ANTRENARE\n",
    "def split_audios_epoch(name, mask, mix, samples_per_frame):\n",
    "    \n",
    "    frame_pos = (int)(nb_of_frames_in_AF/2)\n",
    "\n",
    "    mask_stack = torch.stack(mask)\n",
    "    cpu_mask = mask_stack.cpu()\n",
    "    n_mask = cpu_mask.detach().numpy()\n",
    "\n",
    "    mix_frames = np.array([mix[i:i + samples_per_frame] for i in range(0, len(mix), samples_per_frame)])\n",
    "    sound1 = np.empty([0,])\n",
    "    sound2 = np.empty([0,])\n",
    "\n",
    "\n",
    "    for i in range (0, len(mix_frames)):\n",
    "        stft_mix = librosa.stft(librosa.to_mono(mix_frames[i]), window='hann', n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        # reteaua nu a invatat mastile pentru primele frame_pos bucati [PF] din mix\n",
    "        # deci las matricea STFT asa cum e in mix\n",
    "        if i < frame_pos :\n",
    "            y_frame_1_stft_with_mask = stft_mix\n",
    "            y_frame_2_stft_with_mask = stft_mix\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "            \n",
    "        else:\n",
    "            # n_mask[i-7] pentru ca reteaua invata pt AF-uri facute pe cate 8 PF-uri -> 15 items pt AF\n",
    "            # abia de cand ajunge la primul AF care s a putut compune, folosesc masca invata de retea\n",
    "            \n",
    "            y_frame_1_stft_with_mask = np.multiply(n_mask[i-frame_pos], stft_mix)\n",
    "            y_frame_2_stft_with_mask = np.multiply((1 -  n_mask[i-frame_pos]), stft_mix)\n",
    "\n",
    "            inverse_sound1_stft = librosa.istft(y_frame_1_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "            inverse_sound2_stft = librosa.istft(y_frame_2_stft_with_mask, hop_length=hop_length, window='hann')\n",
    "\n",
    "            sound1 = np.concatenate((sound1, inverse_sound1_stft))\n",
    "            sound2 = np.concatenate((sound2, inverse_sound2_stft))\n",
    "\n",
    "\n",
    "    librosa.output.write_wav(\"recordings/voice1-\"+ str(name) + \".wav\", sound1, sr = 16000)\n",
    "    librosa.output.write_wav(\"recordings/voice2-\"+ str(name) + \".wav\", sound2, sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(network, test_set):\n",
    "\n",
    "#     network.eval()\n",
    "                \n",
    "    test_loss, test_mask, test_accuracy = [], [], []\n",
    "    correct_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (input, target) in enumerate(test_set.items()):\n",
    "\n",
    "            # if cuda is available, send (input, target) to gpu\n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # 1. forward propagation\n",
    "            output = network.forward(input)\n",
    "\n",
    "            # 2. loss calculation\n",
    "            loss = loss_function(target, output[len(output)-1]).detach().item()\n",
    "\n",
    "            # 3. save the mask for the current PF, meaning the last entry in the output\n",
    "            current_mask = output[len(output)-1]\n",
    "            test_mask.append(current_mask)\n",
    "\n",
    "            test_loss.append(loss)\n",
    "\n",
    "            # 4. check how many items where predicted correctly\n",
    "            correct_test += 1 if loss <= marja_eroare else 0\n",
    "\n",
    "\n",
    "        current_accuracy = 100. * correct_test / len(test_set)\n",
    "        print(\"Test set -> \", \"test loss: \", np.mean(test_loss), \"accuracy: \", (int)(current_accuracy), \"%\", \"[\" +\n",
    "                          str(correct_test) + \"/\" + str(len(test_set)) + \"]\")\n",
    "\n",
    "        return test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdam(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "\n",
    "    print(\"__________________________________________ADAM FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    network = Network()\n",
    "    \n",
    "    print(\"network sent to CUDA\")\n",
    "    network.cuda()\n",
    "    \n",
    "    # set optimizer -> article : Adam, lr = 0.01, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(network.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "        \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set = test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=network)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAdamConv(nr_epochs, train_set, valid_set, test_set, mixnb):\n",
    "    \n",
    "    print(\"__________________________________________ADAM CONV + FC_________________________________\")\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model_name = str(nr_epochs) + \"epoci-\"+ mixnb + \".pth\"\n",
    "    \n",
    "    networkConv = NetworkConv()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"networkConv sent to CUDA\")\n",
    "        networkConv.cuda()\n",
    "        \n",
    "    # set optimizer -> article : Adam, lr = 0.001, b1 = 0.9, b2 = 0.999\n",
    "    optimizer = optim.Adam(networkConv.parameters(), lr = 0.001, betas = (0.9, 0.999))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_network(nr_epochs=nr_epochs, \n",
    "                train_set=train_set, valid_set=valid_set, test_set=test_set,\n",
    "                model_name=model_name,\n",
    "                optimizer=optimizer,\n",
    "                network=networkConv)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Elapsed time for \" + model_name + \" : {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    \n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices(voice1_filename, voice2_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        \n",
    "    mix = voice1 + voice2\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-withOUT-noise.wav\", mix, 16000)\n",
    "    \n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mix_from_voices_with_noise(voice1_filename, voice2_filename, noise_filename, mix_5_sec):\n",
    "    \n",
    "    voice1, sr = librosa.load(voice1_filename, sr=16000) \n",
    "    voice1 = np.append(voice1, voice1)\n",
    "    \n",
    "    voice2, sr = librosa.load(voice2_filename, sr=16000)\n",
    "    voice2 = np.append(voice2, voice2)\n",
    "    \n",
    "    noise, sr = librosa.load(noise_filename, sr=16000)\n",
    "    noise = np.append(noise, noise)\n",
    "    noise = noise / 5\n",
    "    \n",
    "    if mix_5_sec == True:\n",
    "        voice1 = make_mix_of_5_seconds(voice1)\n",
    "        voice2 = make_mix_of_5_seconds(voice2)\n",
    "        noise = make_mix_of_5_seconds(noise)\n",
    "    else:\n",
    "        voice1 = make_mix_of_10_seconds(voice1)\n",
    "        voice2 = make_mix_of_10_seconds(voice2)\n",
    "        noise = make_mix_of_10_seconds(noise)\n",
    "    \n",
    "    mix = voice1 + voice2 + noise\n",
    "    \n",
    "    librosa.output.write_wav(\"recordings/mix-with-noise.wav\", mix, 16000)\n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ADAM FC_________________________________\n",
      "network sent to CUDA\n",
      "--------------------------------------Epoch 1 ------------------------------\n",
      "Train set ->  loss:  0.22449886798858643 accuracy:  0 % [0/398]\n",
      "Valid set ->  loss:  0.07739187031984329 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 10 ------------------------------\n",
      "Train set ->  loss:  0.06714106351137161 accuracy:  2 % [9/398]\n",
      "Valid set ->  loss:  0.06627974659204483 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 20 ------------------------------\n",
      "Train set ->  loss:  0.05627674609422684 accuracy:  4 % [17/398]\n",
      "Valid set ->  loss:  0.07326164096593857 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 30 ------------------------------\n",
      "Train set ->  loss:  0.044431302696466446 accuracy:  5 % [20/398]\n",
      "Valid set ->  loss:  0.06799902766942978 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 40 ------------------------------\n",
      "Train set ->  loss:  0.04089108109474182 accuracy:  6 % [26/398]\n",
      "Valid set ->  loss:  0.07424025982618332 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 50 ------------------------------\n",
      "Train set ->  loss:  0.024127019569277763 accuracy:  7 % [31/398]\n",
      "Valid set ->  loss:  0.0842619463801384 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 60 ------------------------------\n",
      "Train set ->  loss:  0.01920766569674015 accuracy:  14 % [56/398]\n",
      "Valid set ->  loss:  0.10278894007205963 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 70 ------------------------------\n",
      "Train set ->  loss:  0.01375688798725605 accuracy:  20 % [81/398]\n",
      "Valid set ->  loss:  0.08957880735397339 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 80 ------------------------------\n",
      "Train set ->  loss:  0.01310247927904129 accuracy:  25 % [100/398]\n",
      "Valid set ->  loss:  0.08109642565250397 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 90 ------------------------------\n",
      "Train set ->  loss:  0.00966055691242218 accuracy:  54 % [215/398]\n",
      "Valid set ->  loss:  0.10409340262413025 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 100 ------------------------------\n",
      "Train set ->  loss:  0.0060052527114748955 accuracy:  88 % [352/398]\n",
      "Valid set ->  loss:  0.09718772023916245 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 110 ------------------------------\n",
      "Train set ->  loss:  0.007313997950404882 accuracy:  94 % [378/398]\n",
      "Valid set ->  loss:  0.10912665724754333 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 120 ------------------------------\n",
      "Train set ->  loss:  0.0076809595339000225 accuracy:  92 % [370/398]\n",
      "Valid set ->  loss:  0.10682468116283417 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 130 ------------------------------\n",
      "Train set ->  loss:  0.004122348036617041 accuracy:  98 % [392/398]\n",
      "Valid set ->  loss:  0.10761528462171555 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 140 ------------------------------\n",
      "Train set ->  loss:  0.003454391146078706 accuracy:  97 % [388/398]\n",
      "Valid set ->  loss:  0.1010349914431572 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 150 ------------------------------\n",
      "Train set ->  loss:  0.0037762427236884832 accuracy:  98 % [393/398]\n",
      "Valid set ->  loss:  0.1083599105477333 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 160 ------------------------------\n",
      "Train set ->  loss:  0.003356341039761901 accuracy:  98 % [394/398]\n",
      "Valid set ->  loss:  0.10897010564804077 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 170 ------------------------------\n",
      "Train set ->  loss:  0.0033938114065676928 accuracy:  98 % [394/398]\n",
      "Valid set ->  loss:  0.10341615974903107 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 180 ------------------------------\n",
      "Train set ->  loss:  0.0033531070221215487 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.12446422129869461 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 190 ------------------------------\n",
      "Train set ->  loss:  0.0030584954656660557 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.10869612544775009 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 200 ------------------------------\n",
      "Train set ->  loss:  0.003129072953015566 accuracy:  98 % [394/398]\n",
      "Valid set ->  loss:  0.1216048076748848 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 210 ------------------------------\n",
      "Train set ->  loss:  0.0021915780380368233 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11061995476484299 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 220 ------------------------------\n",
      "Train set ->  loss:  0.002817032393068075 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11204525828361511 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 230 ------------------------------\n",
      "Train set ->  loss:  0.0019286025781184435 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11567429453134537 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 240 ------------------------------\n",
      "Train set ->  loss:  0.0018901597941294312 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11402948200702667 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 250 ------------------------------\n",
      "Train set ->  loss:  0.0017436137422919273 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11425454914569855 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 260 ------------------------------\n",
      "Train set ->  loss:  0.001737557235173881 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11340786516666412 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 270 ------------------------------\n",
      "Train set ->  loss:  0.0015164230717346072 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11613120883703232 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 280 ------------------------------\n",
      "Train set ->  loss:  0.0016538777854293585 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.11401785165071487 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 290 ------------------------------\n",
      "Train set ->  loss:  0.0013311501825228333 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.1144486740231514 accuracy:  0 % [0/50]\n",
      "--------------------------------------Epoch 300 ------------------------------\n",
      "Train set ->  loss:  0.002698349067941308 accuracy:  99 % [396/398]\n",
      "Valid set ->  loss:  0.12552005052566528 accuracy:  0 % [0/50]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time for 300epoci-FC-mix-80-10-10-v1(7)-v2(32).pth : 00:24:02.08\n",
      "Test set ->  test loss:  0.05461573631637805 accuracy:  79 % [396/498]\n",
      "Test set ->  test loss:  0.10108456361162697 accuracy:  25 % [129/498]\n"
     ]
    }
   ],
   "source": [
    "import winsound\n",
    "import os\n",
    "\n",
    "voice1 = 'recordings/voice1/arctic_a0007.wav'\n",
    "voice2 = 'recordings/voice2/arctic_a0032.wav'\n",
    "    \n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdam(300, train_set, valid_set, test_set_with_noise, \"FC-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec = True)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"FC-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame=samples_per_frame_10ms)\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set, valid_set, test_set_with_noise, \"CONV-mix-intreg-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-intreg-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_name = runAdam(300, train_set_80, valid_set_10, test_set_10, \"FC-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# test first what it learned from train\n",
    "mix = get_mix_from_voices(voice1, voice2, mix_5_sec=True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set)\n",
    "split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# test with noise\n",
    "mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav', mix_5_sec=True)\n",
    "network = torch.load(model_name)\n",
    "test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "split_audios_epoch(\"FC-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix, samples_per_frame_10ms)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# model_name = runAdamConv(200, train_set_80, valid_set_10, test_set_10, \"CONV-mix-80-10-10-v1(7)-v2(32)\")\n",
    "\n",
    "# # test first what it learned from train\n",
    "# mix = get_mix_from_voices(voice1, voice2)\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test\", test_mask, mix)\n",
    "\n",
    "# # test with noise\n",
    "# mix = get_mix_from_voices_with_noise(voice1, voice2, 'recordings/noises/piano5sec.wav')\n",
    "# network = torch.load(model_name)\n",
    "# test_mask = eval(network=network, test_set=test_set_with_noise)\n",
    "# split_audios_epoch(\"CONV-mix-80-10-10-v1(7)-v2(32)-test-noise\", test_mask, mix)\n",
    "\n",
    "# #-----------------------------------------------------------------------------------\n",
    "\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
